{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c13ed1",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-03T10:42:52.628920Z",
     "iopub.status.busy": "2025-08-03T10:42:52.628261Z",
     "iopub.status.idle": "2025-08-03T10:42:54.609291Z",
     "shell.execute_reply": "2025-08-03T10:42:54.608418Z"
    },
    "papermill": {
     "duration": 1.989347,
     "end_time": "2025-08-03T10:42:54.610826",
     "exception": false,
     "start_time": "2025-08-03T10:42:52.621479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/roberta-base/transformers/default/1/rust_model.ot\n",
      "/kaggle/input/roberta-base/transformers/default/1/config.json\n",
      "/kaggle/input/roberta-base/transformers/default/1/merges.txt\n",
      "/kaggle/input/roberta-base/transformers/default/1/README.md\n",
      "/kaggle/input/roberta-base/transformers/default/1/tokenizer.json\n",
      "/kaggle/input/roberta-base/transformers/default/1/vocab.json\n",
      "/kaggle/input/roberta-base/transformers/default/1/tf_model.h5\n",
      "/kaggle/input/roberta-base/transformers/default/1/tokenizer_config.json\n",
      "/kaggle/input/roberta-base/transformers/default/1/dict.txt\n",
      "/kaggle/input/roberta-base/transformers/default/1/pytorch_model.bin\n",
      "/kaggle/input/roberta-base/transformers/default/1/model.safetensors\n",
      "/kaggle/input/roberta-base/transformers/default/1/flax_model.msgpack\n",
      "/kaggle/input/jigsaw-agile-community-rules/sample_submission.csv\n",
      "/kaggle/input/jigsaw-agile-community-rules/train.csv\n",
      "/kaggle/input/jigsaw-agile-community-rules/test.csv\n",
      "/kaggle/input/jigsaw/subreddits.csv\n",
      "/kaggle/input/jigsaw/features.csv\n",
      "/kaggle/input/pm-88457018-at-08-03-2025-10-41-00/__script__.py\n",
      "/kaggle/input/pm-88457018-at-08-03-2025-10-41-00/charset_normalizer-3.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/pm-88457018-at-08-03-2025-10-41-00/markdown2-2.5.3-py3-none-any.whl\n",
      "/kaggle/input/pm-88457018-at-08-03-2025-10-41-00/joblib-1.5.1-py3-none-any.whl\n",
      "/kaggle/input/pm-88457018-at-08-03-2025-10-41-00/click-8.2.1-py3-none-any.whl\n",
      "/kaggle/input/pm-88457018-at-08-03-2025-10-41-00/protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl\n",
      "/kaggle/input/pm-88457018-at-08-03-2025-10-41-00/smmap-5.0.2-py3-none-any.whl\n",
      "/kaggle/input/pm-88457018-at-08-03-2025-10-41-00/requests-2.32.4-py3-none-any.whl\n",
      "/kaggle/input/pm-88457018-at-08-03-2025-10-41-00/wandb-0.21.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/pm-88457018-at-08-03-2025-10-41-00/sentry_sdk-2.34.1-py2.py3-none-any.whl\n",
      "/kaggle/input/pm-88457018-at-08-03-2025-10-41-00/kiwisolver-1.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/pm-88457018-at-08-03-2025-10-41-00/gitpython-3.1.45-py3-none-any.whl\n",
      "/kaggle/input/pm-88457018-at-08-03-2025-10-41-00/soupsieve-2.7-py3-none-any.whl\n",
      "/kaggle/input/pm-88457018-at-08-03-2025-10-41-00/platformdirs-4.3.8-py3-none-any.whl\n",
      "/kaggle/input/pm-88457018-at-08-03-2025-10-41-00/beautifulsoup4-4.13.3-py3-none-any.whl\n",
      "/kaggle/input/pm-88457018-at-08-03-2025-10-41-00/__results__.html\n",
      "/kaggle/input/pm-88457018-at-08-03-2025-10-41-00/PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/pm-88457018-at-08-03-2025-10-41-00/annotated_types-0.7.0-py3-none-any.whl\n",
      "/kaggle/input/pm-88457018-at-08-03-2025-10-41-00/pytz-2025.2-py2.py3-none-any.whl\n",
      "/kaggle/input/pm-88457018-at-08-03-2025-10-41-00/cycler-0.12.1-py3-none-any.whl\n",
      "/kaggle/input/pm-88457018-at-08-03-2025-10-41-00/scikit_learn-1.7.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl\n",
      "/kaggle/input/pm-88457018-at-08-03-2025-10-41-00/idna-3.10-py3-none-any.whl\n",
      "/kaggle/input/pm-88457018-at-08-03-2025-10-41-00/contourpy-1.3.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl\n",
      "/kaggle/input/pm-88457018-at-08-03-2025-10-41-00/urllib3-2.5.0-py3-none-any.whl\n",
      "/kaggle/input/pm-88457018-at-08-03-2025-10-41-00/pillow-11.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl\n",
      "/kaggle/input/pm-88457018-at-08-03-2025-10-41-00/input_requirements.txt\n",
      "/kaggle/input/pm-88457018-at-08-03-2025-10-41-00/typing_extensions-4.14.1-py3-none-any.whl\n",
      "/kaggle/input/pm-88457018-at-08-03-2025-10-41-00/six-1.17.0-py2.py3-none-any.whl\n",
      "/kaggle/input/pm-88457018-at-08-03-2025-10-41-00/typing_inspection-0.4.1-py3-none-any.whl\n",
      "/kaggle/input/pm-88457018-at-08-03-2025-10-41-00/numpy-2.3.2-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl\n",
      "/kaggle/input/pm-88457018-at-08-03-2025-10-41-00/scipy-1.16.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl\n",
      "/kaggle/input/pm-88457018-at-08-03-2025-10-41-00/threadpoolctl-3.6.0-py3-none-any.whl\n",
      "/kaggle/input/pm-88457018-at-08-03-2025-10-41-00/pandas-2.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/pm-88457018-at-08-03-2025-10-41-00/pyparsing-3.2.3-py3-none-any.whl\n",
      "/kaggle/input/pm-88457018-at-08-03-2025-10-41-00/python_dateutil-2.9.0.post0-py2.py3-none-any.whl\n",
      "/kaggle/input/pm-88457018-at-08-03-2025-10-41-00/tqdm-4.66.5-py3-none-any.whl\n",
      "/kaggle/input/pm-88457018-at-08-03-2025-10-41-00/pydantic-2.11.7-py3-none-any.whl\n",
      "/kaggle/input/pm-88457018-at-08-03-2025-10-41-00/pydantic_core-2.33.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/pm-88457018-at-08-03-2025-10-41-00/__script__.ipynb\n",
      "/kaggle/input/pm-88457018-at-08-03-2025-10-41-00/gitdb-4.0.12-py3-none-any.whl\n",
      "/kaggle/input/pm-88457018-at-08-03-2025-10-41-00/packaging-25.0-py3-none-any.whl\n",
      "/kaggle/input/pm-88457018-at-08-03-2025-10-41-00/__output__.json\n",
      "/kaggle/input/pm-88457018-at-08-03-2025-10-41-00/Unidecode-1.4.0-py3-none-any.whl\n",
      "/kaggle/input/pm-88457018-at-08-03-2025-10-41-00/fonttools-4.59.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl\n",
      "/kaggle/input/pm-88457018-at-08-03-2025-10-41-00/matplotlib-3.10.5-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl\n",
      "/kaggle/input/pm-88457018-at-08-03-2025-10-41-00/install_requirements.sh\n",
      "/kaggle/input/pm-88457018-at-08-03-2025-10-41-00/certifi-2025.8.3-py3-none-any.whl\n",
      "/kaggle/input/pm-88457018-at-08-03-2025-10-41-00/tzdata-2025.2-py2.py3-none-any.whl\n",
      "/kaggle/input/pm-88457018-at-08-03-2025-10-41-00/custom.css\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "for dirname, _, filenames in os.walk(\"/kaggle/input\"):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb6d660",
   "metadata": {
    "papermill": {
     "duration": 0.00459,
     "end_time": "2025-08-03T10:42:54.620745",
     "exception": false,
     "start_time": "2025-08-03T10:42:54.616155",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# utils.management\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdf1eaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T10:42:54.631391Z",
     "iopub.status.busy": "2025-08-03T10:42:54.631054Z",
     "iopub.status.idle": "2025-08-03T10:43:01.916079Z",
     "shell.execute_reply": "2025-08-03T10:43:01.915505Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 7.292084,
     "end_time": "2025-08-03T10:43:01.917428",
     "exception": false,
     "start_time": "2025-08-03T10:42:54.625344",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import inspect\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import List, Optional, Union\n",
    "\n",
    "import psutil\n",
    "import torch\n",
    "\n",
    "\n",
    "def clean_mem():\n",
    "    # import gc\n",
    "    # import os\n",
    "    # import sys\n",
    "    # import time\n",
    "    # import traceback\n",
    "\n",
    "    # import psutil\n",
    "    # import torch\n",
    "\n",
    "    process = psutil.Process(os.getpid())\n",
    "\n",
    "    # Measure RAM before cleanup\n",
    "    ram_before = process.memory_info().rss / (1024**2)  # in MB\n",
    "\n",
    "    # Measure GPU before cleanup\n",
    "    if torch.cuda.is_available():\n",
    "        gpu_alloc_before = torch.cuda.memory_allocated() / (1024**2)  # in MB\n",
    "        gpu_reserved_before = torch.cuda.memory_reserved() / (1024**2)  # in MB\n",
    "    else:\n",
    "        gpu_alloc_before = gpu_reserved_before = 0\n",
    "\n",
    "    # clean all traceback\n",
    "    if hasattr(sys, \"last_traceback\"):\n",
    "        traceback.clear_frames(sys.last_traceback)\n",
    "        delattr(sys, \"last_traceback\")\n",
    "    if hasattr(sys, \"last_type\"):\n",
    "        delattr(sys, \"last_type\")\n",
    "    if hasattr(sys, \"last_value\"):\n",
    "        delattr(sys, \"last_value\")\n",
    "\n",
    "    # clean all ipython history\n",
    "    if \"get_ipython\" in globals():\n",
    "        try:\n",
    "            from IPython import get_ipython\n",
    "\n",
    "            ip = get_ipython()\n",
    "            user_ns = ip.user_ns\n",
    "            ip.displayhook.flush()\n",
    "            pc = ip.displayhook.prompt_count + 1\n",
    "            for n in range(1, pc):\n",
    "                user_ns.pop(\"_i\" + repr(n), None)\n",
    "            user_ns.update(dict(_i=\"\", _ii=\"\", _iii=\"\"))\n",
    "            hm = ip.history_manager\n",
    "            hm.input_hist_parsed[:] = [\"\"] * pc\n",
    "            hm.input_hist_raw[:] = [\"\"] * pc\n",
    "            hm._i = hm._ii = hm._iii = hm._i00 = \"\"\n",
    "        except Exception as e:\n",
    "            print(\"ipython mem could not be cleared\")\n",
    "\n",
    "    # do a garbage collection and flush cuda cache\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Give system a small moment to settle (helps RAM measurement be more accurate)\n",
    "    time.sleep(0.1)\n",
    "\n",
    "    # Measure RAM after cleanup\n",
    "    ram_after = process.memory_info().rss / (1024**2)  # in MB\n",
    "\n",
    "    # Measure GPU after cleanup\n",
    "    if torch.cuda.is_available():\n",
    "        gpu_alloc_after = torch.cuda.memory_allocated() / (1024**2)  # in MB\n",
    "        gpu_reserved_after = torch.cuda.memory_reserved() / (1024**2)  # in MB\n",
    "    else:\n",
    "        gpu_alloc_after = gpu_reserved_after = 0\n",
    "\n",
    "    # Report freed memory\n",
    "    print(\n",
    "        f\"RAM freed: {ram_before - ram_after:.2f} MB ({ram_before:.2f} -> {ram_after:.2f})\"\n",
    "    )\n",
    "    if torch.cuda.is_available():\n",
    "        print(\n",
    "            f\"GPU allocated freed: {gpu_alloc_before - gpu_alloc_after:.2f} MB ({gpu_alloc_before:.2f} -> {gpu_alloc_after:.2f})\"\n",
    "        )\n",
    "        print(\n",
    "            f\"GPU reserved freed: {gpu_reserved_before - gpu_reserved_after:.2f} MB ({gpu_reserved_before:.2f} -> {gpu_reserved_after:.2f})\"\n",
    "        )\n",
    "    else:\n",
    "        print(\"No GPU detected.\")\n",
    "\n",
    "\n",
    "def create_logger(\n",
    "    name: str = \"reddit_moderation\",\n",
    "    log_level: str = \"INFO\",\n",
    "    log_file: Optional[Union[str, Path]] = None,\n",
    "    log_dir: Optional[Union[str, Path]] = \"logs\",\n",
    "    console_output: bool = True,\n",
    "    file_output: bool = True,\n",
    "    format_string: Optional[str] = None,\n",
    "    max_bytes: int = 10_000_000,  # 10MB\n",
    "    backup_count: int = 5,\n",
    "    include_timestamp_in_filename: bool = True,\n",
    ") -> logging.Logger:\n",
    "    \"\"\"\n",
    "    Create a fully featured logger for the Reddit comment moderation system.\n",
    "\n",
    "    This logger is designed to handle all aspects of the multi-stage classification\n",
    "    pipeline including zero-shot classification, fine-tuning, and evaluation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    name : str, optional\n",
    "        Logger name, by default \"reddit_moderation\"\n",
    "    log_level : str, optional\n",
    "        Logging level (\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"),\n",
    "        by default \"INFO\"\n",
    "    log_file : str or Path, optional\n",
    "        Specific log file path. If None, auto-generates based on name and timestamp\n",
    "    log_dir : str or Path, optional\n",
    "        Directory for log files, by default \"logs\"\n",
    "    console_output : bool, optional\n",
    "        Whether to output logs to console, by default True\n",
    "    file_output : bool, optional\n",
    "        Whether to output logs to file, by default True\n",
    "    format_string : str, optional\n",
    "        Custom log format string, by default None (uses comprehensive format)\n",
    "    max_bytes : int, optional\n",
    "        Maximum log file size before rotation, by default 10MB\n",
    "    backup_count : int, optional\n",
    "        Number of backup log files to keep, by default 5\n",
    "    include_timestamp_in_filename : bool, optional\n",
    "        Whether to include timestamp in log filename, by default True\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    logging.Logger\n",
    "        Configured logger instance ready for use\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> # Basic usage\n",
    "    >>> logger = create_logger()\n",
    "    >>> logger.info(\"Starting Reddit comment classification pipeline\")\n",
    "\n",
    "    >>> # Advanced usage for training\n",
    "    >>> training_logger = create_logger(\n",
    "    ...     name=\"distilbert_training\",\n",
    "    ...     log_level=\"DEBUG\",\n",
    "    ...     log_file=\"training_session.log\"\n",
    "    ... )\n",
    "    >>> training_logger.debug(\"Training batch processed\")\n",
    "\n",
    "    >>> # For evaluation only\n",
    "    >>> eval_logger = create_logger(\n",
    "    ...     name=\"model_evaluation\",\n",
    "    ...     console_output=False,\n",
    "    ...     log_file=\"evaluation_results.log\"\n",
    "    ... )\n",
    "    \"\"\"\n",
    "\n",
    "    # Create logger\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(getattr(logging, log_level.upper()))\n",
    "\n",
    "    # Clear existing handlers to avoid duplication\n",
    "    logger.handlers.clear()\n",
    "\n",
    "    # Default comprehensive format for ML workflows\n",
    "    if format_string is None:\n",
    "        format_string = \"%(asctime)s | %(name)s | %(levelname)s | %(message)s\"\n",
    "\n",
    "    formatter = logging.Formatter(format_string, datefmt=\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    # Console handler\n",
    "    if console_output:\n",
    "        console_handler = logging.StreamHandler(sys.stdout)\n",
    "        console_handler.setLevel(getattr(logging, log_level.upper()))\n",
    "        console_handler.setFormatter(formatter)\n",
    "        logger.addHandler(console_handler)\n",
    "\n",
    "    # File handler with rotation\n",
    "    if file_output:\n",
    "        # Create log directory\n",
    "        if log_dir:\n",
    "            log_dir = Path(log_dir)\n",
    "            log_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        # Generate log filename\n",
    "        if log_file is None:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            if include_timestamp_in_filename:\n",
    "                log_filename = f\"{name}_{timestamp}.log\"\n",
    "            else:\n",
    "                log_filename = f\"{name}.log\"\n",
    "            log_file = log_dir / log_filename if log_dir else Path(log_filename)\n",
    "        else:\n",
    "            log_file = Path(log_file)\n",
    "            if log_dir and not log_file.is_absolute():\n",
    "                log_file = Path(log_dir) / log_file\n",
    "\n",
    "        # Create rotating file handler\n",
    "        from logging.handlers import RotatingFileHandler\n",
    "\n",
    "        file_handler = RotatingFileHandler(\n",
    "            log_file, maxBytes=max_bytes, backupCount=backup_count, encoding=\"utf-8\"\n",
    "        )\n",
    "        file_handler.setLevel(getattr(logging, log_level.upper()))\n",
    "        file_handler.setFormatter(formatter)\n",
    "        logger.addHandler(file_handler)\n",
    "\n",
    "    # Add some useful methods to the logger\n",
    "    def log_dataset_info(dataset, dataset_name=\"Dataset\"):\n",
    "        \"\"\"Log dataset information\"\"\"\n",
    "        logger.info(f\"{dataset_name} Info:\")\n",
    "        logger.info(f\"  - Size: {len(dataset):,} samples\")\n",
    "        logger.info(f\"  - Columns: {dataset.column_names}\")\n",
    "        if \"labels\" in dataset.column_names:\n",
    "            import numpy as np\n",
    "\n",
    "            labels = np.array(dataset[\"labels\"])\n",
    "            unique, counts = np.unique(labels, return_counts=True)\n",
    "            logger.info(f\"  - Label distribution: {dict(zip(unique, counts))}\")\n",
    "\n",
    "    def log_model_info(model, model_name=\"Model\"):\n",
    "        \"\"\"Log model information\"\"\"\n",
    "        logger.info(f\"{model_name} Info:\")\n",
    "        if hasattr(model, \"config\"):\n",
    "            logger.info(f\"  - Model type: {model.config.model_type}\")\n",
    "            logger.info(f\"  - Hidden size: {model.config.hidden_size}\")\n",
    "            if hasattr(model.config, \"num_labels\"):\n",
    "                logger.info(f\"  - Number of labels: {model.config.num_labels}\")\n",
    "\n",
    "        # Count parameters\n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        logger.info(f\"  - Total parameters: {total_params:,}\")\n",
    "        logger.info(f\"  - Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "    def log_training_args(training_args):\n",
    "        \"\"\"Log training arguments\"\"\"\n",
    "        logger.info(\"Training Configuration:\")\n",
    "        logger.info(f\"  - Learning rate: {training_args.learning_rate}\")\n",
    "        logger.info(f\"  - Batch size: {training_args.per_device_train_batch_size}\")\n",
    "        logger.info(\n",
    "            f\"  - Gradient accumulation: {training_args.gradient_accumulation_steps}\"\n",
    "        )\n",
    "        logger.info(f\"  - Epochs: {training_args.num_train_epochs}\")\n",
    "        logger.info(f\"  - Weight decay: {training_args.weight_decay}\")\n",
    "        logger.info(f\"  - LR scheduler: {training_args.lr_scheduler_type}\")\n",
    "        logger.info(f\"  - Warmup ratio: {training_args.warmup_ratio}\")\n",
    "\n",
    "    def log_metrics(metrics, stage=\"\"):\n",
    "        \"\"\"Log evaluation metrics\"\"\"\n",
    "        stage_prefix = f\"{stage} \" if stage else \"\"\n",
    "        logger.info(f\"{stage_prefix}Metrics:\")\n",
    "        for metric, value in metrics.items():\n",
    "            if isinstance(value, float):\n",
    "                logger.info(f\"  - {metric}: {value:.4f}\")\n",
    "            else:\n",
    "                logger.info(f\"  - {metric}: {value}\")\n",
    "\n",
    "    # Attach utility methods to logger\n",
    "    logger.log_dataset_info = log_dataset_info\n",
    "    logger.log_model_info = log_model_info\n",
    "    logger.log_training_args = log_training_args\n",
    "    logger.log_metrics = log_metrics\n",
    "\n",
    "    # Log logger creation\n",
    "    logger.info(f\"Logger '{name}' created successfully\")\n",
    "    logger.info(f\"Log level: {log_level}\")\n",
    "    if file_output:\n",
    "        logger.info(f\"Log file: {log_file}\")\n",
    "\n",
    "    return logger\n",
    "\n",
    "\n",
    "# Convenience function for quick setup\n",
    "def setup_project_logging(debug_mode: bool = False) -> logging.Logger:\n",
    "    \"\"\"\n",
    "    Quick setup for the Reddit moderation project logging.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    debug_mode : bool\n",
    "        If True, sets log level to DEBUG and enables verbose logging\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    logging.Logger\n",
    "        Configured project logger\n",
    "    \"\"\"\n",
    "    log_level = \"DEBUG\" if debug_mode else \"INFO\"\n",
    "\n",
    "    return create_logger(\n",
    "        name=\"reddit_moderation_pipeline\",\n",
    "        log_level=log_level,\n",
    "        log_dir=\"project_logs\",\n",
    "        include_timestamp_in_filename=True,\n",
    "    )\n",
    "\n",
    "\n",
    "def get_ram_usage():\n",
    "    process = psutil.Process()\n",
    "    return process.memory_info().rss  # bytes\n",
    "\n",
    "\n",
    "def free_vars(\n",
    "    vars_to_delete: List[Union[str, object]],\n",
    "    namespace: Optional[dict] = None,\n",
    "    try_gpu: bool = True,\n",
    "    logger=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Deletes variables by name or reference, frees RAM and GPU (PyTorch) memory,\n",
    "    logs actions via logger if provided.\n",
    "\n",
    "    Args:\n",
    "      vars_to_delete: list of variable names (str) or object refs\n",
    "      namespace: dict to remove names from (defaults to caller's globals())\n",
    "      try_gpu: clear GPU memory for torch objects\n",
    "      logger: logging object or None (use print)\n",
    "    Returns:\n",
    "      (freed_ram_bytes, freed_gpu_bytes)\n",
    "    \"\"\"\n",
    "    # Setup logger if not provided\n",
    "    if logger is None:\n",
    "\n",
    "        def logger(msg):\n",
    "            print(msg)\n",
    "\n",
    "    else:\n",
    "        logger = logger.info\n",
    "\n",
    "    # Automatic namespace resolution\n",
    "    if namespace is None:\n",
    "        # Get frame of the caller, locals then globals\n",
    "        frame = inspect.currentframe().f_back\n",
    "        namespace = frame.f_globals\n",
    "\n",
    "    before_ram = get_ram_usage()\n",
    "    try:\n",
    "        import torch\n",
    "    except ImportError:\n",
    "        torch = None\n",
    "\n",
    "    freed_gpu_bytes = 0\n",
    "    torch_objs = []\n",
    "    deleted = []\n",
    "\n",
    "    for var in vars_to_delete:\n",
    "        if isinstance(var, str):\n",
    "            obj = namespace.get(var, None)\n",
    "            if obj is not None:\n",
    "                deleted.append(var)\n",
    "                if torch and try_gpu:\n",
    "                    torch_objs.append(obj)\n",
    "                del namespace[var]\n",
    "                logger(f\"Deleted variable '{var}'\")\n",
    "            else:\n",
    "                logger(f\"Variable '{var}' not found in namespace\")\n",
    "        else:\n",
    "            # Try to remove all names referencing the object\n",
    "            names = [n for n, v in namespace.items() if v is var]\n",
    "            for n in names:\n",
    "                del namespace[n]\n",
    "                deleted.append(n)\n",
    "                logger(f\"Deleted variable '{n}' (by reference)\")\n",
    "            if not names:\n",
    "                logger(\n",
    "                    f\"Could not find a variable name for object {var!r}, may not be deleted\"\n",
    "                )\n",
    "            if torch and try_gpu:\n",
    "                torch_objs.append(var)\n",
    "\n",
    "    if torch and try_gpu and torch_objs and torch.cuda.is_available():\n",
    "        before_gpu = torch.cuda.memory_allocated()\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "        after_gpu = torch.cuda.memory_allocated()\n",
    "        freed_gpu_bytes = after_gpu - before_gpu\n",
    "        logger(f\"GPU memory freed: {freed_gpu_bytes/(1024**2):.2f} MB\")\n",
    "    # Always run gc\n",
    "    gc.collect()\n",
    "    after_ram = get_ram_usage()\n",
    "    freed_ram_bytes = after_ram - before_ram\n",
    "    logger(f\"RAM memory freed: {freed_ram_bytes/(1024**2):.2f} MB\")\n",
    "    clean_mem()\n",
    "    # return freed_ram_bytes, freed_gpu_bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d9ee92",
   "metadata": {
    "papermill": {
     "duration": 0.004673,
     "end_time": "2025-08-03T10:43:01.927314",
     "exception": false,
     "start_time": "2025-08-03T10:43:01.922641",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# utils.preprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378d5bb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T10:43:01.937939Z",
     "iopub.status.busy": "2025-08-03T10:43:01.937615Z",
     "iopub.status.idle": "2025-08-03T10:43:03.500495Z",
     "shell.execute_reply": "2025-08-03T10:43:03.499844Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 1.570011,
     "end_time": "2025-08-03T10:43:03.501998",
     "exception": false,
     "start_time": "2025-08-03T10:43:01.931987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import heapq\n",
    "import logging\n",
    "import re\n",
    "from functools import partial\n",
    "from typing import Optional\n",
    "\n",
    "import markdown2\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from datasets import Dataset\n",
    "from unidecode import unidecode\n",
    "\n",
    "\n",
    "def sanitize_comment(comment):\n",
    "    # Convert markdown to HTML, then extract the text (HTML tags removed)\n",
    "    html = markdown2.markdown(comment)\n",
    "    text = BeautifulSoup(html, features=\"html.parser\").get_text()\n",
    "\n",
    "    # Convert markdown links [text](url) to just \"text\"\n",
    "    # Must be done on original comment, but here we do it on extracted text to be safe\n",
    "    # To be sure, you can do it before markdown conversion, but here kept as is for simplicity\n",
    "\n",
    "    # The markdown2 conversion often converts markdown links into HTML anchors,\n",
    "    # so links should already have URL removed by BeautifulSoup.get_text().\n",
    "    # However, just in case, let's remove leftover markdown links from original comment first:\n",
    "    text = re.sub(r\"\\[([^\\]]+)\\]\\(([^)]+)\\)\", r\"\\1\", comment)\n",
    "    # Then re-run markdown2 and extract text again to clean up\n",
    "    html = markdown2.markdown(text)\n",
    "    text = BeautifulSoup(html, features=\"html.parser\").get_text()\n",
    "\n",
    "    # Replace URLs with the url itself as plain text\n",
    "    # Extract URLs and replace markdown-style inline URLs [text](url) with url only is already handled,\n",
    "    # but explicit URLs just in text should be replaced with the URL string, not removed.\n",
    "    # For example: \"visit http://example.com for more\" should keep \"http://example.com\" as is.\n",
    "    # So to convert URL markdown to plain URLs requires us to find URLs and keep them as text.\n",
    "\n",
    "    # Here, let's find URLs and replace any markdown link forms to plain URLs if any missed:\n",
    "    # But since markdown2 and BeautifulSoup stripped them to plain text, raw URLs remain intact.\n",
    "\n",
    "    # So no need to remove URLs, but ensure any URLs embedded in text like \"https://...\" remain\n",
    "    # We can optionally extract and re-insert URLs if you want, but seems not required.\n",
    "\n",
    "    # Just to be sure, let's convert all URL-like substrings to themselves surrounded by spaces (to separate)\n",
    "    # This helps if URLs are concatenated with other text.\n",
    "    url_pattern = re.compile(r\"((?:http|https)://[^\\s]+|www\\.[^\\s]+)\", re.IGNORECASE)\n",
    "    text = url_pattern.sub(lambda m: m.group(0), text)\n",
    "\n",
    "    # Convert non-unicode characters to unicode (ASCII compatible)\n",
    "    text = unidecode(text)\n",
    "\n",
    "    # Normalize whitespace\n",
    "    text = \" \".join(text.split()).lower()\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def create_master_dataset(\n",
    "    train: pd.DataFrame,\n",
    "    test: pd.DataFrame,\n",
    "    logger: Optional[logging.Logger] = None,\n",
    "    positive_examples_to_consider: list = [1, 2],\n",
    "    negative_example_to_consider: list = [1, 2],\n",
    "    return_train_main_as_validation: bool = True,\n",
    ") -> pd.DataFrame:\n",
    "    if logger:\n",
    "        logger.info(\"Starting master dataset creation\")\n",
    "        logger.info(f\"Input - Train: {len(train)} rows, Test: {len(test)} rows\")\n",
    "\n",
    "    # 1. From train: use body\n",
    "    if logger:\n",
    "        logger.debug(\"Extracting main training data from 'body' column\")\n",
    "    train_main = train[[\"body\", \"rule\", \"subreddit\", \"rule_violation\"]].copy()\n",
    "    train_main = train_main.rename(\n",
    "        columns={\"body\": \"comment\", \"rule_violation\": \"violation\"}\n",
    "    )\n",
    "    if logger:\n",
    "        logger.debug(f\"Main training data: {len(train_main)} records\")\n",
    "\n",
    "    # 2. From train AND test: from positive/negative examples\n",
    "\n",
    "    # Helper to melt examples from a single dataframe\n",
    "    def extract_examples(\n",
    "        df, prefix_pos=\"positive_example_\", prefix_neg=\"negative_example_\"\n",
    "    ):\n",
    "        records = []\n",
    "\n",
    "        # For positive examples\n",
    "        for i in positive_examples_to_consider:\n",
    "            col = f\"{prefix_pos}{i}\"\n",
    "            # Ensure column exists and drop NA\n",
    "            if col in df.columns:\n",
    "                subdf = df[[\"rule\", \"subreddit\", col]].dropna(subset=[col])\n",
    "                if logger:\n",
    "                    logger.debug(\n",
    "                        f\"Extracting {len(subdf)} positive examples from {col}\"\n",
    "                    )\n",
    "                for _, row in subdf.iterrows():\n",
    "                    records.append(\n",
    "                        {\n",
    "                            \"comment\": row[col],\n",
    "                            \"rule\": row[\"rule\"],\n",
    "                            \"subreddit\": row[\"subreddit\"],\n",
    "                            \"violation\": 1,\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "        # For negative examples\n",
    "        for i in negative_example_to_consider:\n",
    "            col = f\"{prefix_neg}{i}\"\n",
    "            if col in df.columns:\n",
    "                subdf = df[[\"rule\", \"subreddit\", col]].dropna(subset=[col])\n",
    "                if logger:\n",
    "                    logger.debug(\n",
    "                        f\"Extracting {len(subdf)} negative examples from {col}\"\n",
    "                    )\n",
    "                for _, row in subdf.iterrows():\n",
    "                    records.append(\n",
    "                        {\n",
    "                            \"comment\": row[col],\n",
    "                            \"rule\": row[\"rule\"],\n",
    "                            \"subreddit\": row[\"subreddit\"],\n",
    "                            \"violation\": 0,\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "        return pd.DataFrame(records)\n",
    "\n",
    "    if logger:\n",
    "        logger.debug(\"Extracting examples from train dataset\")\n",
    "    train_examples = extract_examples(train)\n",
    "    if logger:\n",
    "        logger.debug(f\"Train examples extracted: {len(train_examples)} records\")\n",
    "\n",
    "    if logger:\n",
    "        logger.debug(\"Extracting examples from test dataset\")\n",
    "    try:\n",
    "        test_examples = extract_examples(test)\n",
    "    except Exception as e:\n",
    "        test_examples = []\n",
    "    if logger:\n",
    "        logger.debug(f\"Test examples extracted: {len(test_examples)} records\")\n",
    "\n",
    "    # Concatenate all parts\n",
    "    if logger:\n",
    "        logger.info(\"Concatenating all dataset parts\")\n",
    "    files_to_concat = [train_examples]\n",
    "    if len(test_examples) > 0:\n",
    "        files_to_concat.append(test_examples)\n",
    "    if not return_train_main_as_validation:\n",
    "        files_to_concat.append(train_main)\n",
    "    master_df = pd.concat(files_to_concat, ignore_index=True)\n",
    "\n",
    "    # Optional: drop rows with empty or null comment if any sneaked in\n",
    "    initial_size = len(master_df)\n",
    "    master_df = master_df.dropna(subset=[\"comment\"])\n",
    "    if logger and len(master_df) < initial_size:\n",
    "        logger.warning(\n",
    "            f\"Dropped {initial_size - len(master_df)} rows with null comments\"\n",
    "        )\n",
    "\n",
    "    # Reset index for cleanliness\n",
    "    master_df = master_df.reset_index(drop=True)\n",
    "\n",
    "    if logger:\n",
    "        logger.info(\n",
    "            f\"Master dataset created successfully: {len(master_df)} total records\"\n",
    "        )\n",
    "        logger.info(\n",
    "            f\"Violation distribution: {master_df['violation'].value_counts().to_dict()}\"\n",
    "        )\n",
    "\n",
    "    return master_df, train_main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ad0592",
   "metadata": {
    "papermill": {
     "duration": 0.004934,
     "end_time": "2025-08-03T10:43:03.512207",
     "exception": false,
     "start_time": "2025-08-03T10:43:03.507273",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2237b1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T10:43:03.523738Z",
     "iopub.status.busy": "2025-08-03T10:43:03.523287Z",
     "iopub.status.idle": "2025-08-03T10:43:06.734282Z",
     "shell.execute_reply": "2025-08-03T10:43:06.733567Z"
    },
    "papermill": {
     "duration": 3.218576,
     "end_time": "2025-08-03T10:43:06.735614",
     "exception": false,
     "start_time": "2025-08-03T10:43:03.517038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/dummy/dummy/runs/onqzttqg?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f1a0f457ad0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(mode=\"disabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ad6a304",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T10:43:06.746693Z",
     "iopub.status.busy": "2025-08-03T10:43:06.746503Z",
     "iopub.status.idle": "2025-08-03T10:43:42.389787Z",
     "shell.execute_reply": "2025-08-03T10:43:42.388933Z"
    },
    "papermill": {
     "duration": 35.650273,
     "end_time": "2025-08-03T10:43:42.391196",
     "exception": false,
     "start_time": "2025-08-03T10:43:06.740923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-03 10:43:16.029411: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1754217796.385787      66 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1754217796.486620      66 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import transformers\n",
    "from datasets import Dataset\n",
    "\n",
    "from scipy.special import softmax\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "\n",
    "from torch.utils import data\n",
    "from torchinfo import summary\n",
    "\n",
    "from transformers import (\n",
    "    AutoModel,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    "    EarlyStoppingCallback,\n",
    "    TrainerCallback,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a019668d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T10:43:42.403533Z",
     "iopub.status.busy": "2025-08-03T10:43:42.402929Z",
     "iopub.status.idle": "2025-08-03T10:43:42.406494Z",
     "shell.execute_reply": "2025-08-03T10:43:42.405993Z"
    },
    "papermill": {
     "duration": 0.010337,
     "end_time": "2025-08-03T10:43:42.407588",
     "exception": false,
     "start_time": "2025-08-03T10:43:42.397251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "367059d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T10:43:42.418192Z",
     "iopub.status.busy": "2025-08-03T10:43:42.417960Z",
     "iopub.status.idle": "2025-08-03T10:43:42.428061Z",
     "shell.execute_reply": "2025-08-03T10:43:42.427546Z"
    },
    "papermill": {
     "duration": 0.016542,
     "end_time": "2025-08-03T10:43:42.429054",
     "exception": false,
     "start_time": "2025-08-03T10:43:42.412512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-03 10:43:42 | reddit_moderation | INFO | Logger 'reddit_moderation' created successfully\n",
      "2025-08-03 10:43:42 | reddit_moderation | INFO | Log level: INFO\n",
      "2025-08-03 10:43:42 | reddit_moderation | INFO | Log file: logs/reddit_moderation_20250803_104342.log\n",
      "2025-08-03 10:43:42 | model | INFO | Logger 'model' created successfully\n",
      "2025-08-03 10:43:42 | model | INFO | Log level: INFO\n",
      "2025-08-03 10:43:42 | model | INFO | Log file: logs/training.log\n"
     ]
    }
   ],
   "source": [
    "logger = create_logger()\n",
    "training_logger = create_logger(name=\"model\", log_file=\"training.log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bc910f",
   "metadata": {
    "papermill": {
     "duration": 0.004656,
     "end_time": "2025-08-03T10:43:42.438943",
     "exception": false,
     "start_time": "2025-08-03T10:43:42.434287",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# load dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "626c9156",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T10:43:42.449710Z",
     "iopub.status.busy": "2025-08-03T10:43:42.449456Z",
     "iopub.status.idle": "2025-08-03T10:43:42.565976Z",
     "shell.execute_reply": "2025-08-03T10:43:42.565417Z"
    },
    "papermill": {
     "duration": 0.123258,
     "end_time": "2025-08-03T10:43:42.567200",
     "exception": false,
     "start_time": "2025-08-03T10:43:42.443942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "INPUT_PATH = os.path.join(\"/\", \"kaggle\", \"input\")\n",
    "# INPUT_PATH = os.path.join(\"..\", \"data\")\n",
    "train = pd.read_csv(\n",
    "    os.path.join(INPUT_PATH, \"jigsaw-agile-community-rules\", \"train.csv\")\n",
    ")\n",
    "test = pd.read_csv(os.path.join(INPUT_PATH, \"jigsaw-agile-community-rules\", \"test.csv\"))\n",
    "submission = pd.read_csv(\n",
    "    os.path.join(INPUT_PATH, \"jigsaw-agile-community-rules\", \"sample_submission.csv\")\n",
    ")\n",
    "features = pd.read_csv(os.path.join(INPUT_PATH, \"jigsaw\", \"features.csv\"))[\n",
    "    \"features\"\n",
    "].tolist()\n",
    "subreddits = pd.read_csv(os.path.join(INPUT_PATH, \"jigsaw\", \"subreddits.csv\"))[\n",
    "    \"subreddit\"\n",
    "].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4842c4b",
   "metadata": {
    "papermill": {
     "duration": 0.005088,
     "end_time": "2025-08-03T10:43:42.577732",
     "exception": false,
     "start_time": "2025-08-03T10:43:42.572644",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# load models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32361fe7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T10:43:42.589351Z",
     "iopub.status.busy": "2025-08-03T10:43:42.588775Z",
     "iopub.status.idle": "2025-08-03T10:43:42.593947Z",
     "shell.execute_reply": "2025-08-03T10:43:42.593416Z"
    },
    "papermill": {
     "duration": 0.012052,
     "end_time": "2025-08-03T10:43:42.595010",
     "exception": false,
     "start_time": "2025-08-03T10:43:42.582958",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-03 10:43:42 | reddit_moderation | INFO | {'classifier': '/kaggle/input/roberta-base/transformers/default/1', 'nli': '/kaggle/input/moritzlaurerdeberta-v3-base-mnli-fever-anli/transformers/default/1'}\n"
     ]
    }
   ],
   "source": [
    "_MODEL_VERSION_PATH = os.path.join(\n",
    "    \"transformers\",\n",
    "    \"default\",\n",
    "    \"1\",\n",
    ")\n",
    "_MODEL_DIR = os.path.join(\"/\", \"kaggle\", \"input\")\n",
    "MODEL_PATH = {\n",
    "    \"classifier\": os.path.join(_MODEL_DIR, \"roberta-base\", _MODEL_VERSION_PATH),\n",
    "    \"nli\": os.path.join(\n",
    "        _MODEL_DIR, \"moritzlaurerdeberta-v3-base-mnli-fever-anli\", _MODEL_VERSION_PATH\n",
    "    ),\n",
    "}\n",
    "\n",
    "# _MODEL_DIR = os.path.join(\"..\", \"model\")\n",
    "# MODEL_PATH = {\n",
    "#     \"classifier-OLD\": os.path.join(_MODEL_DIR, \"facebookai-roberta-large-mnli\"),\n",
    "#     \"nli\": os.path.join(\n",
    "#         _MODEL_DIR,\n",
    "#         \"nli-deberta-v3-small\",\n",
    "#     ),\n",
    "#     \"classifier\": os.path.join(_MODEL_DIR, \"roberta-base\"),\n",
    "# }\n",
    "logger.info(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a277a44",
   "metadata": {
    "papermill": {
     "duration": 0.004969,
     "end_time": "2025-08-03T10:43:42.605250",
     "exception": false,
     "start_time": "2025-08-03T10:43:42.600281",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# training dataset prep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda479f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T10:43:42.616571Z",
     "iopub.status.busy": "2025-08-03T10:43:42.616098Z",
     "iopub.status.idle": "2025-08-03T10:43:42.619069Z",
     "shell.execute_reply": "2025-08-03T10:43:42.618570Z"
    },
    "papermill": {
     "duration": 0.009724,
     "end_time": "2025-08-03T10:43:42.620048",
     "exception": false,
     "start_time": "2025-08-03T10:43:42.610324",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # make test shorter\n",
    "# max_length_train = 5_000\n",
    "# if len(test)>=max_length_train:\n",
    "#     train, _ = train_test_split(\n",
    "#         train, train_size=max_length_train,\n",
    "#         random_state=42,\n",
    "#         shuffle=True,\n",
    "#         stratify=train[\"rule\"]\n",
    "#     )\n",
    "\n",
    "# max_length_test = 20_000\n",
    "# if len(test)>=max_length_test:\n",
    "#     test, _ = train_test_split(\n",
    "#         test, train_size=max_length_test,\n",
    "#         random_state=42,\n",
    "#         shuffle=True,\n",
    "#         stratify=test[\"rule\"]\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96a3cae0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T10:43:42.631271Z",
     "iopub.status.busy": "2025-08-03T10:43:42.631094Z",
     "iopub.status.idle": "2025-08-03T10:43:50.842020Z",
     "shell.execute_reply": "2025-08-03T10:43:50.841236Z"
    },
    "papermill": {
     "duration": 8.217748,
     "end_time": "2025-08-03T10:43:50.843252",
     "exception": false,
     "start_time": "2025-08-03T10:43:42.625504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-03 10:43:42 | reddit_moderation | INFO | Cleaning c = 'body'\n",
      "2025-08-03 10:43:43 | reddit_moderation | INFO | Cleaning c = 'rule'\n",
      "2025-08-03 10:43:44 | reddit_moderation | INFO | Cleaning c = 'subreddit'\n",
      "2025-08-03 10:43:45 | reddit_moderation | INFO | Cleaning c = 'positive_example_1'\n",
      "2025-08-03 10:43:46 | reddit_moderation | INFO | Cleaning c = 'positive_example_2'\n",
      "2025-08-03 10:43:47 | reddit_moderation | INFO | Cleaning c = 'negative_example_1'\n",
      "2025-08-03 10:43:48 | reddit_moderation | INFO | Cleaning c = 'negative_example_2'\n",
      "2025-08-03 10:43:49 | reddit_moderation | INFO | Starting master dataset creation\n",
      "2025-08-03 10:43:49 | reddit_moderation | INFO | Input - Train: 2029 rows, Test: 10 rows\n",
      "2025-08-03 10:43:49 | reddit_moderation | INFO | Concatenating all dataset parts\n",
      "2025-08-03 10:43:49 | reddit_moderation | INFO | Master dataset created successfully: 4078 total records\n",
      "2025-08-03 10:43:49 | reddit_moderation | INFO | Violation distribution: {1: 2039, 0: 2039}\n",
      "2025-08-03 10:43:49 | reddit_moderation | INFO | Deleted variable 'train' (by reference)\n",
      "2025-08-03 10:43:49 | reddit_moderation | INFO | Deleted variable 'test' (by reference)\n",
      "2025-08-03 10:43:49 | reddit_moderation | INFO | GPU memory freed: 0.00 MB\n",
      "2025-08-03 10:43:49 | reddit_moderation | INFO | RAM memory freed: 93.38 MB\n",
      "RAM freed: 0.00 MB (1509.36 -> 1509.36)\n",
      "GPU allocated freed: 0.00 MB (0.00 -> 0.00)\n",
      "GPU reserved freed: 0.00 MB (0.00 -> 0.00)\n"
     ]
    }
   ],
   "source": [
    "for c in [\n",
    "    \"body\",\n",
    "    \"rule\",\n",
    "    \"subreddit\",\n",
    "    \"positive_example_1\",\n",
    "    \"positive_example_2\",\n",
    "    \"negative_example_1\",\n",
    "    \"negative_example_2\",\n",
    "]:\n",
    "    logger.info(f\"Cleaning {c = }\")\n",
    "    train[c] = train[c].apply(sanitize_comment)\n",
    "    if c in test.columns:\n",
    "        test[c] = test[c].apply(sanitize_comment)\n",
    "master_dataset, val_dataset = create_master_dataset(\n",
    "    train,\n",
    "    test,\n",
    "    logger,\n",
    "    positive_examples_to_consider=[1],\n",
    "    negative_example_to_consider=[1],\n",
    ")\n",
    "free_vars([train, test], logger=logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb75e60",
   "metadata": {
    "papermill": {
     "duration": 0.005742,
     "end_time": "2025-08-03T10:43:50.855337",
     "exception": false,
     "start_time": "2025-08-03T10:43:50.849595",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# modelling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acf40a2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T10:43:50.867942Z",
     "iopub.status.busy": "2025-08-03T10:43:50.867439Z",
     "iopub.status.idle": "2025-08-03T10:43:52.042555Z",
     "shell.execute_reply": "2025-08-03T10:43:52.041641Z"
    },
    "papermill": {
     "duration": 1.183026,
     "end_time": "2025-08-03T10:43:52.043887",
     "exception": false,
     "start_time": "2025-08-03T10:43:50.860861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/roberta-base/transformers/default/1 and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer.pad_token = '<pad>' | tokenizer.eos_token = '</s>'\n"
     ]
    }
   ],
   "source": [
    "# basemodel = get_custom_roberta(MODEL_PATH[\"classifier\"])\n",
    "basemodel = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH[\"classifier\"])\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH[\"classifier\"])\n",
    "print(f\"{tokenizer.pad_token = } | {tokenizer.eos_token = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "386af404",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T10:43:52.057132Z",
     "iopub.status.busy": "2025-08-03T10:43:52.056677Z",
     "iopub.status.idle": "2025-08-03T10:43:52.140175Z",
     "shell.execute_reply": "2025-08-03T10:43:52.139644Z"
    },
    "papermill": {
     "duration": 0.091489,
     "end_time": "2025-08-03T10:43:52.141575",
     "exception": false,
     "start_time": "2025-08-03T10:43:52.050086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _make_prompt(row):\n",
    "    prompt = f\"\"\"Rule: {row['rule']}\n",
    "\n",
    "Comment: \"{row['comment']}\"\n",
    "\n",
    "Question: Does this comment violate the rule?\n",
    "Answer:\"\"\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "master_dataset[\"prompt\"] = master_dataset.apply(_make_prompt, axis=1)\n",
    "master_dataset = Dataset.from_pandas(master_dataset)\n",
    "\n",
    "val_dataset[\"prompt\"] = val_dataset.apply(_make_prompt, axis=1)\n",
    "val_dataset = Dataset.from_pandas(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f7dbaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T10:43:52.155003Z",
     "iopub.status.busy": "2025-08-03T10:43:52.154422Z",
     "iopub.status.idle": "2025-08-03T10:43:55.210791Z",
     "shell.execute_reply": "2025-08-03T10:43:55.209773Z"
    },
    "papermill": {
     "duration": 3.064002,
     "end_time": "2025-08-03T10:43:55.212030",
     "exception": false,
     "start_time": "2025-08-03T10:43:52.148028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab1eae3595a3498b8f0959a469d4c4d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4078 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5237f0bc9a64d7dbe3e88c12e5fb673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2029 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-03 10:43:53 | model | INFO | Master Dataset Info:\n",
      "2025-08-03 10:43:53 | model | INFO |   - Size: 4,078 samples\n",
      "2025-08-03 10:43:53 | model | INFO |   - Columns: ['comment', 'rule', 'subreddit', 'violation', 'prompt', 'input_ids', 'attention_mask']\n",
      "2025-08-03 10:43:53 | model | INFO | Master Dataset Info:\n",
      "2025-08-03 10:43:53 | model | INFO |   - Size: 2,029 samples\n",
      "2025-08-03 10:43:53 | model | INFO |   - Columns: ['comment', 'rule', 'subreddit', 'violation', 'prompt', 'input_ids', 'attention_mask']\n",
      "2025-08-03 10:43:53 | reddit_moderation | INFO | Deleted variable 'master_dataset'\n",
      "2025-08-03 10:43:53 | reddit_moderation | INFO | Deleted variable 'val_dataset'\n",
      "2025-08-03 10:43:53 | reddit_moderation | INFO | GPU memory freed: 0.00 MB\n",
      "2025-08-03 10:43:54 | reddit_moderation | INFO | RAM memory freed: 0.00 MB\n",
      "RAM freed: 0.00 MB (1607.31 -> 1607.31)\n",
      "GPU allocated freed: 0.00 MB (0.00 -> 0.00)\n",
      "GPU reserved freed: 0.00 MB (0.00 -> 0.00)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_(batch):\n",
    "    return tokenizer(batch[\"prompt\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "tokenized_dataset = master_dataset.map(preprocess_, batched=True, batch_size=128)\n",
    "tokenized_val = val_dataset.map(preprocess_, batched=True, batch_size=128)\n",
    "\n",
    "training_logger.log_dataset_info(tokenized_dataset, \"Master Dataset\")\n",
    "training_logger.log_dataset_info(tokenized_val, \"Master Dataset\")\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "columns = [\"input_ids\", \"attention_mask\", \"violation\"]\n",
    "tokenized_dataset.set_format(type=\"torch\", columns=columns)\n",
    "tokenized_dataset = tokenized_dataset.rename_column(\"violation\", \"label\")\n",
    "\n",
    "tokenized_val.set_format(type=\"torch\", columns=columns)\n",
    "tokenized_val = tokenized_val.rename_column(\"violation\", \"label\")\n",
    "\n",
    "free_vars([\"master_dataset\", \"val_dataset\"], namespace=globals(), logger=logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3f21ad",
   "metadata": {
    "papermill": {
     "duration": 0.006733,
     "end_time": "2025-08-03T10:43:55.226866",
     "exception": false,
     "start_time": "2025-08-03T10:43:55.220133",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## define metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ff20fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T10:43:55.246325Z",
     "iopub.status.busy": "2025-08-03T10:43:55.245716Z",
     "iopub.status.idle": "2025-08-03T10:43:55.252142Z",
     "shell.execute_reply": "2025-08-03T10:43:55.251241Z"
    },
    "papermill": {
     "duration": 0.01538,
     "end_time": "2025-08-03T10:43:55.253576",
     "exception": false,
     "start_time": "2025-08-03T10:43:55.238196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "previous_auc = 0\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    global previous_auc\n",
    "    logits, labels = eval_pred\n",
    "\n",
    "    # Compute softmax probabilities and predictions\n",
    "    probs = softmax(logits, axis=1)\n",
    "    preds = np.argmax(probs, axis=1)\n",
    "\n",
    "    # Compute classification metrics\n",
    "    auc = roc_auc_score(y_true=labels, y_score=probs[:, 1])\n",
    "    acc = accuracy_score(labels, preds)\n",
    "\n",
    "    # Compute loss (CrossEntropyLoss expects torch tensors)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    loss = loss_fn(torch.tensor(logits), torch.tensor(labels)).item()\n",
    "\n",
    "    metrics = {\"auc\": auc, \"acc\": acc, \"loss\": loss}\n",
    "    improvement = auc - previous_auc\n",
    "    previous_auc = auc\n",
    "    logger.info(\n",
    "        f\"{auc = :.3f} | {acc*100 = :.1f} | {loss = :.2f} | {improvement = :.4f}\"\n",
    "    )\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39bf449",
   "metadata": {
    "papermill": {
     "duration": 0.015184,
     "end_time": "2025-08-03T10:43:55.279237",
     "exception": false,
     "start_time": "2025-08-03T10:43:55.264053",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## finetune\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353f6f9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T10:43:55.299591Z",
     "iopub.status.busy": "2025-08-03T10:43:55.298907Z",
     "iopub.status.idle": "2025-08-03T10:43:55.370929Z",
     "shell.execute_reply": "2025-08-03T10:43:55.370323Z"
    },
    "papermill": {
     "duration": 0.080902,
     "end_time": "2025-08-03T10:43:55.372074",
     "exception": false,
     "start_time": "2025-08-03T10:43:55.291172",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16f7c90f62f74c729f798890af74b146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/4078 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\")\n",
    "from datasets import ClassLabel\n",
    "\n",
    "# 1. Cast \"rule\" to ClassLabel\n",
    "#    This infers the unique values in splits[\"train\"][\"rule\"] and assigns integer IDs.\n",
    "tokenized_dataset = tokenized_dataset.cast_column(\n",
    "    \"rule\", ClassLabel(names=sorted(set(tokenized_dataset[\"rule\"])))\n",
    ")\n",
    "\n",
    "# 2. Now do the stratified split\n",
    "splits = tokenized_dataset.train_test_split(\n",
    "    test_size=0.4, shuffle=True, seed=42, stratify_by_column=\"rule\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8126aac5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T10:43:55.386796Z",
     "iopub.status.busy": "2025-08-03T10:43:55.386572Z",
     "iopub.status.idle": "2025-08-03T10:43:55.421336Z",
     "shell.execute_reply": "2025-08-03T10:43:55.420771Z"
    },
    "papermill": {
     "duration": 0.043151,
     "end_time": "2025-08-03T10:43:55.422598",
     "exception": false,
     "start_time": "2025-08-03T10:43:55.379447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"finetuned-roberta-binary\", exist_ok=True)\n",
    "training_args = TrainingArguments(\n",
    "    # 1. Directory and checkpointing\n",
    "    output_dir=\"finetuned-roberta-binary\",\n",
    "    # save_strategy=\"epoch\",  # Save at end of each epoch\n",
    "    save_total_limit=3,  # Keep only the 3 most recent checkpoints\n",
    "    # 2. Learning rate and schedule\n",
    "    learning_rate=2e-5,  # Common sweet spot for base models\n",
    "    lr_scheduler_type=\"linear\",  # Linear decay after warmup\n",
    "    warmup_ratio=0.1,  # 10% of total steps for warmup\n",
    "    # 3. Batch sizes and accumulation\n",
    "    per_device_train_batch_size=8,  # 8 on 16–32 GB GPU; lower if memory constrained\n",
    "    per_device_eval_batch_size=16,  # Larger eval batch for speed\n",
    "    gradient_accumulation_steps=4,  # Achieves ~32 samples/effective batch\n",
    "    # 4. Epochs and steps\n",
    "    num_train_epochs=4,  # 3–5 epochs is usually sufficient\n",
    "    max_steps=-1,  # Use epochs (not absolute steps)\n",
    "    # 5. Optimizer settings\n",
    "    weight_decay=0.01,  # Standard to regularize attention heads\n",
    "    adam_beta1=0.9,\n",
    "    adam_beta2=0.98,  # Slightly lower than default for stability\n",
    "    adam_epsilon=1e-8,  # Default epsilon\n",
    "    # 6. Precision and performance\n",
    "    fp16=True,  # Mixed precision for speed & memory\n",
    "    dataloader_pin_memory=True,  # Speed up CPU→GPU data transfer\n",
    "    # 7. Evaluation & logging\n",
    "    load_best_model_at_end=True,  # Automatically restore best checkpoint\n",
    "    metric_for_best_model=\"auc\",\n",
    "    greater_is_better=True,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=20,  # Log every 50 batches\n",
    "    logging_first_step=True,\n",
    "    report_to=\"none\",  # Disable WandB/MLflow by default\n",
    "    # 8. Misc\n",
    "    seed=42,  # For reproducibility\n",
    "    overwrite_output_dir=False,\n",
    "    save_strategy=\"steps\",\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=20,\n",
    "    save_steps=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f912e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T10:43:55.437162Z",
     "iopub.status.busy": "2025-08-03T10:43:55.436945Z",
     "iopub.status.idle": "2025-08-03T10:44:00.222536Z",
     "shell.execute_reply": "2025-08-03T10:44:00.221737Z"
    },
    "papermill": {
     "duration": 4.79431,
     "end_time": "2025-08-03T10:44:00.223992",
     "exception": false,
     "start_time": "2025-08-03T10:43:55.429682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=basemodel,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    eval_dataset=tokenized_val,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[\n",
    "        EarlyStoppingCallback(\n",
    "            early_stopping_patience=1, early_stopping_threshold=0.001\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96edc494",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T10:44:00.242203Z",
     "iopub.status.busy": "2025-08-03T10:44:00.241771Z",
     "iopub.status.idle": "2025-08-03T10:44:01.180754Z",
     "shell.execute_reply": "2025-08-03T10:44:01.179836Z"
    },
    "papermill": {
     "duration": 0.95003,
     "end_time": "2025-08-03T10:44:01.182067",
     "exception": false,
     "start_time": "2025-08-03T10:44:00.232037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM freed: 0.00 MB (1615.55 -> 1615.55)\n",
      "GPU allocated freed: 0.00 MB (476.73 -> 476.73)\n",
      "GPU reserved freed: 0.00 MB (530.00 -> 530.00)\n"
     ]
    }
   ],
   "source": [
    "clean_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8838d20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T10:44:01.196793Z",
     "iopub.status.busy": "2025-08-03T10:44:01.196594Z",
     "iopub.status.idle": "2025-08-03T10:55:59.136550Z",
     "shell.execute_reply": "2025-08-03T10:55:59.135812Z"
    },
    "papermill": {
     "duration": 717.948593,
     "end_time": "2025-08-03T10:55:59.137764",
     "exception": false,
     "start_time": "2025-08-03T10:44:01.189171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='140' max='256' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [140/256 11:51 < 09:58, 0.19 it/s, Epoch 2/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Auc</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.692500</td>\n",
       "      <td>0.687471</td>\n",
       "      <td>0.753526</td>\n",
       "      <td>0.545589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.580700</td>\n",
       "      <td>0.520540</td>\n",
       "      <td>0.824683</td>\n",
       "      <td>0.747166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.275200</td>\n",
       "      <td>0.624230</td>\n",
       "      <td>0.867622</td>\n",
       "      <td>0.780680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.206700</td>\n",
       "      <td>0.517243</td>\n",
       "      <td>0.888644</td>\n",
       "      <td>0.818137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.154600</td>\n",
       "      <td>0.534864</td>\n",
       "      <td>0.896204</td>\n",
       "      <td>0.825037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.101000</td>\n",
       "      <td>0.595340</td>\n",
       "      <td>0.897401</td>\n",
       "      <td>0.830951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.055600</td>\n",
       "      <td>0.661762</td>\n",
       "      <td>0.893729</td>\n",
       "      <td>0.827501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-03 10:45:38 | reddit_moderation | INFO | auc = 0.754 | acc*100 = 54.6 | loss = 0.69 | improvement = 0.7535\n",
      "2025-08-03 10:47:22 | reddit_moderation | INFO | auc = 0.825 | acc*100 = 74.7 | loss = 0.52 | improvement = 0.0712\n",
      "2025-08-03 10:49:06 | reddit_moderation | INFO | auc = 0.868 | acc*100 = 78.1 | loss = 0.62 | improvement = 0.0429\n",
      "2025-08-03 10:50:49 | reddit_moderation | INFO | auc = 0.889 | acc*100 = 81.8 | loss = 0.52 | improvement = 0.0210\n",
      "2025-08-03 10:52:33 | reddit_moderation | INFO | auc = 0.896 | acc*100 = 82.5 | loss = 0.53 | improvement = 0.0076\n",
      "2025-08-03 10:54:16 | reddit_moderation | INFO | auc = 0.897 | acc*100 = 83.1 | loss = 0.60 | improvement = 0.0012\n",
      "2025-08-03 10:55:59 | reddit_moderation | INFO | auc = 0.894 | acc*100 = 82.8 | loss = 0.66 | improvement = -0.0037\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=140, training_loss=0.2951631477900914, metrics={'train_runtime': 717.4823, 'train_samples_per_second': 22.735, 'train_steps_per_second': 0.357, 'total_flos': 2348003058032640.0, 'train_loss': 0.2951631477900914, 'epoch': 2.1882352941176473})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa936a6",
   "metadata": {
    "papermill": {
     "duration": 0.007568,
     "end_time": "2025-08-03T10:55:59.155323",
     "exception": false,
     "start_time": "2025-08-03T10:55:59.147755",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# generate predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97caf733",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T10:55:59.170593Z",
     "iopub.status.busy": "2025-08-03T10:55:59.170320Z",
     "iopub.status.idle": "2025-08-03T10:56:00.662233Z",
     "shell.execute_reply": "2025-08-03T10:56:00.661397Z"
    },
    "papermill": {
     "duration": 1.500952,
     "end_time": "2025-08-03T10:56:00.663556",
     "exception": false,
     "start_time": "2025-08-03T10:55:59.162604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-03 10:55:59 | reddit_moderation | INFO | Deleted variable 'tokenized_dataset'\n",
      "2025-08-03 10:55:59 | reddit_moderation | INFO | Deleted variable 'splits'\n",
      "2025-08-03 10:55:59 | reddit_moderation | INFO | GPU memory freed: 0.00 MB\n",
      "2025-08-03 10:55:59 | reddit_moderation | INFO | RAM memory freed: 0.00 MB\n",
      "RAM freed: 0.00 MB (2569.43 -> 2569.43)\n",
      "GPU allocated freed: 0.00 MB (1509.00 -> 1509.00)\n",
      "GPU reserved freed: 0.00 MB (1882.00 -> 1882.00)\n"
     ]
    }
   ],
   "source": [
    "free_vars(\n",
    "    vars_to_delete=[\"tokenized_dataset\", \"splits\"], namespace=globals(), logger=logger\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6236a68e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-03T10:56:00.679357Z",
     "iopub.status.busy": "2025-08-03T10:56:00.679143Z",
     "iopub.status.idle": "2025-08-03T10:56:01.025578Z",
     "shell.execute_reply": "2025-08-03T10:56:01.024779Z"
    },
    "papermill": {
     "duration": 0.355565,
     "end_time": "2025-08-03T10:56:01.026817",
     "exception": false,
     "start_time": "2025-08-03T10:56:00.671252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-03 10:56:00 | reddit_moderation | INFO | Cleaning c = 'body'\n",
      "2025-08-03 10:56:00 | reddit_moderation | INFO | Cleaning c = 'rule'\n",
      "2025-08-03 10:56:00 | reddit_moderation | INFO | Cleaning c = 'subreddit'\n",
      "2025-08-03 10:56:00 | reddit_moderation | INFO | Cleaning c = 'positive_example_1'\n",
      "2025-08-03 10:56:00 | reddit_moderation | INFO | Cleaning c = 'positive_example_2'\n",
      "2025-08-03 10:56:00 | reddit_moderation | INFO | Cleaning c = 'negative_example_1'\n",
      "2025-08-03 10:56:00 | reddit_moderation | INFO | Cleaning c = 'negative_example_2'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8082ed3d73434c2aa0f4eda2479084bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-03 10:56:00 | reddit_moderation | INFO | Starting model predictions on test data\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-03 10:56:00 | reddit_moderation | INFO | Predictions generated: shape (10, 2)\n",
      "2025-08-03 10:56:00 | reddit_moderation | INFO | Probabilities computed: 10 samples\n",
      "2025-08-03 10:56:00 | reddit_moderation | INFO | Creating submission DataFrame\n",
      "2025-08-03 10:56:00 | reddit_moderation | INFO | Submission DataFrame created: 10 rows\n",
      "2025-08-03 10:56:00 | reddit_moderation | INFO | Saving submission to CSV file\n",
      "2025-08-03 10:56:00 | reddit_moderation | INFO | Submission file 'submission.csv' saved successfully\n",
      "2025-08-03 10:56:00 | reddit_moderation | INFO | Displaying sample submission results:\n",
      "2025-08-03 10:56:00 | reddit_moderation | INFO |   Row ID 2029.0: Violation probability = 0.0150\n",
      "2025-08-03 10:56:00 | reddit_moderation | INFO |   Row ID 2030.0: Violation probability = 0.0306\n",
      "2025-08-03 10:56:00 | reddit_moderation | INFO |   Row ID 2031.0: Violation probability = 0.9949\n",
      "2025-08-03 10:56:00 | reddit_moderation | INFO |   Row ID 2032.0: Violation probability = 0.9953\n",
      "2025-08-03 10:56:00 | reddit_moderation | INFO |   Row ID 2033.0: Violation probability = 0.9965\n",
      "2025-08-03 10:56:00 | reddit_moderation | INFO | Test data processing and prediction pipeline completed successfully\n",
      "2025-08-03 10:56:00 | reddit_moderation | INFO | === PREDICTION SUMMARY ===\n",
      "2025-08-03 10:56:01 | reddit_moderation | INFO | Total test samples processed: 10\n",
      "2025-08-03 10:56:01 | reddit_moderation | INFO | High confidence violations (>0.8): 5\n",
      "2025-08-03 10:56:01 | reddit_moderation | INFO | Medium confidence violations (0.5-0.8): 0\n",
      "2025-08-03 10:56:01 | reddit_moderation | INFO | Low violations (<0.5): 5\n",
      "2025-08-03 10:56:01 | reddit_moderation | INFO | === END SUMMARY ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>rule_violation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2029</td>\n",
       "      <td>0.014959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2030</td>\n",
       "      <td>0.030590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2031</td>\n",
       "      <td>0.994935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2032</td>\n",
       "      <td>0.995270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2033</td>\n",
       "      <td>0.996466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  rule_violation\n",
       "0    2029        0.014959\n",
       "1    2030        0.030590\n",
       "2    2031        0.994935\n",
       "3    2032        0.995270\n",
       "4    2033        0.996466"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(os.path.join(INPUT_PATH, \"jigsaw-agile-community-rules\", \"test.csv\"))\n",
    "for c in [\n",
    "    \"body\",\n",
    "    \"rule\",\n",
    "    \"subreddit\",\n",
    "    \"positive_example_1\",\n",
    "    \"positive_example_2\",\n",
    "    \"negative_example_1\",\n",
    "    \"negative_example_2\",\n",
    "]:\n",
    "    logger.info(f\"Cleaning {c = }\")\n",
    "    test[c] = test[c].apply(sanitize_comment)\n",
    "test = test.rename(columns={\"body\": \"comment\"})\n",
    "test[\"prompt\"] = test.apply(_make_prompt, axis=1)\n",
    "test = Dataset.from_pandas(test)\n",
    "tokenized_test = test.map(preprocess_, batched=True, batch_size=128)\n",
    "tokenized_test.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n",
    "# Generate predictions\n",
    "logger.info(\"Starting model predictions on test data\")\n",
    "logger.debug(f\"Using trainer with model: {type(trainer.model).__name__}\")\n",
    "predictions = trainer.predict(tokenized_test).predictions\n",
    "logger.info(f\"Predictions generated: shape {predictions.shape}\")\n",
    "logger.debug(f\"Prediction range: [{predictions.min():.4f}, {predictions.max():.4f}]\")\n",
    "\n",
    "# Convert to probabilities\n",
    "logger.debug(\"Converting logits to probabilities using softmax\")\n",
    "probs = softmax(predictions, axis=1)[:, 1]  # Get violation probabilities\n",
    "logger.info(f\"Probabilities computed: {len(probs)} samples\")\n",
    "logger.debug(f\"Probability range: [{probs.min():.4f}, {probs.max():.4f}]\")\n",
    "logger.debug(f\"Mean probability: {probs.mean():.4f}\")\n",
    "\n",
    "# Create submission file\n",
    "logger.info(\"Creating submission DataFrame\")\n",
    "sub = pd.DataFrame({\"row_id\": test[\"row_id\"], \"rule_violation\": probs})\n",
    "logger.info(f\"Submission DataFrame created: {len(sub)} rows\")\n",
    "logger.debug(f\"Row ID range: {sub['row_id'].min()} to {sub['row_id'].max()}\")\n",
    "\n",
    "# Save submission\n",
    "logger.info(\"Saving submission to CSV file\")\n",
    "sub.to_csv(\"submission.csv\", index=False)\n",
    "logger.info(\"Submission file 'submission.csv' saved successfully\")\n",
    "\n",
    "# Display sample results\n",
    "logger.info(\"Displaying sample submission results:\")\n",
    "sample_results = sub.head()\n",
    "for idx, row in sample_results.iterrows():\n",
    "    logger.info(\n",
    "        f\"  Row ID {row['row_id']}: Violation probability = {row['rule_violation']:.4f}\"\n",
    "    )\n",
    "\n",
    "logger.info(\"Test data processing and prediction pipeline completed successfully\")\n",
    "\n",
    "# Optional: Log summary statistics\n",
    "logger.info(\"=== PREDICTION SUMMARY ===\")\n",
    "logger.info(f\"Total test samples processed: {len(sub)}\")\n",
    "logger.info(f\"High confidence violations (>0.8): {(probs > 0.8).sum()}\")\n",
    "logger.info(\n",
    "    f\"Medium confidence violations (0.5-0.8): {((probs > 0.5) & (probs <= 0.8)).sum()}\"\n",
    ")\n",
    "logger.info(f\"Low violations (<0.5): {(probs <= 0.5).sum()}\")\n",
    "logger.info(\"=== END SUMMARY ===\")\n",
    "\n",
    "sub.head()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 13121456,
     "sourceId": 94635,
     "sourceType": "competition"
    },
    {
     "datasetId": 7952621,
     "sourceId": 12591344,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 418776,
     "modelInstanceId": 400554,
     "sourceId": 504282,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 797.305369,
   "end_time": "2025-08-03T10:56:04.115427",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-03T10:42:46.810058",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0c6bbf7d0df845ca8a96b6828a063805": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0e7692c2a38149e892273a7600f44c79": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "0f0076608c314d6e9a436eea289cb6a4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "14d0356e9e2b4ef680204ee470302402": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b943759e01484f9a872d84bf4f9a070b",
       "max": 4078,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4a27647a699245c292c08acc8d846580",
       "tabbable": null,
       "tooltip": null,
       "value": 4078
      }
     },
     "16f7c90f62f74c729f798890af74b146": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_9e10234d104a4aefa9e3d80228ff1bfa",
        "IPY_MODEL_9cac5fa5d07f464985e5e9ce5fef23ec",
        "IPY_MODEL_7a8ff256ef6b4cd4b9d9c94ce226268c"
       ],
       "layout": "IPY_MODEL_9ae9348b137e424c8ed8b8ff5bf5f31e",
       "tabbable": null,
       "tooltip": null
      }
     },
     "2d3ed618fbed465989a16379c950ef50": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8f3fc2242122457cad8b0e69e3f0ace7",
       "placeholder": "​",
       "style": "IPY_MODEL_0f0076608c314d6e9a436eea289cb6a4",
       "tabbable": null,
       "tooltip": null,
       "value": " 10/10 [00:00&lt;00:00, 571.59 examples/s]"
      }
     },
     "319ed18f78f14988ad79d53f17c131cf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "324551fddcdc4ab2a5298d63d9a8f13a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3f20b70925624cb5ba8c45fe88882a9a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4a27647a699245c292c08acc8d846580": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4a363ee76083444a951a13446c0404fb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5c17c7bbd3e643718dc19e88f05e1b6f",
       "max": 2029,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0e7692c2a38149e892273a7600f44c79",
       "tabbable": null,
       "tooltip": null,
       "value": 2029
      }
     },
     "4b7bbb59689d4355bf0dfc06f6d1f783": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "595485c59ccd4ce8bb4836de66a80e97": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5c17c7bbd3e643718dc19e88f05e1b6f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "63d9f9ff8a9b458892ff58dea7678e6f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6c26b6dabe66434ebafddb76d068fd4e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "73e7bc56d23249ec8b6f287f8056fcef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7486001a9d3d479eb8f010505b6140e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "77df7a2e81e540689675250ca908ac57": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ca5a8a7c7b8747d8b8cbc2154004f64c",
       "placeholder": "​",
       "style": "IPY_MODEL_a1a23d2479d9406ab860b01911e354ca",
       "tabbable": null,
       "tooltip": null,
       "value": " 2029/2029 [00:00&lt;00:00, 3785.94 examples/s]"
      }
     },
     "7a8ff256ef6b4cd4b9d9c94ce226268c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7aac79612b254b18a156e418d7a50a44",
       "placeholder": "​",
       "style": "IPY_MODEL_7486001a9d3d479eb8f010505b6140e2",
       "tabbable": null,
       "tooltip": null,
       "value": " 4078/4078 [00:00&lt;00:00, 91718.35 examples/s]"
      }
     },
     "7aac79612b254b18a156e418d7a50a44": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7d877dee0962482fa7cac8dfb79305f8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8082ed3d73434c2aa0f4eda2479084bd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f9fbc47477ea48d18af3a26013470992",
        "IPY_MODEL_b303d28809974eb29df829717e65f0fe",
        "IPY_MODEL_2d3ed618fbed465989a16379c950ef50"
       ],
       "layout": "IPY_MODEL_3f20b70925624cb5ba8c45fe88882a9a",
       "tabbable": null,
       "tooltip": null
      }
     },
     "808e4f63157d4071ac91b3fcdb964b27": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8bc7b47da76d4d9880f0bbcf914af6eb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7d877dee0962482fa7cac8dfb79305f8",
       "placeholder": "​",
       "style": "IPY_MODEL_6c26b6dabe66434ebafddb76d068fd4e",
       "tabbable": null,
       "tooltip": null,
       "value": "Map: 100%"
      }
     },
     "8f3fc2242122457cad8b0e69e3f0ace7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9ae9348b137e424c8ed8b8ff5bf5f31e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9cac5fa5d07f464985e5e9ce5fef23ec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0c6bbf7d0df845ca8a96b6828a063805",
       "max": 4078,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d469dc09f4054ed5bf11d19b88c7d9de",
       "tabbable": null,
       "tooltip": null,
       "value": 4078
      }
     },
     "9e10234d104a4aefa9e3d80228ff1bfa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b249100735664e708dffbd354fa15b59",
       "placeholder": "​",
       "style": "IPY_MODEL_4b7bbb59689d4355bf0dfc06f6d1f783",
       "tabbable": null,
       "tooltip": null,
       "value": "Casting the dataset: 100%"
      }
     },
     "a1a23d2479d9406ab860b01911e354ca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ab1eae3595a3498b8f0959a469d4c4d6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8bc7b47da76d4d9880f0bbcf914af6eb",
        "IPY_MODEL_14d0356e9e2b4ef680204ee470302402",
        "IPY_MODEL_cef56ed59ab244f5bd6b4996bba6d7eb"
       ],
       "layout": "IPY_MODEL_b5fd11525fa548d2bc2f397bfaca6747",
       "tabbable": null,
       "tooltip": null
      }
     },
     "ab5f18602ef5473494c940c0f315178d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_324551fddcdc4ab2a5298d63d9a8f13a",
       "placeholder": "​",
       "style": "IPY_MODEL_595485c59ccd4ce8bb4836de66a80e97",
       "tabbable": null,
       "tooltip": null,
       "value": "Map: 100%"
      }
     },
     "b249100735664e708dffbd354fa15b59": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b303d28809974eb29df829717e65f0fe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_808e4f63157d4071ac91b3fcdb964b27",
       "max": 10,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ebaf7243529e4a7bb7ee4cdafdb7666f",
       "tabbable": null,
       "tooltip": null,
       "value": 10
      }
     },
     "b5fd11525fa548d2bc2f397bfaca6747": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b943759e01484f9a872d84bf4f9a070b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c5237f0bc9a64d7dbe3e88c12e5fb673": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ab5f18602ef5473494c940c0f315178d",
        "IPY_MODEL_4a363ee76083444a951a13446c0404fb",
        "IPY_MODEL_77df7a2e81e540689675250ca908ac57"
       ],
       "layout": "IPY_MODEL_d52a1fa52c39410bb69c1716dc4cb727",
       "tabbable": null,
       "tooltip": null
      }
     },
     "ca5a8a7c7b8747d8b8cbc2154004f64c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cef56ed59ab244f5bd6b4996bba6d7eb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_63d9f9ff8a9b458892ff58dea7678e6f",
       "placeholder": "​",
       "style": "IPY_MODEL_319ed18f78f14988ad79d53f17c131cf",
       "tabbable": null,
       "tooltip": null,
       "value": " 4078/4078 [00:01&lt;00:00, 3884.21 examples/s]"
      }
     },
     "d469dc09f4054ed5bf11d19b88c7d9de": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "d52a1fa52c39410bb69c1716dc4cb727": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ebaf7243529e4a7bb7ee4cdafdb7666f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "f5d75035f4974c4b90bb080d73d33ae7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f9fbc47477ea48d18af3a26013470992": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f5d75035f4974c4b90bb080d73d33ae7",
       "placeholder": "​",
       "style": "IPY_MODEL_73e7bc56d23249ec8b6f287f8056fcef",
       "tabbable": null,
       "tooltip": null,
       "value": "Map: 100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
