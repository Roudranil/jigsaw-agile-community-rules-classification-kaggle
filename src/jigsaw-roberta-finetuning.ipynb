{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9f5647e",
   "metadata": {},
   "source": [
    "# imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c8d5620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/dummy/dummy/runs/cmdrs9k0?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f1ce55e6110>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(mode=\"disabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0152c411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "import lightning as L\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import transformers\n",
    "from datasets import Dataset\n",
    "from lightning.pytorch.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
    "from rich.table import Table\n",
    "from scipy.special import softmax\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import (\n",
    "    CosineAnnealingLR,\n",
    "    CosineAnnealingWarmRestarts,\n",
    "    LinearLR,\n",
    "    SequentialLR,\n",
    ")\n",
    "from torch.utils import data\n",
    "from torchinfo import summary\n",
    "from torchmetrics.classification import BinaryAccuracy, BinaryAUROC\n",
    "from transformers import (\n",
    "    AutoModel,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    pipeline,\n",
    ")\n",
    "\n",
    "from utils.management import clean_mem, create_logger, free_vars\n",
    "from utils.preprocess import (\n",
    "    add_classification_preds_rule_subreddit,\n",
    "    create_master_dataset,\n",
    "    sanitize_comment,\n",
    ")\n",
    "from utils.reoberta import get_custom_roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adcbf586",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "563b97e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-02 16:44:15 | reddit_moderation | INFO | Logger 'reddit_moderation' created successfully\n",
      "2025-08-02 16:44:15 | reddit_moderation | INFO | Log level: INFO\n",
      "2025-08-02 16:44:15 | reddit_moderation | INFO | Log file: logs/reddit_moderation_20250802_164415.log\n",
      "2025-08-02 16:44:15 | model | INFO | Logger 'model' created successfully\n",
      "2025-08-02 16:44:15 | model | INFO | Log level: INFO\n",
      "2025-08-02 16:44:15 | model | INFO | Log file: logs/training.log\n"
     ]
    }
   ],
   "source": [
    "logger = create_logger()\n",
    "training_logger = create_logger(name=\"model\", log_file=\"training.log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb30170",
   "metadata": {},
   "source": [
    "# load dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e3b31f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT_PATH = os.path.join(\"/\", \"kaggle\", \"input\")\n",
    "INPUT_PATH = os.path.join(\"..\", \"data\")\n",
    "train = pd.read_csv(\n",
    "    os.path.join(INPUT_PATH, \"jigsaw-agile-community-rules\", \"train.csv\")\n",
    ")\n",
    "test = pd.read_csv(os.path.join(INPUT_PATH, \"jigsaw-agile-community-rules\", \"test.csv\"))\n",
    "submission = pd.read_csv(\n",
    "    os.path.join(INPUT_PATH, \"jigsaw-agile-community-rules\", \"sample_submission.csv\")\n",
    ")\n",
    "features = pd.read_csv(os.path.join(INPUT_PATH, \"jigsaw\", \"features.csv\"))[\n",
    "    \"features\"\n",
    "].tolist()\n",
    "subreddits = pd.read_csv(os.path.join(INPUT_PATH, \"jigsaw\", \"subreddits.csv\"))[\n",
    "    \"subreddit\"\n",
    "].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0f9dd8",
   "metadata": {},
   "source": [
    "# load models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef289c2",
   "metadata": {},
   "source": [
    "first model to load will be a basic roberta model, and hopefully we can do some stuff with it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9ca06a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-02 16:44:15 | reddit_moderation | INFO | {'classifier-OLD': '../model/facebookai-roberta-large-mnli', 'nli': '../model/nli-deberta-v3-small', 'classifier': '../model/roberta-base'}\n"
     ]
    }
   ],
   "source": [
    "# _MODEL_DIR = os.path.join(\"/\", \"kaggle\", \"input\")\n",
    "# MODEL_PATH = {\n",
    "#     \"classifier\": os.path.join(\n",
    "#         _MODEL_DIR, \"facebookai-roberta-large-mnli\", \"transformers\", \"default\", \"1\"\n",
    "#     ),\n",
    "#     \"nli\": os.path.join(\n",
    "#         _MODEL_DIR,\n",
    "#         \"moritzlaurerdeberta-v3-base-mnli-fever-anli\",\n",
    "#         \"transformers\",\n",
    "#         \"default\",\n",
    "#         \"1\",\n",
    "#     ),\n",
    "# }\n",
    "_MODEL_VERSION_PATH = os.path.join(\n",
    "    \"transformers\",\n",
    "    \"default\",\n",
    "    \"1\",\n",
    ")\n",
    "_MODEL_DIR = os.path.join(\"..\", \"model\")\n",
    "MODEL_PATH = {\n",
    "    \"classifier-OLD\": os.path.join(_MODEL_DIR, \"facebookai-roberta-large-mnli\"),\n",
    "    \"nli\": os.path.join(\n",
    "        _MODEL_DIR,\n",
    "        \"nli-deberta-v3-small\",\n",
    "    ),\n",
    "    \"classifier\": os.path.join(_MODEL_DIR, \"roberta-base\"),\n",
    "}\n",
    "logger.info(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b3a376",
   "metadata": {},
   "source": [
    "# training dataset prep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "477bb384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-02 16:44:15 | reddit_moderation | INFO | Cleaning c = 'body'\n",
      "2025-08-02 16:44:15 | reddit_moderation | INFO | Cleaning c = 'rule'\n",
      "2025-08-02 16:44:15 | reddit_moderation | INFO | Cleaning c = 'subreddit'\n",
      "2025-08-02 16:44:16 | reddit_moderation | INFO | Cleaning c = 'positive_example_1'\n",
      "2025-08-02 16:44:16 | reddit_moderation | INFO | Cleaning c = 'positive_example_2'\n",
      "2025-08-02 16:44:17 | reddit_moderation | INFO | Cleaning c = 'negative_example_1'\n",
      "2025-08-02 16:44:17 | reddit_moderation | INFO | Cleaning c = 'negative_example_2'\n",
      "2025-08-02 16:44:18 | reddit_moderation | INFO | Starting master dataset creation\n",
      "2025-08-02 16:44:18 | reddit_moderation | INFO | Input - Train: 2029 rows, Test: 10 rows\n",
      "2025-08-02 16:44:18 | reddit_moderation | INFO | Concatenating all dataset parts\n",
      "2025-08-02 16:44:18 | reddit_moderation | INFO | Master dataset created successfully: 10185 total records\n",
      "2025-08-02 16:44:18 | reddit_moderation | INFO | Violation distribution: {1: 5109, 0: 5076}\n",
      "2025-08-02 16:44:18 | reddit_moderation | INFO | Deleted variable 'train' (by reference)\n",
      "2025-08-02 16:44:18 | reddit_moderation | INFO | Deleted variable 'test' (by reference)\n",
      "2025-08-02 16:44:18 | reddit_moderation | INFO | Deleted variable 'master_dataset' (by reference)\n",
      "2025-08-02 16:44:18 | reddit_moderation | INFO | GPU memory freed: 0.00 MB\n",
      "2025-08-02 16:44:18 | reddit_moderation | INFO | RAM memory freed: 108.83 MB\n",
      "RAM freed: -0.00 MB (1061.69 -> 1061.70)\n",
      "GPU allocated freed: 0.00 MB (0.00 -> 0.00)\n",
      "GPU reserved freed: 0.00 MB (0.00 -> 0.00)\n"
     ]
    }
   ],
   "source": [
    "for c in [\n",
    "    \"body\",\n",
    "    \"rule\",\n",
    "    \"subreddit\",\n",
    "    \"positive_example_1\",\n",
    "    \"positive_example_2\",\n",
    "    \"negative_example_1\",\n",
    "    \"negative_example_2\",\n",
    "]:\n",
    "    logger.info(f\"Cleaning {c = }\")\n",
    "    train[c] = train[c].apply(sanitize_comment)\n",
    "    test[c] = test[c].apply(sanitize_comment)\n",
    "master_dataset = create_master_dataset(train, test, logger)\n",
    "dataset = Dataset.from_pandas(master_dataset)\n",
    "free_vars([train, test, master_dataset], logger=logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61264e1",
   "metadata": {},
   "source": [
    "# extract features and tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3e228c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# rule_classifier = pipeline(\n",
    "#     \"zero-shot-classification\", model=MODEL_PATH[\"nli\"], device=device\n",
    "# )\n",
    "subreddit_classifier = pipeline(\n",
    "    \"zero-shot-classification\", model=MODEL_PATH[\"nli\"], device=device\n",
    ")\n",
    "rule_vectorizer = TfidfVectorizer().fit(features)\n",
    "rule_vecs = rule_vectorizer.transform(features)\n",
    "\n",
    "# subreddit_vectorizer = TfidfVectorizer().fit(subreddits)\n",
    "# subreddit_vecs = subreddit_vectorizer.transform(subreddits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46683415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d224dc6befde4f6dadd0405dd39d720e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-02 16:44:19 | reddit_moderation | INFO | Starting prediction for column 'rule'\n",
      "2025-08-02 16:44:19 | reddit_moderation | INFO | Processing 2 texts from batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-02 16:44:19 | reddit_moderation | INFO | Sample 0: top scores ['ban advertising:0.765', 'ban spam:0.383', 'ban illegal content:0.137'], above threshold: 2, chosen: 2\n",
      "2025-08-02 16:44:19 | reddit_moderation | INFO | Sample 1: top scores ['enforce respectful conduct:0.000', 'enforce on topic content:0.000', 'ban low effort content:0.000'], above threshold: 0, chosen: 1\n",
      "2025-08-02 16:44:19 | reddit_moderation | INFO | Prediction completed for 2 samples on column 'rule'\n",
      "2025-08-02 16:44:19 | reddit_moderation | INFO | Sample predictions: ['ban advertising, ban spam', 'enforce respectful conduct']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "360306a4c6d24a8497fabfabb25afe80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-02 16:44:20 | reddit_moderation | INFO | Starting NLI prediction for column 'subreddit'\n",
      "2025-08-02 16:44:20 | reddit_moderation | INFO | Processing 100 texts with NLI classifier\n",
      "2025-08-02 16:44:31 | reddit_moderation | INFO | Sample 7: using best label news with score 0.788\n",
      "2025-08-02 16:44:31 | reddit_moderation | INFO | Sample 10: using best label question answers with score 0.512\n",
      "2025-08-02 16:44:31 | reddit_moderation | INFO | Sample 15: using best label food with score 0.755\n",
      "2025-08-02 16:44:31 | reddit_moderation | INFO | Sample 30: using best label niche with score 0.544\n",
      "2025-08-02 16:44:31 | reddit_moderation | INFO | Sample 33: using best label relationship with score 0.657\n",
      "2025-08-02 16:44:31 | reddit_moderation | INFO | Sample 41: using best label nsfw with score 0.678\n",
      "2025-08-02 16:44:31 | reddit_moderation | INFO | Sample 45: using best label regional with score 0.757\n",
      "2025-08-02 16:44:31 | reddit_moderation | INFO | Sample 46: using best label relationship with score 0.641\n",
      "2025-08-02 16:44:31 | reddit_moderation | INFO | Sample 49: using best label regional with score 0.721\n",
      "2025-08-02 16:44:31 | reddit_moderation | INFO | Sample 52: best score 0.421 < 0.5, using fallback\n",
      "2025-08-02 16:44:31 | reddit_moderation | INFO | Sample 57: using best label niche with score 0.669\n",
      "2025-08-02 16:44:31 | reddit_moderation | INFO | Sample 61: best score 0.408 < 0.5, using fallback\n",
      "2025-08-02 16:44:31 | reddit_moderation | INFO | Sample 65: using best label advice with score 0.520\n",
      "2025-08-02 16:44:31 | reddit_moderation | INFO | Sample 72: using best label relationship with score 0.753\n",
      "2025-08-02 16:44:31 | reddit_moderation | INFO | Sample 73: using best label advice with score 0.712\n",
      "2025-08-02 16:44:31 | reddit_moderation | INFO | Sample 76: using best label creative with score 0.721\n",
      "2025-08-02 16:44:31 | reddit_moderation | INFO | Sample 87: best score 0.360 < 0.5, using fallback\n",
      "2025-08-02 16:44:31 | reddit_moderation | INFO | Sample 88: using best label adult with score 0.794\n",
      "2025-08-02 16:44:31 | reddit_moderation | INFO | Sample 95: using best label technology with score 0.529\n",
      "2025-08-02 16:44:31 | reddit_moderation | INFO | NLI prediction completed for 100 samples on column 'subreddit'\n",
      "2025-08-02 16:44:31 | reddit_moderation | INFO | Used fallback 'general or other' for 3 samples\n",
      "2025-08-02 16:44:31 | reddit_moderation | INFO | Sample predictions: ['entertainment', 'technology, science', 'politics']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d547d42ddbdf4aebaf497487865fb1da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Attach predictions:   0%|          | 0/10185 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_with_features, rule_lookup, subreddit_lookup = (\n",
    "    add_classification_preds_rule_subreddit(\n",
    "        dataset,\n",
    "        rule_vectorizer,\n",
    "        rule_vecs,\n",
    "        features,\n",
    "        subreddit_classifier,\n",
    "        subreddits,\n",
    "        logger=logger,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d592b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-02 16:44:31 | reddit_moderation | INFO | Deleted variable 'dataset'\n",
      "2025-08-02 16:44:31 | reddit_moderation | INFO | Deleted variable 'rule_vectorizer'\n",
      "2025-08-02 16:44:31 | reddit_moderation | INFO | Deleted variable 'rule_vecs'\n",
      "2025-08-02 16:44:31 | reddit_moderation | INFO | Deleted variable 'features'\n",
      "2025-08-02 16:44:31 | reddit_moderation | INFO | Deleted variable 'subreddits'\n",
      "2025-08-02 16:44:31 | reddit_moderation | INFO | Deleted variable 'subreddit_classifier'\n",
      "2025-08-02 16:44:31 | reddit_moderation | INFO | GPU memory freed: 0.00 MB\n",
      "2025-08-02 16:44:32 | reddit_moderation | INFO | RAM memory freed: 0.00 MB\n",
      "RAM freed: 0.00 MB (1888.94 -> 1888.94)\n",
      "GPU allocated freed: 0.00 MB (550.63 -> 550.63)\n",
      "GPU reserved freed: 0.00 MB (578.00 -> 578.00)\n"
     ]
    }
   ],
   "source": [
    "free_vars(\n",
    "    vars_to_delete=[\n",
    "        \"dataset\",\n",
    "        \"rule_vectorizer\",\n",
    "        \"rule_vecs\",\n",
    "        \"features\",\n",
    "        \"subreddits\",\n",
    "        \"subreddit_classifier\",\n",
    "    ],\n",
    "    namespace=globals(),\n",
    "    logger=logger,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1836719",
   "metadata": {},
   "source": [
    "# modelling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a221e77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at ../model/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer.pad_token = '<pad>' | tokenizer.eos_token = '</s>'\n"
     ]
    }
   ],
   "source": [
    "# basemodel = get_custom_roberta(MODEL_PATH[\"classifier\"])\n",
    "basemodel = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH[\"classifier\"])\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH[\"classifier\"])\n",
    "print(f\"{tokenizer.pad_token = } | {tokenizer.eos_token = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9aee5e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basemodel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a068a71e",
   "metadata": {},
   "source": [
    "## freeze and unfreeze stuff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83e630c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _freeze_module(module: nn.Module):\n",
    "    for param in module.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "\n",
    "def _unfreeze_module(module: nn.Module):\n",
    "    for param in module.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "\n",
    "def _get_layer(model, layer_idx: int):\n",
    "    \"\"\"\n",
    "    Returns one transformer block (RobertaLayer) by index.\n",
    "    layer_idx = 0 .. 23 for roberta-large\n",
    "    \"\"\"\n",
    "    return model.layer[layer_idx]\n",
    "\n",
    "\n",
    "def _cast_module(module: nn.Module, dtype: torch.dtype):\n",
    "    \"\"\"recursively casts module parameters & buffers\"\"\"\n",
    "    for p in module.parameters(recurse=False):\n",
    "        if p.dtype == torch.float32:\n",
    "            p.data = p.data.to(dtype=dtype)\n",
    "    for b in module.buffers(recurse=False):\n",
    "        if b.dtype == torch.float32:\n",
    "            b.data = b.data.to(dtype=dtype)\n",
    "    for child in module.children():\n",
    "        _cast_module(child, dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c86f20",
   "metadata": {},
   "source": [
    "## create the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed531ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-02 16:44:32 | reddit_moderation | INFO | Deleted variable 'dataset_with_features'\n",
      "2025-08-02 16:44:32 | reddit_moderation | INFO | GPU memory freed: 0.00 MB\n",
      "2025-08-02 16:44:32 | reddit_moderation | INFO | RAM memory freed: 0.00 MB\n",
      "RAM freed: 0.00 MB (1898.63 -> 1898.63)\n",
      "GPU allocated freed: 0.00 MB (8.12 -> 8.12)\n",
      "GPU reserved freed: 0.00 MB (20.00 -> 20.00)\n"
     ]
    }
   ],
   "source": [
    "dataset = dataset_with_features.to_pandas()\n",
    "free_vars([\"dataset_with_features\"], namespace=globals(), logger=logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e934445c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_prompt(row):\n",
    "    prompt = f\"\"\"Rule: {row['rule']}\n",
    "Subreddit: {row['subreddit']} ({row['predicted_subreddit_feature']})\n",
    "Content restrictions: {row['predicted_rule_feature']}\n",
    "\n",
    "Comment: \"{row['comment']}\"\n",
    "\n",
    "Question: Does this comment violate the rule?\n",
    "Answer:\"\"\"\n",
    "    return prompt\n",
    "\n",
    "\n",
    "dataset[\"prompt\"] = dataset.apply(_make_prompt, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8080429b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = train_test_split(\n",
    "    dataset,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    "    stratify=dataset[\"violation\"].astype(str) + \"-\" + dataset[\"rule\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6cc1f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tokenizer.eos_token is None:\n",
    "    print(\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e6b3bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommentDataset(data.Dataset):\n",
    "    def __init__(self, prompts, labels, tokenizer):\n",
    "        super().__init__()\n",
    "        self.prompts = prompts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.tokenizer.padding_side = \"left\"\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            if not self.tokenizer.eos_token is None:\n",
    "                self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "            else:\n",
    "                self.tokenizer.pad_token = \"[PAD]\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        encodings = self.tokenizer(\n",
    "            self.prompts[index], padding=\"max_length\", max_length=512, truncation=True\n",
    "        )\n",
    "        attention_mask = encodings[\"attention_mask\"]\n",
    "        input_ids = encodings[\"input_ids\"]\n",
    "        label = self.labels[index]\n",
    "        return (\n",
    "            torch.tensor(input_ids),\n",
    "            torch.tensor(attention_mask),\n",
    "            torch.tensor(label),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5ff2303c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CommentDataset(\n",
    "    prompts=train[\"prompt\"].tolist(),\n",
    "    labels=train[\"violation\"].tolist(),\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "val_dataset = CommentDataset(\n",
    "    prompts=val[\"prompt\"].tolist(),\n",
    "    labels=val[\"violation\"].tolist(),\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "train_dataloader = data.DataLoader(\n",
    "    train_dataset, batch_size=32, num_workers=4, pin_memory=False\n",
    ")\n",
    "val_dataloader = data.DataLoader(\n",
    "    val_dataset, batch_size=32, num_workers=4, pin_memory=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7b5c10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn.shape = torch.Size([32, 512]) | in_id.shape = torch.Size([32, 512]) | label.shape = torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "attn, in_id, label = next(iter(train_dataloader))\n",
    "print(f\"{attn.shape = } | {in_id.shape = } | {label.shape = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "968a3ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM freed: 0.00 MB (1900.61 -> 1900.61)\n",
      "GPU allocated freed: 0.00 MB (8.12 -> 8.12)\n",
      "GPU reserved freed: 0.00 MB (20.00 -> 20.00)\n"
     ]
    }
   ],
   "source": [
    "clean_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "580517b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basemodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9316516d",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "basemodel(in_id, attn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c55a15",
   "metadata": {},
   "source": [
    "## define metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4bcf1da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_averaged_auc(logits, labels):\n",
    "    \"\"\"\n",
    "    Compute AUC score for binary classification.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    logits : torch.Tensor\n",
    "        Raw model outputs of shape (batch_size, 1)\n",
    "    labels : torch.Tensor\n",
    "        Ground truth labels of shape (batch_size, 1)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        AUC score\n",
    "    \"\"\"\n",
    "    # convert to probabilities using sigmoid for binary classification\n",
    "    probs = F.sigmoid(logits).squeeze().detach().cpu().numpy()\n",
    "    labels_np = labels.squeeze().detach().cpu().numpy()\n",
    "\n",
    "    # handle edge case where all labels are same class\n",
    "    if len(set(labels_np)) == 1:\n",
    "        return 0.5\n",
    "\n",
    "    return roc_auc_score(y_true=labels_np, y_score=probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28cd2d8",
   "metadata": {},
   "source": [
    "## finetune model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7632cf70",
   "metadata": {},
   "source": [
    "first freeze the entire model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8b88e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d8908b",
   "metadata": {},
   "source": [
    "now make the custom model by adding some more layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a8505bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressLogger(Callback):  # Callback already imported\n",
    "    \"\"\"\n",
    "    Hugging-Face-style progress table that prints *once* per\n",
    "    `log_every_n_steps` and once after every validation epoch.\n",
    "\n",
    "    • Overwrites the previous table instead of appending new prints.\n",
    "    • Adds columns lazily when the metric first appears\n",
    "      → no more NaN spam.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, log_every_n_steps: int = 50):\n",
    "        super().__init__()\n",
    "        self.n = log_every_n_steps\n",
    "        self._rows: list[dict] = []  # accumulated rows\n",
    "        self._cols: list[str] = [\"step\", \"epoch\"]\n",
    "        self._last_step = -1  # to suppress duplicates\n",
    "        self._last_len = 0  # last #chars printed\n",
    "\n",
    "    # ----------------- helpers ----------------- #\n",
    "    @staticmethod\n",
    "    def _scalar(x):\n",
    "        if hasattr(x, \"detach\"):\n",
    "            x = x.detach().cpu()\n",
    "        return float(x)\n",
    "\n",
    "    def _collect(self, step: int, epoch: int, metrics: dict):\n",
    "        row = {\"step\": step, \"epoch\": epoch}\n",
    "        for k, v in metrics.items():\n",
    "            if k in {\"step\", \"epoch\"}:\n",
    "                continue\n",
    "            # add a new column the first time we see this metric\n",
    "            if k not in self._cols:\n",
    "                self._cols.append(k)\n",
    "            try:\n",
    "                row[k] = self._scalar(v)\n",
    "            except Exception:\n",
    "                pass  # skip non-scalars\n",
    "        self._rows.append(row)\n",
    "\n",
    "    def _print_table(self):\n",
    "        df = pd.DataFrame(self._rows, columns=self._cols)\n",
    "        with pd.option_context(\"display.float_format\", \"{:.5f}\".format):\n",
    "            table = df.to_string(index=False)\n",
    "\n",
    "        # wipe previous printout\n",
    "        sys.stdout.write(\"\\r\" + \" \" * self._last_len + \"\\r\")\n",
    "        sys.stdout.write(table)\n",
    "        sys.stdout.flush()\n",
    "        self._last_len = len(table)\n",
    "\n",
    "    # ---------------- Lightning hooks ---------------- #\n",
    "    def on_train_batch_end(self, trainer, pl_module, *_):\n",
    "        step = trainer.global_step\n",
    "        if step and step % self.n == 0 and step != self._last_step:\n",
    "            self._collect(step, trainer.current_epoch, trainer.callback_metrics)\n",
    "            self._print_table()\n",
    "            self._last_step = step\n",
    "\n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        step = trainer.global_step\n",
    "        if step != self._last_step:  # skip if already printed for this step\n",
    "            self._collect(step, trainer.current_epoch, trainer.callback_metrics)\n",
    "            self._print_table()\n",
    "            sys.stdout.write(\"\\n\")  # newline so checkpoint msgs start clean\n",
    "            self._last_step = step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62353004",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MlpHead(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int = 1024,\n",
    "        num_hidden_layers: int = 3,\n",
    "        num_output_classes: int = 1,\n",
    "        hidden_dim: int = 1024,\n",
    "        dropout: float = 0.2,\n",
    "        *args,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        hidden_layers = [\n",
    "            nn.Linear(in_features=input_dim, out_features=hidden_dim, bias=True),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.ReLU(),\n",
    "        ]\n",
    "        for i in range(num_hidden_layers - 1):\n",
    "            out_features = (\n",
    "                (hidden_dim // 2) if (i == (num_hidden_layers - 2)) else hidden_dim\n",
    "            )\n",
    "            layer = [\n",
    "                nn.Linear(in_features=hidden_dim, out_features=out_features, bias=True),\n",
    "                nn.Dropout(p=dropout),\n",
    "                nn.ReLU(),\n",
    "            ]\n",
    "            hidden_layers.extend(layer)\n",
    "        self.hidden_layers = nn.Sequential(*hidden_layers)\n",
    "        self.classifier_head = nn.Linear(\n",
    "            in_features=out_features, out_features=num_output_classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        hidden_layer_output = self.hidden_layers(x)\n",
    "        out = self.classifier_head(hidden_layer_output)\n",
    "        return out.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83baa03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasedRedditMod(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        basemodel,\n",
    "        num_hidden_layers: int = 3,\n",
    "        num_output_classes: int = 1,\n",
    "        hidden_dim: int = 1024,\n",
    "        lr: float = 3e-4,\n",
    "        dropout: float = 0.2,\n",
    "        model_save_path: str = \"\",\n",
    "        # scheduler parameters\n",
    "        scheduler_type: str = \"cosine_warmup\",\n",
    "        warmup_epochs: int = 2,\n",
    "        max_epochs: int = 20,\n",
    "        # step-based logging and validation\n",
    "        log_every_n_steps: int = 100,\n",
    "        val_check_interval: int = 500,\n",
    "        save_every_n_steps: int = 1000,\n",
    "        # early stopping parameters\n",
    "        early_stopping_patience: int = 3,\n",
    "        early_stopping_min_delta: float = 0.001,\n",
    "        early_stopping_monitor: str = \"val_auroc\",\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.basemodel = basemodel\n",
    "        self.lr = lr\n",
    "        self.model_save_path = model_save_path\n",
    "        self.scheduler_type = scheduler_type\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "        self.max_epochs = max_epochs\n",
    "\n",
    "        # step-based configuration\n",
    "        self.log_every_n_steps = log_every_n_steps\n",
    "        self.val_check_interval = val_check_interval\n",
    "        self.save_every_n_steps = save_every_n_steps\n",
    "\n",
    "        # freeze base model weights\n",
    "        for param in self.basemodel.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        # early stopping config\n",
    "        self.early_stopping_config = {\n",
    "            \"patience\": early_stopping_patience,\n",
    "            \"min_delta\": early_stopping_min_delta,\n",
    "            \"monitor\": early_stopping_monitor,\n",
    "        }\n",
    "\n",
    "        self.mlphead = MlpHead(\n",
    "            input_dim=basemodel.config.hidden_size,\n",
    "            num_hidden_layers=num_hidden_layers,\n",
    "            num_output_classes=num_output_classes,\n",
    "            hidden_dim=hidden_dim,\n",
    "            dropout=dropout,\n",
    "        )\n",
    "        self.loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        # epoch-based metrics\n",
    "        self.train_acc = BinaryAccuracy()\n",
    "        self.train_auroc = BinaryAUROC()\n",
    "        self.val_acc = BinaryAccuracy()\n",
    "        self.val_auroc = BinaryAUROC()\n",
    "\n",
    "        # step-based metrics for intermediate logging\n",
    "        self.train_acc_steps = BinaryAccuracy()\n",
    "        self.train_auroc_steps = BinaryAUROC()\n",
    "        self.val_acc_steps = BinaryAccuracy()\n",
    "        self.val_auroc_steps = BinaryAUROC()\n",
    "\n",
    "        # freeze, unfreeze and cast\n",
    "        _freeze_module(self.basemodel.embeddings)\n",
    "        # _cast_module(reddit_mod.basemodel.embeddings, torch.bfloat16)\n",
    "        for idx in range(0, 12 // 2):\n",
    "            _freeze_module(_get_layer(self.basemodel.encoder, idx))\n",
    "        # _cast_module(_get_layer(reddit_mod.basemodel.encoder, idx), torch.bfloat16)\n",
    "        trainable = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "        total = sum(p.numel() for p in self.parameters())\n",
    "        print(\n",
    "            f\"Trainable params: {trainable/1e6:.1f} M  /  Total params: {total/1e6:.1f} M\"\n",
    "        )\n",
    "        # _cast_module(self, torch.bfloat16)\n",
    "\n",
    "    def get_callbacks(self):\n",
    "        \"\"\"\n",
    "        Create all necessary callbacks for training.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list\n",
    "            List of configured PyTorch Lightning callbacks\n",
    "        \"\"\"\n",
    "        callbacks = []\n",
    "\n",
    "        # early stopping callback\n",
    "        early_stop = EarlyStopping(\n",
    "            monitor=self.early_stopping_config[\"monitor\"],\n",
    "            patience=self.early_stopping_config[\"patience\"],\n",
    "            min_delta=self.early_stopping_config[\"min_delta\"],\n",
    "            mode=\"max\",\n",
    "            verbose=True,\n",
    "            strict=True,\n",
    "        )\n",
    "        callbacks.append(early_stop)\n",
    "\n",
    "        # step-based checkpoint callback\n",
    "        step_checkpoint = ModelCheckpoint(\n",
    "            dirpath=f\"{self.model_save_path}/step_checkpoints/\",\n",
    "            filename=\"model-step-{step:06d}-{val_auroc:.4f}\",\n",
    "            every_n_train_steps=self.save_every_n_steps,\n",
    "            save_top_k=3,\n",
    "            monitor=self.early_stopping_config[\"monitor\"],\n",
    "            mode=\"max\",\n",
    "            save_last=True,\n",
    "            verbose=True,\n",
    "        )\n",
    "        callbacks.append(step_checkpoint)\n",
    "\n",
    "        # epoch-based checkpoint callback (best model)\n",
    "        epoch_checkpoint = ModelCheckpoint(\n",
    "            dirpath=f\"{self.model_save_path}/epoch_checkpoints/\",\n",
    "            filename=\"best-model-{epoch:02d}-{val_auroc:.4f}\",\n",
    "            monitor=self.early_stopping_config[\"monitor\"],\n",
    "            mode=\"max\",\n",
    "            save_top_k=1,\n",
    "            save_last=False,\n",
    "            verbose=True,\n",
    "        )\n",
    "        callbacks.append(epoch_checkpoint)\n",
    "\n",
    "        return callbacks\n",
    "\n",
    "    def load_best_model(self, checkpoint_dir: str = None):\n",
    "        \"\"\"\n",
    "        Load the best model checkpoint based on validation metrics.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        checkpoint_dir : str, optional\n",
    "            Directory containing checkpoints. If None, uses model_save_path\n",
    "        \"\"\"\n",
    "        import glob\n",
    "        import os\n",
    "\n",
    "        if checkpoint_dir is None:\n",
    "            checkpoint_dir = f\"{self.model_save_path}/epoch_checkpoints/\"\n",
    "\n",
    "        # find best checkpoint file\n",
    "        checkpoint_files = glob.glob(os.path.join(checkpoint_dir, \"best-model-*.ckpt\"))\n",
    "\n",
    "        if not checkpoint_files:\n",
    "            print(\"No best model checkpoint found\")\n",
    "            return\n",
    "\n",
    "        # load the best checkpoint (should be only one due to save_top_k=1)\n",
    "        best_checkpoint = checkpoint_files[0]\n",
    "        print(f\"Loading best model from: {best_checkpoint}\")\n",
    "\n",
    "        # load state dict\n",
    "        checkpoint = torch.load(best_checkpoint, map_location=self.device)\n",
    "        self.load_state_dict(checkpoint[\"state_dict\"])\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # base model forward pass (frozen)\n",
    "        with torch.no_grad():\n",
    "            pooled = self.basemodel(\n",
    "                input_ids=input_ids, attention_mask=attention_mask\n",
    "            ).pooler_output\n",
    "        return self.mlphead(pooled).unsqueeze(1)\n",
    "\n",
    "    def training_step(self, batch, batch_idx, *args, **kwargs):\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        logits = self(input_ids, attention_mask)\n",
    "\n",
    "        # ensure correct dtypes and shapes for bce loss\n",
    "        labels_float = labels.float().unsqueeze(1)\n",
    "        loss = self.loss_fn(logits, labels_float)\n",
    "\n",
    "        # compute probabilities for metrics\n",
    "        probs = torch.sigmoid(logits)\n",
    "        labels_int = labels_float.int()\n",
    "\n",
    "        # update epoch-based metrics\n",
    "        self.train_acc.update(probs, labels_int)\n",
    "        self.train_auroc.update(probs, labels_int)\n",
    "\n",
    "        # update step-based metrics\n",
    "        self.train_acc_steps.update(probs, labels_int)\n",
    "        self.train_auroc_steps.update(probs, labels_int)\n",
    "\n",
    "        # always log loss\n",
    "        self.log(\"train_loss\", loss, on_step=True, prog_bar=True)\n",
    "\n",
    "        # step-based metric logging\n",
    "        if self.global_step % self.log_every_n_steps == 0:\n",
    "            self._log_step_metrics(is_train=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx, *args, **kwargs):\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        logits = self(input_ids, attention_mask)\n",
    "\n",
    "        # ensure correct dtypes and shapes for bce loss\n",
    "        labels_float = labels.float().unsqueeze(1)\n",
    "        loss = self.loss_fn(logits, labels_float)\n",
    "\n",
    "        # compute probabilities for metrics\n",
    "        probs = torch.sigmoid(logits)\n",
    "        labels_int = labels_float.int()\n",
    "\n",
    "        # update epoch-based metrics\n",
    "        self.val_acc.update(probs, labels_int)\n",
    "        self.val_auroc.update(probs, labels_int)\n",
    "\n",
    "        # update step-based metrics\n",
    "        self.val_acc_steps.update(probs, labels_int)\n",
    "        self.val_auroc_steps.update(probs, labels_int)\n",
    "\n",
    "        # log validation loss\n",
    "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def _log_step_metrics(self, is_train=True):\n",
    "        \"\"\"Log metrics at specified step intervals.\"\"\"\n",
    "        prefix = \"train\" if is_train else \"val\"\n",
    "        acc_metric = self.train_acc_steps if is_train else self.val_acc_steps\n",
    "        auroc_metric = self.train_auroc_steps if is_train else self.val_auroc_steps\n",
    "\n",
    "        # compute step-based metrics\n",
    "        acc_score = acc_metric.compute()\n",
    "        auroc_score = auroc_metric.compute()\n",
    "\n",
    "        # log step metrics\n",
    "        self.log(f\"{prefix}_acc_steps\", acc_score, on_step=True, prog_bar=True)\n",
    "        self.log(f\"{prefix}_auroc_steps\", auroc_score, on_step=True, prog_bar=True)\n",
    "        self.log(\"global_step\", float(self.global_step), on_step=True)\n",
    "\n",
    "        # reset step metrics for next window\n",
    "        acc_metric.reset()\n",
    "        auroc_metric.reset()\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        \"\"\"Compute and log epoch-aggregated validation metrics.\"\"\"\n",
    "        # compute epoch metrics\n",
    "        val_acc_epoch = self.val_acc.compute()\n",
    "        val_auroc_epoch = self.val_auroc.compute()\n",
    "\n",
    "        # log epoch metrics\n",
    "        self.log(\"val_acc\", val_acc_epoch, prog_bar=True)\n",
    "        self.log(\"val_auroc\", val_auroc_epoch, prog_bar=True)\n",
    "\n",
    "        # reset metrics for next epoch\n",
    "        self.val_acc.reset()\n",
    "        self.val_auroc.reset()\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        \"\"\"Compute and log epoch-aggregated training metrics.\"\"\"\n",
    "        # compute epoch metrics\n",
    "        train_acc_epoch = self.train_acc.compute()\n",
    "        train_auroc_epoch = self.train_auroc.compute()\n",
    "\n",
    "        # log epoch metrics\n",
    "        self.log(\"train_acc\", train_acc_epoch, prog_bar=True)\n",
    "        self.log(\"train_auroc\", train_auroc_epoch, prog_bar=True)\n",
    "\n",
    "        # reset metrics for next epoch\n",
    "        self.train_acc.reset()\n",
    "        self.train_auroc.reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Configure optimizer and learning rate scheduler.\"\"\"\n",
    "        # optimizer setup - only optimize mlp head parameters\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            self.parameters(),\n",
    "            lr=self.lr,\n",
    "            betas=(0.9, 0.98),\n",
    "            eps=1e-6,\n",
    "            weight_decay=0.1,\n",
    "        )\n",
    "\n",
    "        if self.scheduler_type == \"cosine_warmup\":\n",
    "            return self._configure_cosine_warmup_scheduler(optimizer)\n",
    "        elif self.scheduler_type == \"linear_warmup\":\n",
    "            return self._configure_linear_warmup_scheduler(optimizer)\n",
    "        else:\n",
    "            return optimizer\n",
    "\n",
    "    def _configure_cosine_warmup_scheduler(self, optimizer):\n",
    "        \"\"\"Configure cosine annealing scheduler with warmup.\"\"\"\n",
    "        warmup_steps = self.warmup_epochs\n",
    "        total_steps = self.max_epochs\n",
    "\n",
    "        # warmup scheduler\n",
    "        warmup_scheduler = LinearLR(\n",
    "            optimizer, start_factor=0.01, total_iters=warmup_steps\n",
    "        )\n",
    "\n",
    "        # cosine annealing scheduler\n",
    "        cosine_scheduler = CosineAnnealingLR(\n",
    "            optimizer, T_max=total_steps - warmup_steps, eta_min=self.lr * 0.01\n",
    "        )\n",
    "\n",
    "        # combine warmup + cosine\n",
    "        scheduler = SequentialLR(\n",
    "            optimizer,\n",
    "            schedulers=[warmup_scheduler, cosine_scheduler],\n",
    "            milestones=[warmup_steps],\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"interval\": \"epoch\",\n",
    "                \"frequency\": 1,\n",
    "                \"monitor\": \"val_auroc\",\n",
    "            },\n",
    "        }\n",
    "\n",
    "    def _configure_linear_warmup_scheduler(self, optimizer):\n",
    "        \"\"\"Configure linear decay scheduler with warmup.\"\"\"\n",
    "        warmup_steps = self.warmup_epochs\n",
    "        total_steps = self.max_epochs\n",
    "\n",
    "        # warmup scheduler\n",
    "        warmup_scheduler = LinearLR(\n",
    "            optimizer, start_factor=0.01, total_iters=warmup_steps\n",
    "        )\n",
    "\n",
    "        # linear decay scheduler\n",
    "        decay_scheduler = LinearLR(\n",
    "            optimizer,\n",
    "            start_factor=1.0,\n",
    "            end_factor=0.01,\n",
    "            total_iters=total_steps - warmup_steps,\n",
    "        )\n",
    "\n",
    "        # combine warmup + decay\n",
    "        scheduler = SequentialLR(\n",
    "            optimizer,\n",
    "            schedulers=[warmup_scheduler, decay_scheduler],\n",
    "            milestones=[warmup_steps],\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"optimizer\": optimizer,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"interval\": \"epoch\",\n",
    "                \"frequency\": 1,\n",
    "                \"monitor\": \"val_auroc\",\n",
    "            },\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eff35b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 45.5 M  /  Total params: 127.0 M\n"
     ]
    }
   ],
   "source": [
    "reddit_mod = BasedRedditMod(\n",
    "    basemodel=basemodel,\n",
    "    lr=2e-6,\n",
    "    scheduler_type=\"cosine_warmup\",\n",
    "    warmup_epochs=1,\n",
    "    max_epochs=5,\n",
    "    model_save_path=\"./training_outputs\",\n",
    "    # step-based configuration\n",
    "    log_every_n_steps=len(train_dataloader) // 8,\n",
    "    val_check_interval=len(train_dataloader) // 4,\n",
    "    save_every_n_steps=len(train_dataloader) // 4,\n",
    "    # early stopping\n",
    "    early_stopping_patience=5,\n",
    "    early_stopping_monitor=\"val_auroc\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1d612759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasedRedditMod(\n",
       "  (basemodel): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): RobertaPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (mlphead): MlpHead(\n",
       "    (hidden_layers): Sequential(\n",
       "      (0): Linear(in_features=768, out_features=1024, bias=True)\n",
       "      (1): Dropout(p=0.2, inplace=False)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (4): Dropout(p=0.2, inplace=False)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=1024, out_features=512, bias=True)\n",
       "      (7): Dropout(p=0.2, inplace=False)\n",
       "      (8): ReLU()\n",
       "    )\n",
       "    (classifier_head): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       "  (loss_fn): BCEWithLogitsLoss()\n",
       "  (train_acc): BinaryAccuracy()\n",
       "  (train_auroc): BinaryAUROC()\n",
       "  (val_acc): BinaryAccuracy()\n",
       "  (val_auroc): BinaryAUROC()\n",
       "  (train_acc_steps): BinaryAccuracy()\n",
       "  (train_auroc_steps): BinaryAUROC()\n",
       "  (val_acc_steps): BinaryAccuracy()\n",
       "  (val_auroc_steps): BinaryAUROC()\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1523eaa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [15,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [15,0,0], thread: [1,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [15,0,0], thread: [2,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [15,0,0], thread: [3,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [15,0,0], thread: [4,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [15,0,0], thread: [5,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [15,0,0], thread: [6,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [15,0,0], thread: [7,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [15,0,0], thread: [8,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [15,0,0], thread: [9,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [15,0,0], thread: [10,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [15,0,0], thread: [11,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [15,0,0], thread: [12,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [15,0,0], thread: [13,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [15,0,0], thread: [14,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [15,0,0], thread: [15,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [15,0,0], thread: [16,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [15,0,0], thread: [17,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [15,0,0], thread: [18,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [15,0,0], thread: [19,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [15,0,0], thread: [20,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [15,0,0], thread: [21,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [15,0,0], thread: [22,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [15,0,0], thread: [23,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [15,0,0], thread: [24,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [15,0,0], thread: [25,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [15,0,0], thread: [26,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [15,0,0], thread: [27,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [15,0,0], thread: [28,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [15,0,0], thread: [29,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [15,0,0], thread: [30,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [15,0,0], thread: [31,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [16,0,0], thread: [64,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [16,0,0], thread: [65,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [16,0,0], thread: [66,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [16,0,0], thread: [67,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [16,0,0], thread: [68,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [16,0,0], thread: [69,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [16,0,0], thread: [70,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [16,0,0], thread: [71,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [16,0,0], thread: [72,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [16,0,0], thread: [73,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [16,0,0], thread: [74,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [16,0,0], thread: [75,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [16,0,0], thread: [76,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [16,0,0], thread: [77,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [16,0,0], thread: [78,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [16,0,0], thread: [79,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [16,0,0], thread: [80,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [16,0,0], thread: [81,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [16,0,0], thread: [82,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [16,0,0], thread: [83,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [16,0,0], thread: [84,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [16,0,0], thread: [85,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [16,0,0], thread: [86,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [16,0,0], thread: [87,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [16,0,0], thread: [88,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [16,0,0], thread: [89,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [16,0,0], thread: [90,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [16,0,0], thread: [91,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [16,0,0], thread: [92,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [16,0,0], thread: [93,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [16,0,0], thread: [94,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/Indexing.cu:1553: indexSelectLargeIndex: block: [16,0,0], thread: [95,0,0] Assertion `srcIndex < srcSelectDimSize` failed.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run torchinfo. See above stack traces for more details. Executed layers up to: [RobertaEmbeddings: 2, Embedding: 3, Embedding: 3, Embedding: 3, LayerNorm: 3, Dropout: 3]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/diffusion/lib/python3.11/site-packages/torchinfo/torchinfo.py:295\u001b[39m, in \u001b[36mforward_pass\u001b[39m\u001b[34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[39m\n\u001b[32m    294\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m     _ = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/diffusion/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/diffusion/lib/python3.11/site-packages/torch/nn/modules/module.py:1857\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1856\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1857\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1858\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1859\u001b[39m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[32m   1860\u001b[39m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[32m   1861\u001b[39m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/diffusion/lib/python3.11/site-packages/torch/nn/modules/module.py:1805\u001b[39m, in \u001b[36mModule._call_impl.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1803\u001b[39m     args = bw_hook.setup_input_hook(args)\n\u001b[32m-> \u001b[39m\u001b[32m1805\u001b[39m result = \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1806\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 167\u001b[39m, in \u001b[36mBasedRedditMod.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask)\u001b[39m\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     pooled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbasemodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m.pooler_output\n\u001b[32m    170\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mlphead(pooled).unsqueeze(\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/diffusion/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/diffusion/lib/python3.11/site-packages/torch/nn/modules/module.py:1857\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1856\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1857\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1858\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1859\u001b[39m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[32m   1860\u001b[39m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[32m   1861\u001b[39m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/diffusion/lib/python3.11/site-packages/torch/nn/modules/module.py:1805\u001b[39m, in \u001b[36mModule._call_impl.<locals>.inner\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m   1803\u001b[39m     args = bw_hook.setup_input_hook(args)\n\u001b[32m-> \u001b[39m\u001b[32m1805\u001b[39m result = \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1806\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/diffusion/lib/python3.11/site-packages/transformers/models/roberta/modeling_roberta.py:944\u001b[39m, in \u001b[36mRobertaModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    943\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m944\u001b[39m         extended_attention_mask = \u001b[43m_prepare_4d_attention_mask_for_sdpa\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_len\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseq_length\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    948\u001b[39m     \u001b[38;5;66;03m# We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]\u001b[39;00m\n\u001b[32m    949\u001b[39m     \u001b[38;5;66;03m# ourselves in which case we just need to make it broadcastable to all heads.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/diffusion/lib/python3.11/site-packages/transformers/modeling_attn_mask_utils.py:448\u001b[39m, in \u001b[36m_prepare_4d_attention_mask_for_sdpa\u001b[39m\u001b[34m(mask, dtype, tgt_len)\u001b[39m\n\u001b[32m    447\u001b[39m \u001b[38;5;66;03m# torch.jit.trace, symbolic_trace and torchdynamo with fullgraph=True are unable to capture data-dependent controlflows.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m448\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tracing \u001b[38;5;129;01mand\u001b[39;00m torch.all(mask == \u001b[32m1\u001b[39m):\n\u001b[32m    449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# create model with learning rate scheduling\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# get existing callbacks\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     \u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreddit_mod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m514\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtypes\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlong\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlong\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcol_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# \"input_size\",\u001b[39;49;00m\n\u001b[32m     12\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutput_size\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnum_params\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrainable\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# include trainable_params column\u001b[39;49;00m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/diffusion/lib/python3.11/site-packages/torchinfo/torchinfo.py:223\u001b[39m, in \u001b[36msummary\u001b[39m\u001b[34m(model, input_size, input_data, batch_dim, cache_forward_pass, col_names, col_width, depth, device, dtypes, mode, row_settings, verbose, **kwargs)\u001b[39m\n\u001b[32m    216\u001b[39m validate_user_params(\n\u001b[32m    217\u001b[39m     input_data, input_size, columns, col_width, device, dtypes, verbose\n\u001b[32m    218\u001b[39m )\n\u001b[32m    220\u001b[39m x, correct_input_size = process_input(\n\u001b[32m    221\u001b[39m     input_data, input_size, batch_dim, device, dtypes\n\u001b[32m    222\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m223\u001b[39m summary_list = \u001b[43mforward_pass\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_forward_pass\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    226\u001b[39m formatting = FormattingOptions(depth, verbose, columns, col_width, rows)\n\u001b[32m    227\u001b[39m results = ModelStatistics(\n\u001b[32m    228\u001b[39m     summary_list, correct_input_size, get_total_memory_used(x), formatting\n\u001b[32m    229\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/diffusion/lib/python3.11/site-packages/torchinfo/torchinfo.py:304\u001b[39m, in \u001b[36mforward_pass\u001b[39m\u001b[34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[39m\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    303\u001b[39m     executed_layers = [layer \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m summary_list \u001b[38;5;28;01mif\u001b[39;00m layer.executed]\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    305\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFailed to run torchinfo. See above stack traces for more details. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    306\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExecuted layers up to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexecuted_layers\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    307\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    308\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    309\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m hooks:\n",
      "\u001b[31mRuntimeError\u001b[39m: Failed to run torchinfo. See above stack traces for more details. Executed layers up to: [RobertaEmbeddings: 2, Embedding: 3, Embedding: 3, Embedding: 3, LayerNorm: 3, Dropout: 3]"
     ]
    }
   ],
   "source": [
    "# create model with learning rate scheduling\n",
    "# get existing callbacks\n",
    "\n",
    "\n",
    "print(\n",
    "    summary(\n",
    "        reddit_mod,\n",
    "        input_size=[(64, 514)] * 2,\n",
    "        dtypes=[torch.long, torch.long],\n",
    "        col_names=[\n",
    "            # \"input_size\",\n",
    "            \"output_size\",\n",
    "            \"num_params\",\n",
    "            \"trainable\",\n",
    "        ],  # include trainable_params column\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fee4624a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mclean_mem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/kaggle-competitions/jigsaw-comments/src/utils/management.py:68\u001b[39m, in \u001b[36mclean_mem\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# do a garbage collection and flush cuda cache\u001b[39;00m\n\u001b[32m     67\u001b[39m gc.collect()\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m.\u001b[49m\u001b[43mempty_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[38;5;66;03m# Give system a small moment to settle (helps RAM measurement be more accurate)\u001b[39;00m\n\u001b[32m     71\u001b[39m time.sleep(\u001b[32m0.1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/diffusion/lib/python3.11/site-packages/torch/cuda/memory.py:222\u001b[39m, in \u001b[36mempty_cache\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    211\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Release all unoccupied cached memory currently held by the caching\u001b[39;00m\n\u001b[32m    212\u001b[39m \u001b[33;03mallocator so that those can be used in other GPU application and visible in\u001b[39;00m\n\u001b[32m    213\u001b[39m \u001b[33;03m`nvidia-smi`.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    219\u001b[39m \u001b[33;03m    more details about GPU memory management.\u001b[39;00m\n\u001b[32m    220\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    221\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_cuda_emptyCache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "clean_mem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "69c25975",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "callbacks = reddit_mod.get_callbacks()\n",
    "\n",
    "# add HF-style progress bar\n",
    "# hf_progress = HuggingFaceStyleProgressBar()\n",
    "progress = ProgressLogger(log_every_n_steps=reddit_mod.log_every_n_steps)\n",
    "callbacks.append(progress)\n",
    "trainer = L.Trainer(\n",
    "    callbacks=callbacks,\n",
    "    accelerator=\"gpu\",\n",
    "    max_epochs=reddit_mod.max_epochs,\n",
    "    # step-based logging configuration\n",
    "    log_every_n_steps=reddit_mod.log_every_n_steps,\n",
    "    # step-based validation configuration\n",
    "    val_check_interval=reddit_mod.val_check_interval,\n",
    "    # enable checkpointing\n",
    "    enable_checkpointing=True,\n",
    "    # enable progress bar for step tracking\n",
    "    enable_progress_bar=True,\n",
    "    precision=16,\n",
    "    gradient_clip_val=1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d0f5289",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 4060 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name              | Type              | Params | Mode \n",
      "-----------------------------------------------------------------\n",
      "0  | basemodel         | RobertaModel      | 124 M  | train\n",
      "1  | mlphead           | MlpHead           | 2.4 M  | train\n",
      "2  | loss_fn           | BCEWithLogitsLoss | 0      | train\n",
      "3  | train_acc         | BinaryAccuracy    | 0      | train\n",
      "4  | train_auroc       | BinaryAUROC       | 0      | train\n",
      "5  | val_acc           | BinaryAccuracy    | 0      | train\n",
      "6  | val_auroc         | BinaryAUROC       | 0      | train\n",
      "7  | train_acc_steps   | BinaryAccuracy    | 0      | train\n",
      "8  | train_auroc_steps | BinaryAUROC       | 0      | train\n",
      "9  | val_acc_steps     | BinaryAccuracy    | 0      | train\n",
      "10 | val_auroc_steps   | BinaryAUROC       | 0      | train\n",
      "-----------------------------------------------------------------\n",
      "45.5 M    Trainable params\n",
      "81.5 M    Non-trainable params\n",
      "127 M     Total params\n",
      "508.032   Total estimated model params size (MB)\n",
      "249       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac8331c8c12f46b5b5aca426958c4e43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (2048) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [64, 2048].  Tensor sizes: [1, 514]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreddit_mod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/diffusion/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:561\u001b[39m, in \u001b[36mTrainer.fit\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    559\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    560\u001b[39m \u001b[38;5;28mself\u001b[39m.should_stop = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m561\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/diffusion/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:48\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     46\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m trainer.strategy.launcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     47\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[32m     51\u001b[39m     _call_teardown_hook(trainer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/diffusion/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:599\u001b[39m, in \u001b[36mTrainer._fit_impl\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    592\u001b[39m     download_model_from_registry(ckpt_path, \u001b[38;5;28mself\u001b[39m)\n\u001b[32m    593\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    594\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn,\n\u001b[32m    595\u001b[39m     ckpt_path,\n\u001b[32m    596\u001b[39m     model_provided=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    597\u001b[39m     model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    598\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.stopped\n\u001b[32m    602\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/diffusion/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:1012\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path)\u001b[39m\n\u001b[32m   1007\u001b[39m \u001b[38;5;28mself\u001b[39m._signal_connector.register_signal_handlers()\n\u001b[32m   1009\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1010\u001b[39m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[32m   1011\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1012\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1015\u001b[39m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[32m   1016\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1017\u001b[39m log.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: trainer tearing down\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/diffusion/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:1054\u001b[39m, in \u001b[36mTrainer._run_stage\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1052\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.training:\n\u001b[32m   1053\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[32m-> \u001b[39m\u001b[32m1054\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1055\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.autograd.set_detect_anomaly(\u001b[38;5;28mself\u001b[39m._detect_anomaly):\n\u001b[32m   1056\u001b[39m         \u001b[38;5;28mself\u001b[39m.fit_loop.run()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/diffusion/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:1083\u001b[39m, in \u001b[36mTrainer._run_sanity_check\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1080\u001b[39m call._call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mon_sanity_check_start\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1082\u001b[39m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1083\u001b[39m \u001b[43mval_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1085\u001b[39m call._call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mon_sanity_check_end\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1087\u001b[39m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/diffusion/lib/python3.11/site-packages/lightning/pytorch/loops/utilities.py:179\u001b[39m, in \u001b[36m_no_grad_context.<locals>._decorator\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    177\u001b[39m     context_manager = torch.no_grad\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/diffusion/lib/python3.11/site-packages/lightning/pytorch/loops/evaluation_loop.py:145\u001b[39m, in \u001b[36m_EvaluationLoop.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    143\u001b[39m     \u001b[38;5;28mself\u001b[39m.batch_progress.is_last_batch = data_fetcher.done\n\u001b[32m    144\u001b[39m     \u001b[38;5;66;03m# run step hooks\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_evaluation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m    147\u001b[39m     \u001b[38;5;66;03m# this needs to wrap the `*_step` call too (not just `next`) for `dataloader_iter` support\u001b[39;00m\n\u001b[32m    148\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/diffusion/lib/python3.11/site-packages/lightning/pytorch/loops/evaluation_loop.py:437\u001b[39m, in \u001b[36m_EvaluationLoop._evaluation_step\u001b[39m\u001b[34m(self, batch, batch_idx, dataloader_idx, dataloader_iter)\u001b[39m\n\u001b[32m    431\u001b[39m hook_name = \u001b[33m\"\u001b[39m\u001b[33mtest_step\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer.testing \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mvalidation_step\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    432\u001b[39m step_args = (\n\u001b[32m    433\u001b[39m     \u001b[38;5;28mself\u001b[39m._build_step_args_from_hook_kwargs(hook_kwargs, hook_name)\n\u001b[32m    434\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_dataloader_iter\n\u001b[32m    435\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m (dataloader_iter,)\n\u001b[32m    436\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m437\u001b[39m output = \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mstep_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[38;5;28mself\u001b[39m.batch_progress.increment_processed()\n\u001b[32m    441\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m using_dataloader_iter:\n\u001b[32m    442\u001b[39m     \u001b[38;5;66;03m# update the hook kwargs now that the step method might have consumed the iterator\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/diffusion/lib/python3.11/site-packages/lightning/pytorch/trainer/call.py:328\u001b[39m, in \u001b[36m_call_strategy_hook\u001b[39m\u001b[34m(trainer, hook_name, *args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m trainer.profiler.profile(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer.strategy.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     output = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[32m    331\u001b[39m pl_module._current_fx_name = prev_fx_name\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/diffusion/lib/python3.11/site-packages/lightning/pytorch/strategies/strategy.py:412\u001b[39m, in \u001b[36mStrategy.validation_step\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    410\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model != \u001b[38;5;28mself\u001b[39m.lightning_module:\n\u001b[32m    411\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_redirection(\u001b[38;5;28mself\u001b[39m.model, \u001b[38;5;28mself\u001b[39m.lightning_module, \u001b[33m\"\u001b[39m\u001b[33mvalidation_step\u001b[39m\u001b[33m\"\u001b[39m, *args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m412\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlightning_module\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 203\u001b[39m, in \u001b[36mBasedRedditMod.validation_step\u001b[39m\u001b[34m(self, batch, batch_idx, *args, **kwargs)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvalidation_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, batch_idx, *args, **kwargs):\n\u001b[32m    202\u001b[39m     input_ids, attention_mask, labels = batch\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     logits = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    205\u001b[39m     \u001b[38;5;66;03m# ensure correct dtypes and shapes for bce loss\u001b[39;00m\n\u001b[32m    206\u001b[39m     labels_float = labels.float().unsqueeze(\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/diffusion/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/diffusion/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 167\u001b[39m, in \u001b[36mBasedRedditMod.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask)\u001b[39m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids, attention_mask):\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# base model forward pass (frozen)\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m         pooled = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbasemodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m            \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.pooler_output\n\u001b[32m    170\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mlphead(pooled).unsqueeze(\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/diffusion/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/diffusion/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/diffusion/lib/python3.11/site-packages/transformers/models/roberta/modeling_roberta.py:909\u001b[39m, in \u001b[36mRobertaModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    907\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.embeddings, \u001b[33m\"\u001b[39m\u001b[33mtoken_type_ids\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    908\u001b[39m     buffered_token_type_ids = \u001b[38;5;28mself\u001b[39m.embeddings.token_type_ids[:, :seq_length]\n\u001b[32m--> \u001b[39m\u001b[32m909\u001b[39m     buffered_token_type_ids_expanded = \u001b[43mbuffered_token_type_ids\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    910\u001b[39m     token_type_ids = buffered_token_type_ids_expanded\n\u001b[32m    911\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mRuntimeError\u001b[39m: The expanded size of the tensor (2048) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [64, 2048].  Tensor sizes: [1, 514]"
     ]
    }
   ],
   "source": [
    "trainer.fit(reddit_mod, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787a833c",
   "metadata": {},
   "source": [
    "# generate predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524d8441",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
