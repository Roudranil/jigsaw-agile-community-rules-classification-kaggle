{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T10:58:17.064143Z",
     "iopub.status.busy": "2025-08-14T10:58:17.063315Z",
     "iopub.status.idle": "2025-08-14T10:58:17.067741Z",
     "shell.execute_reply": "2025-08-14T10:58:17.066846Z",
     "shell.execute_reply.started": "2025-08-14T10:58:17.064117Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import wandb\n",
    "\n",
    "# wandb.init(mode=\"disabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T10:58:17.069134Z",
     "iopub.status.busy": "2025-08-14T10:58:17.068947Z",
     "iopub.status.idle": "2025-08-14T10:58:17.086310Z",
     "shell.execute_reply": "2025-08-14T10:58:17.085415Z",
     "shell.execute_reply.started": "2025-08-14T10:58:17.069120Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from typing import List, Literal, Union\n",
    "\n",
    "import lightning as L\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from lightning.pytorch import callbacks as lcb\n",
    "from scipy.special import softmax\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn, optim, utils\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torchmetrics.classification import BinaryAccuracy, BinaryAUROC, BinaryF1Score\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    RobertaConfig,\n",
    "    RobertaForSequenceClassification,\n",
    "    RobertaPreTrainedModel,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ON_KAGGLE = all(os.path.exists(p) for p in [\"/kaggle/working\", \"/kaggle/input\"])\n",
    "\n",
    "if ON_KAGGLE:\n",
    "    INPUT_PATH = os.path.join(\"/\", \"kaggle\", \"input\")\n",
    "    OUTPUT_PATH = os.path.join(\"/\", \"kaggle\", \"working\")\n",
    "    _MODEL_VERSION_PATH = os.path.join(\n",
    "        \"transformers\",\n",
    "        \"default\",\n",
    "        \"1\",\n",
    "    )\n",
    "    _MODEL_DIR = os.path.join(\"/\", \"kaggle\", \"input\")\n",
    "    MODEL_PATH = {\n",
    "        \"classifier\": os.path.join(_MODEL_DIR, \"roberta-base\", _MODEL_VERSION_PATH),\n",
    "    }\n",
    "else:\n",
    "    INPUT_PATH = os.path.join(\"..\", \"data\")\n",
    "    OUTPUT_PATH = os.path.join(\".\", \"rulewise-output\")\n",
    "    os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "    _MODEL_DIR = os.path.join(\"..\", \"model\")\n",
    "    MODEL_PATH = {\n",
    "        \"classifier\": \"FacebookAI/roberta-base\",\n",
    "    }\n",
    "\n",
    "TRY_PROBABILITY_CALIBRATION = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T10:58:17.087425Z",
     "iopub.status.busy": "2025-08-14T10:58:17.087104Z",
     "iopub.status.idle": "2025-08-14T10:58:17.103739Z",
     "shell.execute_reply": "2025-08-14T10:58:17.102938Z",
     "shell.execute_reply.started": "2025-08-14T10:58:17.087402Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T10:58:17.184088Z",
     "iopub.status.busy": "2025-08-14T10:58:17.183862Z",
     "iopub.status.idle": "2025-08-14T10:58:17.213800Z",
     "shell.execute_reply": "2025-08-14T10:58:17.213090Z",
     "shell.execute_reply.started": "2025-08-14T10:58:17.184072Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import inspect\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import List, Optional, Union\n",
    "\n",
    "import psutil\n",
    "import torch\n",
    "\n",
    "\n",
    "def clean_mem():\n",
    "    # import gc\n",
    "    # import os\n",
    "    # import sys\n",
    "    # import time\n",
    "    # import traceback\n",
    "\n",
    "    # import psutil\n",
    "    # import torch\n",
    "\n",
    "    process = psutil.Process(os.getpid())\n",
    "\n",
    "    # Measure RAM before cleanup\n",
    "    ram_before = process.memory_info().rss / (1024**2)  # in MB\n",
    "\n",
    "    # Measure GPU before cleanup\n",
    "    if torch.cuda.is_available():\n",
    "        gpu_alloc_before = torch.cuda.memory_allocated() / (1024**2)  # in MB\n",
    "        gpu_reserved_before = torch.cuda.memory_reserved() / (1024**2)  # in MB\n",
    "    else:\n",
    "        gpu_alloc_before = gpu_reserved_before = 0\n",
    "\n",
    "    # clean all traceback\n",
    "    if hasattr(sys, \"last_traceback\"):\n",
    "        traceback.clear_frames(sys.last_traceback)\n",
    "        delattr(sys, \"last_traceback\")\n",
    "    if hasattr(sys, \"last_type\"):\n",
    "        delattr(sys, \"last_type\")\n",
    "    if hasattr(sys, \"last_value\"):\n",
    "        delattr(sys, \"last_value\")\n",
    "\n",
    "    # clean all ipython history\n",
    "    if \"get_ipython\" in globals():\n",
    "        try:\n",
    "            from IPython import get_ipython\n",
    "\n",
    "            ip = get_ipython()\n",
    "            user_ns = ip.user_ns\n",
    "            ip.displayhook.flush()\n",
    "            pc = ip.displayhook.prompt_count + 1\n",
    "            for n in range(1, pc):\n",
    "                user_ns.pop(\"_i\" + repr(n), None)\n",
    "            user_ns.update(dict(_i=\"\", _ii=\"\", _iii=\"\"))\n",
    "            hm = ip.history_manager\n",
    "            hm.input_hist_parsed[:] = [\"\"] * pc\n",
    "            hm.input_hist_raw[:] = [\"\"] * pc\n",
    "            hm._i = hm._ii = hm._iii = hm._i00 = \"\"\n",
    "        except Exception as e:\n",
    "            print(\"ipython mem could not be cleared\")\n",
    "\n",
    "    # do a garbage collection and flush cuda cache\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Give system a small moment to settle (helps RAM measurement be more accurate)\n",
    "    time.sleep(0.1)\n",
    "\n",
    "    # Measure RAM after cleanup\n",
    "    ram_after = process.memory_info().rss / (1024**2)  # in MB\n",
    "\n",
    "    # Measure GPU after cleanup\n",
    "    if torch.cuda.is_available():\n",
    "        gpu_alloc_after = torch.cuda.memory_allocated() / (1024**2)  # in MB\n",
    "        gpu_reserved_after = torch.cuda.memory_reserved() / (1024**2)  # in MB\n",
    "    else:\n",
    "        gpu_alloc_after = gpu_reserved_after = 0\n",
    "\n",
    "    # Report freed memory\n",
    "    print(\n",
    "        f\"RAM freed: {ram_before - ram_after:.2f} MB ({ram_before:.2f} -> {ram_after:.2f})\"\n",
    "    )\n",
    "    if torch.cuda.is_available():\n",
    "        print(\n",
    "            f\"GPU allocated freed: {gpu_alloc_before - gpu_alloc_after:.2f} MB ({gpu_alloc_before:.2f} -> {gpu_alloc_after:.2f})\"\n",
    "        )\n",
    "        print(\n",
    "            f\"GPU reserved freed: {gpu_reserved_before - gpu_reserved_after:.2f} MB ({gpu_reserved_before:.2f} -> {gpu_reserved_after:.2f})\"\n",
    "        )\n",
    "    else:\n",
    "        print(\"No GPU detected.\")\n",
    "\n",
    "\n",
    "def create_logger(\n",
    "    name: str = \"reddit_moderation\",\n",
    "    log_level: str = \"INFO\",\n",
    "    log_file: Optional[Union[str, Path]] = None,\n",
    "    log_dir: Optional[Union[str, Path]] = \"logs\",\n",
    "    console_output: bool = True,\n",
    "    file_output: bool = True,\n",
    "    format_string: Optional[str] = None,\n",
    "    max_bytes: int = 10_000_000,  # 10MB\n",
    "    backup_count: int = 5,\n",
    "    include_timestamp_in_filename: bool = True,\n",
    ") -> logging.Logger:\n",
    "    \"\"\"\n",
    "    Create a fully featured logger for the Reddit comment moderation system.\n",
    "\n",
    "    This logger is designed to handle all aspects of the multi-stage classification\n",
    "    pipeline including zero-shot classification, fine-tuning, and evaluation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    name : str, optional\n",
    "        Logger name, by default \"reddit_moderation\"\n",
    "    log_level : str, optional\n",
    "        Logging level (\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"),\n",
    "        by default \"INFO\"\n",
    "    log_file : str or Path, optional\n",
    "        Specific log file path. If None, auto-generates based on name and timestamp\n",
    "    log_dir : str or Path, optional\n",
    "        Directory for log files, by default \"logs\"\n",
    "    console_output : bool, optional\n",
    "        Whether to output logs to console, by default True\n",
    "    file_output : bool, optional\n",
    "        Whether to output logs to file, by default True\n",
    "    format_string : str, optional\n",
    "        Custom log format string, by default None (uses comprehensive format)\n",
    "    max_bytes : int, optional\n",
    "        Maximum log file size before rotation, by default 10MB\n",
    "    backup_count : int, optional\n",
    "        Number of backup log files to keep, by default 5\n",
    "    include_timestamp_in_filename : bool, optional\n",
    "        Whether to include timestamp in log filename, by default True\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    logging.Logger\n",
    "        Configured logger instance ready for use\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> # Basic usage\n",
    "    >>> logger = create_logger()\n",
    "    >>> logger.info(\"Starting Reddit comment classification pipeline\")\n",
    "\n",
    "    >>> # Advanced usage for training\n",
    "    >>> training_logger = create_logger(\n",
    "    ...     name=\"distilbert_training\",\n",
    "    ...     log_level=\"DEBUG\",\n",
    "    ...     log_file=\"training_session.log\"\n",
    "    ... )\n",
    "    >>> training_logger.debug(\"Training batch processed\")\n",
    "\n",
    "    >>> # For evaluation only\n",
    "    >>> eval_logger = create_logger(\n",
    "    ...     name=\"model_evaluation\",\n",
    "    ...     console_output=False,\n",
    "    ...     log_file=\"evaluation_results.log\"\n",
    "    ... )\n",
    "    \"\"\"\n",
    "\n",
    "    # Create logger\n",
    "    logger = logging.getLogger(name)\n",
    "    logger.setLevel(getattr(logging, log_level.upper()))\n",
    "\n",
    "    # Clear existing handlers to avoid duplication\n",
    "    logger.handlers.clear()\n",
    "\n",
    "    # Default comprehensive format for ML workflows\n",
    "    if format_string is None:\n",
    "        format_string = \"%(asctime)s | %(name)s | %(levelname)s | %(message)s\"\n",
    "\n",
    "    formatter = logging.Formatter(format_string, datefmt=\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    # Console handler\n",
    "    if console_output:\n",
    "        console_handler = logging.StreamHandler(sys.stdout)\n",
    "        console_handler.setLevel(getattr(logging, log_level.upper()))\n",
    "        console_handler.setFormatter(formatter)\n",
    "        logger.addHandler(console_handler)\n",
    "\n",
    "    # File handler with rotation\n",
    "    if file_output:\n",
    "        # Create log directory\n",
    "        if log_dir:\n",
    "            log_dir = Path(log_dir)\n",
    "            log_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        # Generate log filename\n",
    "        if log_file is None:\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            if include_timestamp_in_filename:\n",
    "                log_filename = f\"{name}_{timestamp}.log\"\n",
    "            else:\n",
    "                log_filename = f\"{name}.log\"\n",
    "            log_file = log_dir / log_filename if log_dir else Path(log_filename)\n",
    "        else:\n",
    "            log_file = Path(log_file)\n",
    "            if log_dir and not log_file.is_absolute():\n",
    "                log_file = Path(log_dir) / log_file\n",
    "\n",
    "        # Create rotating file handler\n",
    "        from logging.handlers import RotatingFileHandler\n",
    "\n",
    "        file_handler = RotatingFileHandler(\n",
    "            log_file, maxBytes=max_bytes, backupCount=backup_count, encoding=\"utf-8\"\n",
    "        )\n",
    "        file_handler.setLevel(getattr(logging, log_level.upper()))\n",
    "        file_handler.setFormatter(formatter)\n",
    "        logger.addHandler(file_handler)\n",
    "\n",
    "    # Add some useful methods to the logger\n",
    "    def log_dataset_info(dataset, dataset_name=\"Dataset\"):\n",
    "        \"\"\"Log dataset information\"\"\"\n",
    "        logger.info(f\"{dataset_name} Info:\")\n",
    "        logger.info(f\"  - Size: {len(dataset):,} samples\")\n",
    "        logger.info(f\"  - Columns: {dataset.column_names}\")\n",
    "        if \"labels\" in dataset.column_names:\n",
    "            import numpy as np\n",
    "\n",
    "            labels = np.array(dataset[\"labels\"])\n",
    "            unique, counts = np.unique(labels, return_counts=True)\n",
    "            logger.info(f\"  - Label distribution: {dict(zip(unique, counts))}\")\n",
    "\n",
    "    def log_model_info(model, model_name=\"Model\"):\n",
    "        \"\"\"Log model information\"\"\"\n",
    "        logger.info(f\"{model_name} Info:\")\n",
    "        if hasattr(model, \"config\"):\n",
    "            logger.info(f\"  - Model type: {model.config.model_type}\")\n",
    "            logger.info(f\"  - Hidden size: {model.config.hidden_size}\")\n",
    "            if hasattr(model.config, \"num_labels\"):\n",
    "                logger.info(f\"  - Number of labels: {model.config.num_labels}\")\n",
    "\n",
    "        # Count parameters\n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        logger.info(f\"  - Total parameters: {total_params:,}\")\n",
    "        logger.info(f\"  - Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "    def log_training_args(training_args):\n",
    "        \"\"\"Log training arguments\"\"\"\n",
    "        logger.info(\"Training Configuration:\")\n",
    "        logger.info(f\"  - Learning rate: {training_args.learning_rate}\")\n",
    "        logger.info(f\"  - Batch size: {training_args.per_device_train_batch_size}\")\n",
    "        logger.info(\n",
    "            f\"  - Gradient accumulation: {training_args.gradient_accumulation_steps}\"\n",
    "        )\n",
    "        logger.info(f\"  - Epochs: {training_args.num_train_epochs}\")\n",
    "        logger.info(f\"  - Weight decay: {training_args.weight_decay}\")\n",
    "        logger.info(f\"  - LR scheduler: {training_args.lr_scheduler_type}\")\n",
    "        logger.info(f\"  - Warmup ratio: {training_args.warmup_ratio}\")\n",
    "\n",
    "    def log_metrics(metrics, stage=\"\"):\n",
    "        \"\"\"Log evaluation metrics\"\"\"\n",
    "        stage_prefix = f\"{stage} \" if stage else \"\"\n",
    "        logger.info(f\"{stage_prefix}Metrics:\")\n",
    "        for metric, value in metrics.items():\n",
    "            if isinstance(value, float):\n",
    "                logger.info(f\"  - {metric}: {value:.4f}\")\n",
    "            else:\n",
    "                logger.info(f\"  - {metric}: {value}\")\n",
    "\n",
    "    # Attach utility methods to logger\n",
    "    logger.log_dataset_info = log_dataset_info\n",
    "    logger.log_model_info = log_model_info\n",
    "    logger.log_training_args = log_training_args\n",
    "    logger.log_metrics = log_metrics\n",
    "\n",
    "    # Log logger creation\n",
    "    logger.info(f\"Logger '{name}' created successfully\")\n",
    "    logger.info(f\"Log level: {log_level}\")\n",
    "    if file_output:\n",
    "        logger.info(f\"Log file: {log_file}\")\n",
    "\n",
    "    return logger\n",
    "\n",
    "\n",
    "# Convenience function for quick setup\n",
    "def setup_project_logging(debug_mode: bool = False) -> logging.Logger:\n",
    "    \"\"\"\n",
    "    Quick setup for the Reddit moderation project logging.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    debug_mode : bool\n",
    "        If True, sets log level to DEBUG and enables verbose logging\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    logging.Logger\n",
    "        Configured project logger\n",
    "    \"\"\"\n",
    "    log_level = \"DEBUG\" if debug_mode else \"INFO\"\n",
    "\n",
    "    return create_logger(\n",
    "        name=\"reddit_moderation_pipeline\",\n",
    "        log_level=log_level,\n",
    "        log_dir=\"project_logs\",\n",
    "        include_timestamp_in_filename=True,\n",
    "    )\n",
    "\n",
    "\n",
    "def get_ram_usage():\n",
    "    process = psutil.Process()\n",
    "    return process.memory_info().rss  # bytes\n",
    "\n",
    "\n",
    "def free_vars(\n",
    "    vars_to_delete: List[Union[str, object]],\n",
    "    namespace: Optional[dict] = None,\n",
    "    try_gpu: bool = True,\n",
    "    logger=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Deletes variables by name or reference, frees RAM and GPU (PyTorch) memory,\n",
    "    logs actions via logger if provided.\n",
    "\n",
    "    Args:\n",
    "      vars_to_delete: list of variable names (str) or object refs\n",
    "      namespace: dict to remove names from (defaults to caller's globals())\n",
    "      try_gpu: clear GPU memory for torch objects\n",
    "      logger: logging object or None (use print)\n",
    "    Returns:\n",
    "      (freed_ram_bytes, freed_gpu_bytes)\n",
    "    \"\"\"\n",
    "    # Setup logger if not provided\n",
    "    if logger is None:\n",
    "\n",
    "        def logger(msg):\n",
    "            print(msg)\n",
    "\n",
    "    else:\n",
    "        logger = logger.info\n",
    "\n",
    "    # Automatic namespace resolution\n",
    "    if namespace is None:\n",
    "        # Get frame of the caller, locals then globals\n",
    "        frame = inspect.currentframe().f_back\n",
    "        namespace = frame.f_globals\n",
    "\n",
    "    before_ram = get_ram_usage()\n",
    "    try:\n",
    "        import torch\n",
    "    except ImportError:\n",
    "        torch = None\n",
    "\n",
    "    freed_gpu_bytes = 0\n",
    "    torch_objs = []\n",
    "    deleted = []\n",
    "\n",
    "    for var in vars_to_delete:\n",
    "        if isinstance(var, str):\n",
    "            obj = namespace.get(var, None)\n",
    "            if obj is not None:\n",
    "                deleted.append(var)\n",
    "                if torch and try_gpu:\n",
    "                    torch_objs.append(obj)\n",
    "                del namespace[var]\n",
    "                logger(f\"Deleted variable '{var}'\")\n",
    "            else:\n",
    "                logger(f\"Variable '{var}' not found in namespace\")\n",
    "        else:\n",
    "            # Try to remove all names referencing the object\n",
    "            names = [n for n, v in namespace.items() if v is var]\n",
    "            for n in names:\n",
    "                del namespace[n]\n",
    "                deleted.append(n)\n",
    "                logger(f\"Deleted variable '{n}' (by reference)\")\n",
    "            if not names:\n",
    "                logger(\n",
    "                    f\"Could not find a variable name for object {var!r}, may not be deleted\"\n",
    "                )\n",
    "            if torch and try_gpu:\n",
    "                torch_objs.append(var)\n",
    "\n",
    "    if torch and try_gpu and torch_objs and torch.cuda.is_available():\n",
    "        before_gpu = torch.cuda.memory_allocated()\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "        after_gpu = torch.cuda.memory_allocated()\n",
    "        freed_gpu_bytes = after_gpu - before_gpu\n",
    "        logger(f\"GPU memory freed: {freed_gpu_bytes/(1024**2):.2f} MB\")\n",
    "    # Always run gc\n",
    "    gc.collect()\n",
    "    after_ram = get_ram_usage()\n",
    "    freed_ram_bytes = after_ram - before_ram\n",
    "    logger(f\"RAM memory freed: {freed_ram_bytes/(1024**2):.2f} MB\")\n",
    "    clean_mem()\n",
    "    # return freed_ram_bytes, freed_gpu_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T10:58:17.215580Z",
     "iopub.status.busy": "2025-08-14T10:58:17.215343Z",
     "iopub.status.idle": "2025-08-14T10:58:17.232497Z",
     "shell.execute_reply": "2025-08-14T10:58:17.231802Z",
     "shell.execute_reply.started": "2025-08-14T10:58:17.215556Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import markdown2\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "\n",
    "\n",
    "def sanitize_comment(comment):\n",
    "    # Convert markdown to HTML, then extract the text (HTML tags removed)\n",
    "    html = markdown2.markdown(comment)\n",
    "    text = BeautifulSoup(html, features=\"html.parser\").get_text()\n",
    "\n",
    "    text = re.sub(r\"\\[([^\\]]+)\\]\\(([^)]+)\\)\", r\"\\1\", comment)\n",
    "    # Then re-run markdown2 and extract text again to clean up\n",
    "    html = markdown2.markdown(text)\n",
    "    text = BeautifulSoup(html, features=\"html.parser\").get_text()\n",
    "\n",
    "    url_pattern = re.compile(r\"((?:http|https)://[^\\s]+|www\\.[^\\s]+)\", re.IGNORECASE)\n",
    "    text = url_pattern.sub(lambda m: m.group(0), text)\n",
    "\n",
    "    # Convert non-unicode characters to unicode (ASCII compatible)\n",
    "    text = unidecode(text)\n",
    "\n",
    "    # Normalize whitespace\n",
    "    text = \" \".join(text.split()).lower()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read datasets from path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T10:58:17.233629Z",
     "iopub.status.busy": "2025-08-14T10:58:17.233266Z",
     "iopub.status.idle": "2025-08-14T10:58:17.253744Z",
     "shell.execute_reply": "2025-08-14T10:58:17.252986Z",
     "shell.execute_reply.started": "2025-08-14T10:58:17.233605Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-17 18:09:00 | rulewise | INFO | Logger 'rulewise' created successfully\n",
      "2025-08-17 18:09:00 | rulewise | INFO | Log level: INFO\n",
      "2025-08-17 18:09:00 | rulewise | INFO | Log file: logs/rulewise_20250817_180900.log\n"
     ]
    }
   ],
   "source": [
    "logger = create_logger(name=\"rulewise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-17 18:09:00 | rulewise | INFO | ON_KAGGLE = False\n",
      "2025-08-17 18:09:00 | rulewise | INFO | INPUT_PATH = '../data'\n",
      "2025-08-17 18:09:00 | rulewise | INFO | OUTPUT_PATH = './rulewise-output'\n",
      "2025-08-17 18:09:00 | rulewise | INFO | _MODEL_DIR = '../model'\n",
      "2025-08-17 18:09:00 | rulewise | INFO | MODEL_PATH = {'classifier': 'FacebookAI/roberta-base'}\n",
      "2025-08-17 18:09:00 | rulewise | INFO | TRY_PROBABILITY_CALIBRATION = False\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"{ON_KAGGLE = }\")\n",
    "logger.info(f\"{INPUT_PATH = }\")\n",
    "logger.info(f\"{OUTPUT_PATH = }\")\n",
    "logger.info(f\"{_MODEL_DIR = }\")\n",
    "logger.info(f\"{MODEL_PATH = }\")\n",
    "logger.info(f\"{TRY_PROBABILITY_CALIBRATION = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T10:58:17.254723Z",
     "iopub.status.busy": "2025-08-14T10:58:17.254491Z",
     "iopub.status.idle": "2025-08-14T10:58:17.297082Z",
     "shell.execute_reply": "2025-08-14T10:58:17.296363Z",
     "shell.execute_reply.started": "2025-08-14T10:58:17.254697Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\n",
    "    os.path.join(INPUT_PATH, \"jigsaw-agile-community-rules\", \"train.csv\")\n",
    ")\n",
    "test = pd.read_csv(os.path.join(INPUT_PATH, \"jigsaw-agile-community-rules\", \"test.csv\"))\n",
    "submission = pd.read_csv(\n",
    "    os.path.join(INPUT_PATH, \"jigsaw-agile-community-rules\", \"sample_submission.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clean the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T10:58:17.299469Z",
     "iopub.status.busy": "2025-08-14T10:58:17.299163Z",
     "iopub.status.idle": "2025-08-14T10:58:23.630103Z",
     "shell.execute_reply": "2025-08-14T10:58:23.629430Z",
     "shell.execute_reply.started": "2025-08-14T10:58:17.299447Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-17 18:09:00 | rulewise | INFO | Cleaning c = 'body'\n",
      "2025-08-17 18:09:01 | rulewise | INFO | Cleaning c = 'rule'\n",
      "2025-08-17 18:09:01 | rulewise | INFO | Cleaning c = 'subreddit'\n",
      "2025-08-17 18:09:01 | rulewise | INFO | Cleaning c = 'positive_example_1'\n",
      "2025-08-17 18:09:02 | rulewise | INFO | Cleaning c = 'positive_example_2'\n",
      "2025-08-17 18:09:02 | rulewise | INFO | Cleaning c = 'negative_example_1'\n",
      "2025-08-17 18:09:03 | rulewise | INFO | Cleaning c = 'negative_example_2'\n"
     ]
    }
   ],
   "source": [
    "for c in [\n",
    "    \"body\",\n",
    "    \"rule\",\n",
    "    \"subreddit\",\n",
    "    \"positive_example_1\",\n",
    "    \"positive_example_2\",\n",
    "    \"negative_example_1\",\n",
    "    \"negative_example_2\",\n",
    "]:\n",
    "    logger.info(f\"Cleaning {c = }\")\n",
    "    train[c] = train[c].apply(sanitize_comment)\n",
    "    test[c] = test[c].apply(sanitize_comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## melt the dataset\n",
    "\n",
    "there will be 3 parts\n",
    "\n",
    "-   actual training\n",
    "-   training examples\n",
    "-   testing examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T10:58:23.631091Z",
     "iopub.status.busy": "2025-08-14T10:58:23.630847Z",
     "iopub.status.idle": "2025-08-14T10:58:23.657758Z",
     "shell.execute_reply": "2025-08-14T10:58:23.656948Z",
     "shell.execute_reply.started": "2025-08-14T10:58:23.631070Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_main = (\n",
    "    train[[\"row_id\", \"body\", \"rule\", \"rule_violation\"]]\n",
    "    .rename(columns={\"rule_violation\": \"label\"})\n",
    "    .assign(split=\"train\")\n",
    ")\n",
    "train_examples = pd.concat(\n",
    "    [\n",
    "        (\n",
    "            train[[\"row_id\", \"rule\", \"positive_example_1\", \"positive_example_2\"]]\n",
    "            .melt(id_vars=[\"row_id\", \"rule\"], value_name=\"body\")\n",
    "            .assign(label=1, split=\"train\")\n",
    "            .drop(columns=[\"variable\"])\n",
    "        ),\n",
    "        (\n",
    "            train[[\"row_id\", \"rule\", \"negative_example_1\", \"negative_example_2\"]]\n",
    "            .melt(id_vars=[\"row_id\", \"rule\"], value_name=\"body\")\n",
    "            .assign(label=0, split=\"train\")\n",
    "            .drop(columns=[\"variable\"])\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "test_examples = pd.concat(\n",
    "    [\n",
    "        (\n",
    "            test[[\"row_id\", \"rule\", \"positive_example_1\", \"positive_example_2\"]]\n",
    "            .melt(id_vars=[\"row_id\", \"rule\"], value_name=\"body\")\n",
    "            .assign(label=1, split=\"test\")\n",
    "            .drop(columns=[\"variable\"])\n",
    "        ),\n",
    "        (\n",
    "            test[[\"row_id\", \"rule\", \"negative_example_1\", \"negative_example_2\"]]\n",
    "            .melt(id_vars=[\"row_id\", \"rule\"], value_name=\"body\")\n",
    "            .assign(label=0, split=\"test\")\n",
    "            .drop(columns=[\"variable\"])\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T10:58:23.658903Z",
     "iopub.status.busy": "2025-08-14T10:58:23.658655Z",
     "iopub.status.idle": "2025-08-14T10:58:23.746618Z",
     "shell.execute_reply": "2025-08-14T10:58:23.745917Z",
     "shell.execute_reply.started": "2025-08-14T10:58:23.658882Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fulldata = pd.concat(\n",
    "    [train_main, train_examples[train_main.columns], test_examples[train_main.columns]],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "# since we are using the examples there will be duplicates\n",
    "fulldata = fulldata.drop_duplicates(subset=[\"body\", \"rule\", \"label\"])\n",
    "fulldata.to_csv(os.path.join(OUTPUT_PATH, \"fulldata.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T10:58:23.747642Z",
     "iopub.status.busy": "2025-08-14T10:58:23.747410Z",
     "iopub.status.idle": "2025-08-14T10:58:25.283413Z",
     "shell.execute_reply": "2025-08-14T10:58:25.282651Z",
     "shell.execute_reply.started": "2025-08-14T10:58:23.747625Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-17 18:09:03 | rulewise | INFO | Deleted variable 'train'\n",
      "2025-08-17 18:09:03 | rulewise | INFO | Deleted variable 'train_main'\n",
      "2025-08-17 18:09:03 | rulewise | INFO | Deleted variable 'train_examples'\n",
      "2025-08-17 18:09:03 | rulewise | INFO | Deleted variable 'test_examples'\n",
      "2025-08-17 18:09:04 | rulewise | INFO | RAM memory freed: 16.25 MB\n",
      "RAM freed: 0.00 MB (892.02 -> 892.02)\n",
      "No GPU detected.\n"
     ]
    }
   ],
   "source": [
    "free_vars(\n",
    "    [\"train\", \"train_main\", \"train_examples\", \"test_examples\"],\n",
    "    namespace=globals(),\n",
    "    logger=logger,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create dataset and dataloader\n",
    "\n",
    "when we are creating the dataloader, we should specify the rule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T10:58:25.284997Z",
     "iopub.status.busy": "2025-08-14T10:58:25.284258Z",
     "iopub.status.idle": "2025-08-14T10:58:25.290940Z",
     "shell.execute_reply": "2025-08-14T10:58:25.290149Z",
     "shell.execute_reply.started": "2025-08-14T10:58:25.284973Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CommentDataset(utils.data.Dataset):\n",
    "    def __init__(self, dataset, tokenizer, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        dataset = dataset\n",
    "        self.row_id = dataset[\"row_id\"].tolist()\n",
    "        self.rule = dataset[\"rule\"].tolist()\n",
    "        self.body = dataset[\"body\"].tolist()\n",
    "        self.label = dataset[\"label\"].tolist()\n",
    "\n",
    "        rule_encodings = tokenizer(self.rule, truncation=True, padding=\"max_length\")\n",
    "        comment_encodings = tokenizer(self.body, truncation=True, padding=\"max_length\")\n",
    "\n",
    "        self.rule_input_ids = rule_encodings[\"input_ids\"]\n",
    "        self.rule_attention_mask = rule_encodings[\"attention_mask\"]\n",
    "        self.comment_input_ids = comment_encodings[\"input_ids\"]\n",
    "        self.comment_attention_mask = comment_encodings[\"attention_mask\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (\n",
    "            torch.tensor(self.rule_input_ids[index]),\n",
    "            torch.tensor(self.rule_attention_mask[index]),\n",
    "            torch.tensor(self.comment_input_ids[index]),\n",
    "            torch.tensor(self.comment_attention_mask[index]),\n",
    "            torch.tensor(self.label[index]),\n",
    "            torch.tensor(self.row_id[index]),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T10:58:25.292028Z",
     "iopub.status.busy": "2025-08-14T10:58:25.291703Z",
     "iopub.status.idle": "2025-08-14T10:58:25.309987Z",
     "shell.execute_reply": "2025-08-14T10:58:25.309244Z",
     "shell.execute_reply.started": "2025-08-14T10:58:25.292005Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prepare_datasets(fulldata, test, test_size, rule):\n",
    "    if isinstance(rule, str):\n",
    "        rule = [rule]\n",
    "    subdata = fulldata[fulldata[\"rule\"].isin(rule)]\n",
    "    subtest = test[test[\"rule\"].isin(rule)]\n",
    "\n",
    "    logger.info(f\"{len(subdata)}/{len(fulldata)} rows remain in fulldata.\")\n",
    "    logger.info(f\"{len(subtest)}/{len(test)} rows remain in test.\")\n",
    "    train, val = train_test_split(\n",
    "        subdata,\n",
    "        test_size=test_size,\n",
    "        shuffle=True,\n",
    "        random_state=42,\n",
    "        stratify=subdata[\"label\"],\n",
    "    )\n",
    "    subtest[\"label\"] = 0\n",
    "    columns = [\"row_id\", \"body\", \"rule\", \"label\"]\n",
    "    return train[columns], val[columns], subtest[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T10:58:25.311017Z",
     "iopub.status.busy": "2025-08-14T10:58:25.310771Z",
     "iopub.status.idle": "2025-08-14T10:58:25.326678Z",
     "shell.execute_reply": "2025-08-14T10:58:25.325959Z",
     "shell.execute_reply.started": "2025-08-14T10:58:25.310995Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prepare_dataloaders(train, val, test, tokenizer, batch_size=8):\n",
    "    train_dataset = CommentDataset(train, tokenizer)\n",
    "    train_dataloader = utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        drop_last=True,\n",
    "        shuffle=True,\n",
    "        # num_workers=4,\n",
    "        batch_size=batch_size,\n",
    "    )\n",
    "    val_dataset = CommentDataset(val, tokenizer)\n",
    "    val_dataloader = utils.data.DataLoader(\n",
    "        val_dataset,\n",
    "        drop_last=True,\n",
    "        shuffle=True,\n",
    "        # num_workers=4,\n",
    "        batch_size=2 * batch_size,\n",
    "    )\n",
    "    test_dataset = CommentDataset(test, tokenizer)\n",
    "    test_dataloader = utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        drop_last=False,\n",
    "        shuffle=False,\n",
    "        # num_workers=4,\n",
    "        batch_size=4 * batch_size,\n",
    "    )\n",
    "\n",
    "    return train_dataloader, val_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# modelling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T10:58:25.327821Z",
     "iopub.status.busy": "2025-08-14T10:58:25.327503Z",
     "iopub.status.idle": "2025-08-14T10:58:25.347609Z",
     "shell.execute_reply": "2025-08-14T10:58:25.346885Z",
     "shell.execute_reply.started": "2025-08-14T10:58:25.327800Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-17 18:09:06 | rulewise | INFO | {'classifier': 'FacebookAI/roberta-base'}\n"
     ]
    }
   ],
   "source": [
    "logger.info(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define the model classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classifier head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, hidden_size: int, num_labels: int = 2, dropout: float = 0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        # a layer norm to ensure that means and standard deviations are standardised\n",
    "        self.layer_norm = nn.LayerNorm(hidden_size * 4)\n",
    "        # now take a clf head\n",
    "        # this should bring the compressed thingy\n",
    "        # down to num_labels\n",
    "        self.clf = nn.Sequential(\n",
    "            nn.Linear(hidden_size * 4, hidden_size // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_size // 2, hidden_size // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_size // 4, num_labels),\n",
    "        )\n",
    "\n",
    "    def forward(self, rule_outputs, comment_outputs):\n",
    "        # sentence similarity thingy from sbert did not work\n",
    "        # back to just the difference\n",
    "        diff = torch.abs(rule_outputs - comment_outputs)\n",
    "        # actually back to more features\n",
    "        # - rule output\n",
    "        # - comment output\n",
    "        # - diff\n",
    "        # - elementwise product\n",
    "        combined = torch.cat(\n",
    "            [rule_outputs, comment_outputs, diff, rule_outputs * comment_outputs], dim=1\n",
    "        )\n",
    "        # apply layer norm\n",
    "        combined = self.layer_norm(combined)\n",
    "        # now do the classification\n",
    "        logits = self.clf(combined)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### difference roberta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T10:58:25.348564Z",
     "iopub.status.busy": "2025-08-14T10:58:25.348347Z",
     "iopub.status.idle": "2025-08-14T10:58:25.362242Z",
     "shell.execute_reply": "2025-08-14T10:58:25.361578Z",
     "shell.execute_reply.started": "2025-08-14T10:58:25.348549Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class DifferenceRoberta(RobertaPreTrainedModel):\n",
    "    config_class = RobertaConfig\n",
    "\n",
    "    def __init__(self, config: RobertaConfig):\n",
    "        super().__init__(config)\n",
    "        _basemodel = RobertaForSequenceClassification(config)\n",
    "        self.roberta = _basemodel.roberta\n",
    "        self.classifier = Classifier(\n",
    "            hidden_size=config.hidden_size, num_labels=config.num_labels, dropout=0.4\n",
    "        )\n",
    "        # self.classifier = _basemodel.classifier\n",
    "        self.hidden_size = config.hidden_size\n",
    "        free_vars([\"_basemodel\"], namespace=locals(), logger=logger)\n",
    "        self.init_weights()\n",
    "        logger.info(config)\n",
    "\n",
    "    @staticmethod\n",
    "    def mean_pool(last_hidden_state: torch.Tensor, attention_mask: torch.Tensor):\n",
    "        \"\"\"\n",
    "        last_hidden_state: (B, T, H)\n",
    "        attention_mask: (B, T) with 1 for real tokens, 0 for padding\n",
    "        returns: (B, H) mean-pooled over token positions where attention_mask == 1\n",
    "        \"\"\"\n",
    "        # convert mask to float on same device as last_hidden_state\n",
    "        mask = attention_mask.unsqueeze(-1).to(\n",
    "            dtype=last_hidden_state.dtype\n",
    "        )  # (B, T, 1)\n",
    "        # sum of hidden states where mask == 1\n",
    "        masked_sum = (last_hidden_state * mask).sum(dim=1)  # (B, H)\n",
    "        # number of real tokens per example\n",
    "        lengths = mask.sum(dim=1).clamp(min=1.0)  # (B, 1) clamp avoid div-by-zero\n",
    "        pooled = masked_sum / lengths  # broadcasting divides (B, H) / (B, 1)\n",
    "        return pooled\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        rule_input_ids=None,\n",
    "        rule_attention_mask=None,\n",
    "        comment_input_ids=None,\n",
    "        comment_attention_mask=None,\n",
    "        return_dict=True,\n",
    "        **kwargs\n",
    "    ):\n",
    "        return_dict = (\n",
    "            return_dict if return_dict is not None else self.config.use_return_dict\n",
    "        )\n",
    "\n",
    "        # get last_hidden_state for both inputs\n",
    "        rule_lhs = self.roberta(\n",
    "            input_ids=rule_input_ids,\n",
    "            attention_mask=rule_attention_mask,\n",
    "            return_dict=True,\n",
    "        ).last_hidden_state  # (B, T_r, H)\n",
    "\n",
    "        comment_lhs = self.roberta(\n",
    "            input_ids=comment_input_ids,\n",
    "            attention_mask=comment_attention_mask,\n",
    "            return_dict=True,\n",
    "        ).last_hidden_state  # (B, T_c, H)\n",
    "\n",
    "        # replace CLS with mean pooling\n",
    "        rule_outputs = self.mean_pool(rule_lhs, rule_attention_mask)  # (B, H)\n",
    "        comment_outputs = self.mean_pool(comment_lhs, comment_attention_mask)  # (B, H)\n",
    "\n",
    "        # base feature: difference (as before)\n",
    "        logits = self.classifier(rule_outputs, comment_outputs)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tie everything together in lightning module\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T10:58:25.364942Z",
     "iopub.status.busy": "2025-08-14T10:58:25.364707Z",
     "iopub.status.idle": "2025-08-14T10:58:25.383621Z",
     "shell.execute_reply": "2025-08-14T10:58:25.382878Z",
     "shell.execute_reply.started": "2025-08-14T10:58:25.364927Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class BasedRedditMod(L.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        diffroberta: DifferenceRoberta,\n",
    "        # model_path: str,\n",
    "        # num_labels: int,\n",
    "        max_steps: int,\n",
    "        weight: torch.Tensor = None,\n",
    "        logger: logging.Logger = logger,\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.diffroberta = diffroberta\n",
    "        self.loss_fn = nn.CrossEntropyLoss(weight=weight)\n",
    "        self.max_steps = max_steps\n",
    "\n",
    "        self.accuracy = BinaryAccuracy()\n",
    "        self.auroc = BinaryAUROC()\n",
    "        self.previous_auroc = 0\n",
    "\n",
    "        self.mylogger = logger\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        rid, ram, cid, cam, labels, row_ids = batch\n",
    "        logits = self.diffroberta(rid, ram, cid, cam)\n",
    "        loss = self.loss_fn(logits, labels)\n",
    "        self.log(\"train_loss\", loss, on_step=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx, *args, **kwargs):\n",
    "        rid, ram, cid, cam, labels, row_ids = batch\n",
    "        logits = self.diffroberta(rid, ram, cid, cam)\n",
    "        loss = self.loss_fn(logits, labels)\n",
    "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        # compute the metrics\n",
    "        probs, preds = self._get_predictions_from_logits(logits, labels, row_ids)\n",
    "        self.accuracy.update(preds=preds, target=labels)\n",
    "        self.auroc.update(preds=probs, target=labels)\n",
    "\n",
    "        self.log_dict(\n",
    "            {\n",
    "                \"accuracy\": self.accuracy.compute(),\n",
    "                \"auroc\": self.auroc.compute(),\n",
    "            },\n",
    "            on_epoch=True,\n",
    "            on_step=False,\n",
    "            prog_bar=False,\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        accuracy = self.accuracy.compute()\n",
    "        auroc = self.auroc.compute()\n",
    "        change = auroc - self.previous_auroc\n",
    "        self.previous_auroc = auroc\n",
    "\n",
    "        self.accuracy.reset()\n",
    "        self.auroc.reset()\n",
    "\n",
    "        lrs = [pg[\"lr\"] for pg in self.trainer.optimizers[0].param_groups]\n",
    "\n",
    "        # robust step lookup: prefer trainer.global_step, fall back to self.global_step or 0\n",
    "        step = getattr(self.trainer, \"global_step\", None)\n",
    "        if step is None:\n",
    "            step = getattr(self, \"global_step\", 0)\n",
    "\n",
    "        self.mylogger.info(\n",
    "            f\"#:{step}: acc = {accuracy*100.0:.2f} % | \"\n",
    "            f\"auroc = {auroc:.2f} (D = {change:.3f}) | \"\n",
    "            f\"lr = {lrs[0]:.2e}\"\n",
    "        )\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, *args, **kwargs):\n",
    "        rid, ram, cid, cam, labels, row_ids = batch\n",
    "        logits = self.diffroberta(rid, ram, cid, cam)\n",
    "        probs, _ = self._get_predictions_from_logits(logits, labels, row_ids)\n",
    "        return row_ids, probs, labels\n",
    "\n",
    "    def _get_predictions_from_logits(self, logits, labels, row_ids):\n",
    "        # get the probs and the preds\n",
    "        probs_full = F.softmax(logits, dim=1)\n",
    "        probs = probs_full[:, 1]\n",
    "        preds = torch.argmax(probs_full, dim=1)\n",
    "\n",
    "        assert preds.shape == probs.shape == labels.shape == row_ids.shape\n",
    "\n",
    "        return probs, preds\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        lr = 2e-5\n",
    "        wd = 0.01\n",
    "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "        param_groups = [\n",
    "            {\n",
    "                \"params\": [\n",
    "                    p\n",
    "                    for n, p in self.diffroberta.named_parameters()\n",
    "                    if not any(nd in n for nd in no_decay)\n",
    "                ],\n",
    "                \"weight_decay\": wd,\n",
    "            },\n",
    "            {\n",
    "                \"params\": [\n",
    "                    p\n",
    "                    for n, p in self.diffroberta.named_parameters()\n",
    "                    if any(nd in n for nd in no_decay)\n",
    "                ],\n",
    "                \"weight_decay\": 0.0,\n",
    "            },\n",
    "        ]\n",
    "        optimiser = optim.AdamW(param_groups, lr=lr)\n",
    "\n",
    "        scheduler = lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer=optimiser, T_max=self.max_steps, eta_min=5e-6\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            self.mylogger.info(\n",
    "                f\"param_groups={len(optimiser.param_groups)} | max_steps={getattr(self,'max_steps',None)}\"\n",
    "            )\n",
    "            for i, pg in enumerate(optimiser.param_groups):\n",
    "                n = sum(p.numel() for p in pg.get(\"params\", []) if p is not None)\n",
    "                lr = pg.get(\"lr\", None)\n",
    "                wd = pg.get(\"weight_decay\", None)\n",
    "                self.mylogger.info(f\"pg[{i}] params={n:,} lr={lr:.2e} wd={wd}\")\n",
    "        except Exception as e:\n",
    "            self.mylogger.exception(f\"_log_opt_info failed: {e}\")\n",
    "\n",
    "        return {\n",
    "            \"optimizer\": optimiser,\n",
    "            \"lr_scheduler\": {\n",
    "                \"scheduler\": scheduler,\n",
    "                \"interval\": \"step\",\n",
    "            },\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### constants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T10:58:25.403636Z",
     "iopub.status.busy": "2025-08-14T10:58:25.402662Z",
     "iopub.status.idle": "2025-08-14T10:58:25.415579Z",
     "shell.execute_reply": "2025-08-14T10:58:25.414901Z",
     "shell.execute_reply.started": "2025-08-14T10:58:25.403614Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def collate_predictions(submission_list):\n",
    "    submission = pd.concat(submission_list, ignore_index=True)\n",
    "    submission.to_csv(os.path.join(OUTPUT_PATH, \"submission.csv\"))\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T10:58:25.416514Z",
     "iopub.status.busy": "2025-08-14T10:58:25.416278Z",
     "iopub.status.idle": "2025-08-14T10:58:25.432189Z",
     "shell.execute_reply": "2025-08-14T10:58:25.431482Z",
     "shell.execute_reply.started": "2025-08-14T10:58:25.416494Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-17 18:09:06 | rulewise | INFO | BATCH_SIZE = 8\n",
      "2025-08-17 18:09:06 | rulewise | INFO | GRAD_ACCUMULATION_STEPS = 4\n",
      "2025-08-17 18:09:06 | rulewise | INFO | VALIDATION_PER_N_STEPS = 64\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 8\n",
    "GRAD_ACCUMULATION_STEPS = 4\n",
    "VALIDATION_PER_N_STEPS = 2 * BATCH_SIZE * GRAD_ACCUMULATION_STEPS\n",
    "# EPOCHS = 5\n",
    "\n",
    "logger.info(f\"{BATCH_SIZE = }\")\n",
    "logger.info(f\"{GRAD_ACCUMULATION_STEPS = }\")\n",
    "logger.info(f\"{VALIDATION_PER_N_STEPS = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get all rules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T10:58:25.433119Z",
     "iopub.status.busy": "2025-08-14T10:58:25.432925Z",
     "iopub.status.idle": "2025-08-14T10:58:25.449601Z",
     "shell.execute_reply": "2025-08-14T10:58:25.448874Z",
     "shell.execute_reply.started": "2025-08-14T10:58:25.433105Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-17 18:09:06 | rulewise | INFO | {'no advertising: spam, referral links, unsolicited advertising, and promotional content are not allowed.': 0, 'no legal advice: do not offer or request legal advice.': 1}\n"
     ]
    }
   ],
   "source": [
    "# get all the rules\n",
    "all_rules = fulldata[\"rule\"].unique().tolist()\n",
    "id2rule = dict(enumerate(all_rules))\n",
    "rule2id = {v: k for k, v in id2rule.items()}\n",
    "\n",
    "logger.info(rule2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run loop to train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-14T10:58:25.450727Z",
     "iopub.status.busy": "2025-08-14T10:58:25.450455Z",
     "iopub.status.idle": "2025-08-14T10:58:46.130094Z",
     "shell.execute_reply": "2025-08-14T10:58:46.128778Z",
     "shell.execute_reply.started": "2025-08-14T10:58:25.450707Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-08-17 18:09:06 | rulewise | INFO | tokenizer.pad_token = '<pad>' | tokenizer.eos_token = '</s>'\n",
      "2025-08-17 18:09:06 | rulewise | INFO | ./rulewise-output/rule-0\n",
      "2025-08-17 18:09:06 | rulewise | INFO | 860/1874 rows remain in fulldata.\n",
      "2025-08-17 18:09:06 | rulewise | INFO | 9/10 rows remain in test.\n",
      "2025-08-17 18:09:06 | rulewise | INFO | train steps = 80 | val steps = 13\n",
      "2025-08-17 18:09:06 | rulewise | INFO | Deleted variable 'train'\n",
      "2025-08-17 18:09:06 | rulewise | INFO | Deleted variable 'val'\n",
      "2025-08-17 18:09:06 | rulewise | INFO | Deleted variable 'subtest'\n",
      "2025-08-17 18:09:06 | rulewise | INFO | RAM memory freed: 0.00 MB\n",
      "RAM freed: 0.00 MB (988.82 -> 988.82)\n",
      "No GPU detected.\n",
      "2025-08-17 18:09:08 | rulewise | INFO | Deleted variable '_basemodel'\n",
      "2025-08-17 18:09:08 | rulewise | INFO | RAM memory freed: 0.00 MB\n",
      "RAM freed: 0.00 MB (992.19 -> 992.19)\n",
      "No GPU detected.\n",
      "2025-08-17 18:09:09 | rulewise | INFO | RobertaConfig {\n",
      "  \"_attn_implementation_autoset\": true,\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.51.3\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DifferenceRoberta were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.clf.0.bias', 'classifier.clf.0.weight', 'classifier.clf.3.bias', 'classifier.clf.3.weight', 'classifier.clf.6.bias', 'classifier.clf.6.weight', 'classifier.layer_norm.bias', 'classifier.layer_norm.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "MisconfigurationException",
     "evalue": "`CUDAAccelerator` can not run on your system since the accelerator is not available. The following accelerator(s) is available and can be passed into `accelerator` argument of `Trainer`: ['cpu'].",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMisconfigurationException\u001b[39m                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 78\u001b[39m\n\u001b[32m     71\u001b[39m early_stopping_callback_loss = lcb.EarlyStopping(\n\u001b[32m     72\u001b[39m     monitor=\u001b[33m\"\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m\"\u001b[39m, min_delta=\u001b[32m1e-5\u001b[39m, patience=\u001b[32m4\u001b[39m, mode=\u001b[33m\"\u001b[39m\u001b[33mmin\u001b[39m\u001b[33m\"\u001b[39m, verbose=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     73\u001b[39m )\n\u001b[32m     75\u001b[39m \u001b[38;5;66;03m# ---------------------\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;66;03m# customise the trainer\u001b[39;00m\n\u001b[32m     77\u001b[39m \u001b[38;5;66;03m# ---------------------\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m trainer = \u001b[43mL\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# limit_train_batches=2 * VALIDATION_PER_N_STEPS,  # this is only for rapid iteration\u001b[39;49;00m\n\u001b[32m     80\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mVALIDATION_PER_N_STEPS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# max_epochs=1,\u001b[39;49;00m\n\u001b[32m     82\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccelerator\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     83\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# devices=2,\u001b[39;49;00m\n\u001b[32m     84\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# train in mixed bf16 precision\u001b[39;49;00m\n\u001b[32m     85\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbf16-mixed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# each training batch size is 8\u001b[39;49;00m\n\u001b[32m     87\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# accumulate gradients over 4 batches... so eff. batch size is 32\u001b[39;49;00m\n\u001b[32m     88\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad_batches\u001b[49m\u001b[43m=\u001b[49m\u001b[43mGRAD_ACCUMULATION_STEPS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# clip gradients' global norm to <=0.5 using gradient_clip_algorithm='norm' by default\u001b[39;49;00m\n\u001b[32m     90\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgradient_clip_val\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# perform eval every 32 steps\u001b[39;49;00m\n\u001b[32m     92\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_check_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mVALIDATION_PER_N_STEPS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# model checkpointing\u001b[39;49;00m\n\u001b[32m     94\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdefault_root_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrule_output_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# callbacks\u001b[39;49;00m\n\u001b[32m     96\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_callback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m        \u001b[49m\u001b[43mearly_stopping_callback_auroc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# early_stopping_callback_loss,\u001b[39;49;00m\n\u001b[32m    100\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[38;5;66;03m# -------------\u001b[39;00m\n\u001b[32m    104\u001b[39m \u001b[38;5;66;03m# fit the model\u001b[39;00m\n\u001b[32m    105\u001b[39m \u001b[38;5;66;03m# -------------\u001b[39;00m\n\u001b[32m    106\u001b[39m model.train()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/diffusion/lib/python3.11/site-packages/lightning/pytorch/utilities/argparse.py:70\u001b[39m, in \u001b[36m_defaults_from_env_vars.<locals>.insert_env_defaults\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     67\u001b[39m kwargs = \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mlist\u001b[39m(env_variables.items()) + \u001b[38;5;28mlist\u001b[39m(kwargs.items()))\n\u001b[32m     69\u001b[39m \u001b[38;5;66;03m# all args were already moved to kwargs\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m70\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/diffusion/lib/python3.11/site-packages/lightning/pytorch/trainer/trainer.py:404\u001b[39m, in \u001b[36mTrainer.__init__\u001b[39m\u001b[34m(self, accelerator, strategy, devices, num_nodes, precision, logger, callbacks, fast_dev_run, max_epochs, min_epochs, max_steps, min_steps, max_time, limit_train_batches, limit_val_batches, limit_test_batches, limit_predict_batches, overfit_batches, val_check_interval, check_val_every_n_epoch, num_sanity_val_steps, log_every_n_steps, enable_checkpointing, enable_progress_bar, enable_model_summary, accumulate_grad_batches, gradient_clip_val, gradient_clip_algorithm, deterministic, benchmark, inference_mode, use_distributed_sampler, profiler, detect_anomaly, barebones, plugins, sync_batchnorm, reload_dataloaders_every_n_epochs, default_root_dir, model_registry)\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;66;03m# init connectors\u001b[39;00m\n\u001b[32m    402\u001b[39m \u001b[38;5;28mself\u001b[39m._data_connector = _DataConnector(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m404\u001b[39m \u001b[38;5;28mself\u001b[39m._accelerator_connector = \u001b[43m_AcceleratorConnector\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevices\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccelerator\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccelerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m    \u001b[49m\u001b[43msync_batchnorm\u001b[49m\u001b[43m=\u001b[49m\u001b[43msync_batchnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbenchmark\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbenchmark\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_distributed_sampler\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_distributed_sampler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m    \u001b[49m\u001b[43mplugins\u001b[49m\u001b[43m=\u001b[49m\u001b[43mplugins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[38;5;28mself\u001b[39m._logger_connector = _LoggerConnector(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    417\u001b[39m \u001b[38;5;28mself\u001b[39m._callback_connector = _CallbackConnector(\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/diffusion/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/accelerator_connector.py:147\u001b[39m, in \u001b[36m_AcceleratorConnector.__init__\u001b[39m\u001b[34m(self, devices, num_nodes, accelerator, strategy, plugins, precision, sync_batchnorm, benchmark, use_distributed_sampler, deterministic)\u001b[39m\n\u001b[32m    144\u001b[39m     \u001b[38;5;28mself\u001b[39m._accelerator_flag = \u001b[38;5;28mself\u001b[39m._choose_gpu_accelerator_backend()\n\u001b[32m    146\u001b[39m \u001b[38;5;28mself\u001b[39m._check_device_config_and_set_final_flags(devices=devices, num_nodes=num_nodes)\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_set_parallel_devices_and_init_accelerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[38;5;66;03m# 3. Instantiate ClusterEnvironment\u001b[39;00m\n\u001b[32m    150\u001b[39m \u001b[38;5;28mself\u001b[39m.cluster_environment: ClusterEnvironment = \u001b[38;5;28mself\u001b[39m._choose_and_init_cluster_environment()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/venvs/diffusion/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/accelerator_connector.py:369\u001b[39m, in \u001b[36m_AcceleratorConnector._set_parallel_devices_and_init_accelerator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    363\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m accelerator_cls.is_available():\n\u001b[32m    364\u001b[39m     available_accelerator = [\n\u001b[32m    365\u001b[39m         acc_str\n\u001b[32m    366\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m acc_str \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._accelerator_types\n\u001b[32m    367\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m AcceleratorRegistry[acc_str][\u001b[33m\"\u001b[39m\u001b[33maccelerator\u001b[39m\u001b[33m\"\u001b[39m].is_available()\n\u001b[32m    368\u001b[39m     ]\n\u001b[32m--> \u001b[39m\u001b[32m369\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\n\u001b[32m    370\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccelerator_cls.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` can not run on your system\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    371\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m since the accelerator is not available. The following accelerator(s)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    372\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m is available and can be passed into `accelerator` argument of\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    373\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m `Trainer`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavailable_accelerator\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    374\u001b[39m     )\n\u001b[32m    376\u001b[39m \u001b[38;5;28mself\u001b[39m._set_devices_flag_if_auto_passed()\n\u001b[32m    377\u001b[39m \u001b[38;5;28mself\u001b[39m._devices_flag = accelerator_cls.parse_devices(\u001b[38;5;28mself\u001b[39m._devices_flag)\n",
      "\u001b[31mMisconfigurationException\u001b[39m: `CUDAAccelerator` can not run on your system since the accelerator is not available. The following accelerator(s) is available and can be passed into `accelerator` argument of `Trainer`: ['cpu']."
     ]
    }
   ],
   "source": [
    "all_submissions = []\n",
    "# ------------------------\n",
    "# initialise the tokenizer\n",
    "# ------------------------\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH[\"classifier\"])\n",
    "logger.info(f\"{tokenizer.pad_token = } | {tokenizer.eos_token = }\")\n",
    "\n",
    "for i, rule in enumerate(all_rules):\n",
    "    if i == 0:\n",
    "        pass\n",
    "    # -------------------------------\n",
    "    # get the rule\n",
    "    # make the output paths and stuff\n",
    "    # -------------------------------\n",
    "    rule_output_path = os.path.join(OUTPUT_PATH, f\"rule-{rule2id[rule]}\")\n",
    "    os.makedirs(rule_output_path, exist_ok=True)\n",
    "    logger.info(rule_output_path)\n",
    "\n",
    "    # --------------------------\n",
    "    # prepare the datasets\n",
    "    # as well as the dataloaders\n",
    "    # --------------------------\n",
    "    train, val, subtest = prepare_datasets(fulldata.copy(), test.copy(), 0.25, rule)\n",
    "    train_dataloader, val_dataloader, subtest_dataloader = prepare_dataloaders(\n",
    "        train, val, subtest, tokenizer, batch_size=BATCH_SIZE\n",
    "    )\n",
    "    logger.info(\n",
    "        f\"train steps = {len(train_dataloader)} | val steps = {len(val_dataloader)}\"\n",
    "    )\n",
    "    weight = torch.Tensor(\n",
    "        train[\"label\"].value_counts(normalize=True).sort_index().values\n",
    "    )\n",
    "    free_vars([\"train\", \"val\", \"subtest\"], namespace=globals(), logger=logger)\n",
    "\n",
    "    # --------------------\n",
    "    # initialise the model\n",
    "    # --------------------\n",
    "    diffroberta = DifferenceRoberta.from_pretrained(\n",
    "        MODEL_PATH[\"classifier\"], num_labels=2\n",
    "    )\n",
    "    model = BasedRedditMod(\n",
    "        diffroberta=diffroberta,\n",
    "        # model_path=MODEL_PATH[\"classifier\"],\n",
    "        # num_labels=2,\n",
    "        max_steps=(4 * VALIDATION_PER_N_STEPS) // GRAD_ACCUMULATION_STEPS,\n",
    "        weight=weight,\n",
    "        logger=logger,\n",
    "    )\n",
    "\n",
    "    # ---------\n",
    "    # callbacks\n",
    "    # ---------\n",
    "    # ideally i want 2 checkpoints to be saved\n",
    "    # the best one\n",
    "    # the latest one\n",
    "    # i want the checkpoints to be saved immediately after validation check is performed\n",
    "    checkpoint_callback = lcb.ModelCheckpoint(\n",
    "        monitor=\"auroc\",\n",
    "        dirpath=rule_output_path,\n",
    "        mode=\"max\",\n",
    "        save_top_k=1,\n",
    "        save_last=True,\n",
    "        save_on_train_epoch_end=False,\n",
    "    )\n",
    "    # have two early stopping callbacks\n",
    "    # primary - stop if auroc does not improve much\n",
    "    # secondary - stop if val loss does not improve much\n",
    "    early_stopping_callback_auroc = lcb.EarlyStopping(\n",
    "        monitor=\"auroc\", min_delta=1e-4, patience=2, mode=\"max\", verbose=True\n",
    "    )\n",
    "    early_stopping_callback_loss = lcb.EarlyStopping(\n",
    "        monitor=\"val_loss\", min_delta=1e-5, patience=4, mode=\"min\", verbose=True\n",
    "    )\n",
    "\n",
    "    # ---------------------\n",
    "    # customise the trainer\n",
    "    # ---------------------\n",
    "    trainer = L.Trainer(\n",
    "        # limit_train_batches=2 * VALIDATION_PER_N_STEPS,  # this is only for rapid iteration\n",
    "        max_steps=8 * VALIDATION_PER_N_STEPS,\n",
    "        # max_epochs=1,\n",
    "        accelerator=\"cuda\",\n",
    "        # devices=2,\n",
    "        # train in mixed bf16 precision\n",
    "        precision=\"bf16-mixed\",\n",
    "        # each training batch size is 8\n",
    "        # accumulate gradients over 4 batches... so eff. batch size is 32\n",
    "        accumulate_grad_batches=GRAD_ACCUMULATION_STEPS,\n",
    "        # clip gradients' global norm to <=0.5 using gradient_clip_algorithm='norm' by default\n",
    "        gradient_clip_val=0.5,\n",
    "        # perform eval every 32 steps\n",
    "        val_check_interval=VALIDATION_PER_N_STEPS,\n",
    "        # model checkpointing\n",
    "        default_root_dir=rule_output_path,\n",
    "        # callbacks\n",
    "        callbacks=[\n",
    "            checkpoint_callback,\n",
    "            early_stopping_callback_auroc,\n",
    "            # early_stopping_callback_loss,\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    # -------------\n",
    "    # fit the model\n",
    "    # -------------\n",
    "    model.train()\n",
    "    trainer.fit(\n",
    "        model=model, train_dataloaders=train_dataloader, val_dataloaders=val_dataloader\n",
    "    )\n",
    "    free_vars(\n",
    "        [\"model\", \"train_dataloader\"],\n",
    "        namespace=globals(),\n",
    "        logger=logger,\n",
    "    )\n",
    "\n",
    "    # --------------------------------------------\n",
    "    # load the best model and use it for inference\n",
    "    # --------------------------------------------\n",
    "    best_ckpt = checkpoint_callback.best_model_path\n",
    "    logger.info(f\"Loading model for inference and next rule from {best_ckpt}\")\n",
    "    model = BasedRedditMod.load_from_checkpoint(\n",
    "        best_ckpt,\n",
    "        strict=False,\n",
    "        diffroberta=diffroberta,\n",
    "        # model_path=MODEL_PATH[\"classifier\"],\n",
    "        # num_labels=2,\n",
    "        max_steps=(4 * VALIDATION_PER_N_STEPS) // GRAD_ACCUMULATION_STEPS,\n",
    "        logger=logger,\n",
    "    )\n",
    "\n",
    "    # ----------------------------------------------\n",
    "    # evaluate predictions on validation (TEMPORARY)\n",
    "    # ----------------------------------------------\n",
    "    model.eval()\n",
    "    # this will return a list of length = len(dataloader)\n",
    "    # each element will be a tuple of length 3\n",
    "    # tuple = (row_ids, probs)\n",
    "    outs = trainer.predict(model=model, dataloaders=val_dataloader)\n",
    "    row_ids = torch.cat([o[0] for o in outs], dim=0).detach().cpu().numpy()\n",
    "    probs = torch.cat([o[1] for o in outs], dim=0).detach().cpu().numpy()\n",
    "    labels = torch.cat([o[2] for o in outs], dim=0).detach().cpu().numpy()\n",
    "    preds = (probs > 0.5).astype(float)\n",
    "    _evaluation_for_this_rule = pd.DataFrame(\n",
    "        {\"row_id\": row_ids, \"prob\": probs, \"label\": labels, \"pred\": preds}\n",
    "    )\n",
    "    free_vars(\n",
    "        [\"outs\", \"row_ids\", \"probs\", \"labels\", \"preds\"],\n",
    "        namespace=globals(),\n",
    "        logger=logger,\n",
    "    )\n",
    "    logger.info(\n",
    "        \"\\n\"\n",
    "        + classification_report(\n",
    "            _evaluation_for_this_rule[\"label\"], _evaluation_for_this_rule[\"pred\"]\n",
    "        )\n",
    "    )\n",
    "    logger.info(\n",
    "        f\"auc = {roc_auc_score(_evaluation_for_this_rule['label'], _evaluation_for_this_rule['prob']):.2f}\"\n",
    "    )\n",
    "    if i == 1:\n",
    "        break\n",
    "\n",
    "    # -----------------\n",
    "    # write predictions\n",
    "    # -----------------\n",
    "    model.eval()\n",
    "    # this will return a list of length = len(dataloader)\n",
    "    # each element will be a tuple of length 3\n",
    "    # tuple = (row_ids, probs)\n",
    "    outs = trainer.predict(model=model, dataloaders=subtest_dataloader)\n",
    "    row_ids = torch.cat([o[0] for o in outs], dim=0).detach().cpu().numpy()\n",
    "    probs = torch.cat([o[1] for o in outs], dim=0).detach().cpu().numpy()\n",
    "    free_vars([\"outs\"], namespace=globals(), logger=logger)\n",
    "\n",
    "    # -------------------------------\n",
    "    # perform probability calibration\n",
    "    # -------------------------------\n",
    "    # EXPERIMENTAL\n",
    "    # perform prob calibration with isotonic regression\n",
    "    # needs to be evaluated\n",
    "    # try a submission without calibration and one with calibration\n",
    "    if TRY_PROBABILITY_CALIBRATION and len(val_dataloader) > 1_000:\n",
    "        reg = IsotonicRegression(y_min=0, y_max=1, out_of_bounds=\"clip\")\n",
    "        reg.fit(_evaluation_for_this_rule[\"prob\"], _evaluation_for_this_rule[\"label\"])\n",
    "        calibrated_probs = reg.transform(probs)\n",
    "    else:\n",
    "        calibrated_probs = probs\n",
    "\n",
    "    _submission_for_this_rule = pd.DataFrame(\n",
    "        {\"row_id\": row_ids, \"rule_violation\": calibrated_probs}\n",
    "    )\n",
    "    all_submissions.append(_submission_for_this_rule)\n",
    "\n",
    "    free_vars(\n",
    "        [\n",
    "            \"model\",\n",
    "            \"diffroberta\",\n",
    "            \"val_dataloader\",\n",
    "            \"subtest_dataloader\",\n",
    "            \"row_ids\",\n",
    "            \"probs\",\n",
    "            \"trainer\",\n",
    "            \"_evaluation_for_this_rule\",\n",
    "            \"reg\",\n",
    "            \"calibrated_probs\",\n",
    "        ],\n",
    "        namespace=globals(),\n",
    "        logger=logger,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-08-14T10:58:46.130547Z",
     "iopub.status.idle": "2025-08-14T10:58:46.130842Z",
     "shell.execute_reply": "2025-08-14T10:58:46.130712Z",
     "shell.execute_reply.started": "2025-08-14T10:58:46.130695Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>rule_violation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2029</td>\n",
       "      <td>0.046725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2031</td>\n",
       "      <td>0.880386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2032</td>\n",
       "      <td>0.886813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2033</td>\n",
       "      <td>0.882833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2034</td>\n",
       "      <td>0.040846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2035</td>\n",
       "      <td>0.869715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2036</td>\n",
       "      <td>0.042722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2037</td>\n",
       "      <td>0.040846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2038</td>\n",
       "      <td>0.880386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  rule_violation\n",
       "0    2029        0.046725\n",
       "1    2031        0.880386\n",
       "2    2032        0.886813\n",
       "3    2033        0.882833\n",
       "4    2034        0.040846\n",
       "5    2035        0.869715\n",
       "6    2036        0.042722\n",
       "7    2037        0.040846\n",
       "8    2038        0.880386"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collate_predictions(all_submissions)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 13121456,
     "sourceId": 94635,
     "sourceType": "competition"
    },
    {
     "modelId": 418776,
     "modelInstanceId": 400554,
     "sourceId": 504282,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "diffusion",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
